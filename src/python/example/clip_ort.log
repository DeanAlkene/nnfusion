ONNX model check passed!
Importing ONNX model into ONNX Runtime...
Execution Providers: ['CPUExecutionProvider']
tensor([[49406,   320,  1125,   539,   550, 18376,  6765,   320,  4558,   525,
          7496, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0',
       dtype=torch.int32)
last_hidden_state
[-0.3884   0.02298 -0.0521  -0.1841  -0.02733 -0.3357  -0.01758 -0.187
  0.1877  -0.09064] ...(size = 59136 end with 0.5947265625, sum = -6364.0)
pooler_output
[-2.629    0.362    0.2937   0.9526  -1.535    1.501   -1.932   -0.07025
 -0.155   -0.4287 ] ...(size = 768 end with -0.1319580078125, sum = -83.6875)
/text_model/Constant_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Constant_1_output_0
[-1 77] ...(size = 2 end with 77, sum = 76)
/text_model/Reshape_output_0
[49406   320  1125   539   550 18376  6765   320  4558   525] ...(size = 77 end with 49407, sum = 3350842)
/text_model/embeddings/token_embedding/Gather_output_0
[ 0.001093   0.003204   0.0002851 -0.00214   -0.0007925  0.002691
  0.001445  -0.002293   0.001591  -0.001003 ] ...(size = 59136 end with 0.005207061767578125, sum = 28.96875)
/text_model/embeddings/position_embedding/Gather_output_0
[ 0.001584  0.002008  0.000208 -0.001874 -0.000706  0.002995  0.000633
 -0.002918  0.001847 -0.001681] ...(size = 59136 end with -0.0309600830078125, sum = -17.984375)
/text_model/embeddings/Add_output_0
[ 0.002678  0.00521   0.000493 -0.004013 -0.001499  0.005684  0.002077
 -0.00521   0.003437 -0.002686] ...(size = 59136 end with -0.0257568359375, sum = 10.984375)
/text_model/Constant_2_output_0
[-65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with -65504.0, sum = -inf)
/text_model/Trilu_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/Constant_3_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Unsqueeze_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/Cast_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/encoder/layers.0/layer_norm1/ReduceMean_output_0
[ 1.163e-03  9.567e-05  2.080e-04  3.879e-04  2.961e-04  7.778e-05
  2.201e-04 -5.037e-05  1.353e-04  1.959e-04] ...(size = 77 end with 0.00013005733489990234, sum = 0.0142974853515625)
/text_model/encoder/layers.0/layer_norm1/Sub_output_0
[ 0.001514   0.00405   -0.00067   -0.005177  -0.00266    0.004524
  0.0009146 -0.006374   0.002275  -0.003847 ] ...(size = 59136 end with -0.02587890625, sum = -0.0033054351806640625)
/text_model/encoder/layers.0/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.0/layer_norm1/Pow_output_0
[2.265e-06 1.639e-05 4.768e-07 2.682e-05 7.093e-06 2.044e-05 8.345e-07
 4.065e-05 5.186e-06 1.478e-05] ...(size = 59136 end with 0.0006699562072753906, sum = 88.0)
/text_model/encoder/layers.0/layer_norm1/ReduceMean_1_output_0
[0.002272  0.0002143 0.0002223 0.0002228 0.0002271 0.0002363 0.000224
 0.0002309 0.0002328 0.0002211] ...(size = 77 end with 0.0019969940185546875, sum = 0.114501953125)
/text_model/encoder/layers.0/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.0/layer_norm1/Add_output_0
[0.002283  0.0002244 0.0002323 0.0002328 0.0002371 0.0002463 0.000234
 0.0002409 0.0002428 0.0002311] ...(size = 77 end with 0.0020084381103515625, sum = 0.11529541015625)
/text_model/encoder/layers.0/layer_norm1/Sqrt_output_0
[0.04776  0.01498  0.01524  0.01526  0.015396 0.01569  0.0153   0.015526
 0.01559  0.015205] ...(size = 77 end with 0.0447998046875, sum = 2.904296875)
/text_model/encoder/layers.0/layer_norm1/Div_output_0
[ 0.03168  0.0848  -0.01402 -0.10834 -0.05573  0.09467  0.01915 -0.1334
  0.0476  -0.0805 ] ...(size = 59136 end with -0.57763671875, sum = 0.018768310546875)
/text_model/encoder/layers.0/layer_norm1/Mul_output_0
[ 0.05832  0.1399  -0.02516 -0.1929  -0.0984   0.1674   0.0356  -0.2433
  0.08344 -0.1399 ] ...(size = 59136 end with -1.0185546875, sum = -537.5)
/text_model/encoder/layers.0/layer_norm1/Add_1_output_0
[-0.00566 -0.0492  -0.09143 -0.0771  -0.11774  0.0906  -0.05685 -0.0931
 -0.0706  -0.08624] ...(size = 59136 end with -1.1064453125, sum = 687.5)
/text_model/encoder/layers.0/self_attn/q_proj/MatMul_output_0
[-0.433   0.3574  0.2161  0.0329 -0.0923  0.2028  0.1508  0.1422 -0.2048
 -0.2307] ...(size = 59136 end with -2.298828125, sum = -1381.0)
/text_model/encoder/layers.0/self_attn/q_proj/Add_output_0
[-0.674    0.5063   0.6797   0.10077  0.563    0.4426   0.2074   0.017
 -0.2289  -0.2081 ] ...(size = 59136 end with -2.3046875, sum = 161.0)
/text_model/encoder/layers.0/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.0/self_attn/Mul_output_0
[-0.0842    0.0633    0.08496   0.012596  0.0704    0.05533   0.02592
  0.002125 -0.02861  -0.02602 ] ...(size = 59136 end with -0.2880859375, sum = 20.125)
/text_model/encoder/layers.0/self_attn/k_proj/MatMul_output_0
[ 0.2192   0.38     0.4      0.2438  -4.35    -0.3853  -0.891   -1.254
  0.3762   0.00815] ...(size = 59136 end with -0.6865234375, sum = 1608.0)
/text_model/encoder/layers.0/self_attn/k_proj/Add_output_0
[ 0.2164   0.3767   0.406    0.2445  -4.33    -0.3845  -0.8833  -1.265
  0.3843   0.00625] ...(size = 59136 end with -0.69970703125, sum = 1648.0)
/text_model/encoder/layers.0/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.0/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.0/self_attn/Reshape_output_0
[ 0.2164   0.3767   0.406    0.2445  -4.33    -0.3845  -0.8833  -1.265
  0.3843   0.00625] ...(size = 59136 end with -0.69970703125, sum = 1648.0)
/text_model/encoder/layers.0/self_attn/Transpose_output_0
[ 0.2164   0.3767   0.406    0.2445  -4.33    -0.3845  -0.8833  -1.265
  0.3843   0.00625] ...(size = 59136 end with -0.69970703125, sum = 1648.0)
/text_model/encoder/layers.0/self_attn/v_proj/MatMul_output_0
[-0.1937  -0.09595 -0.06027  0.1292   0.0522   0.0734   0.0346   0.0528
  0.3577  -0.0579 ] ...(size = 59136 end with -0.0877685546875, sum = 42.78125)
/text_model/encoder/layers.0/self_attn/v_proj/Add_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.10211181640625, sum = -3.25)
/text_model/encoder/layers.0/self_attn/Reshape_1_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.10211181640625, sum = -3.25)
/text_model/encoder/layers.0/self_attn/Transpose_1_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.10211181640625, sum = -3.427734375)
/text_model/encoder/layers.0/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.0/self_attn/Reshape_2_output_0
[-0.0842    0.0633    0.08496   0.012596  0.0704    0.05533   0.02592
  0.002125 -0.02861  -0.02602 ] ...(size = 59136 end with -0.2880859375, sum = 20.125)
/text_model/encoder/layers.0/self_attn/Transpose_2_output_0
[-0.0842    0.0633    0.08496   0.012596  0.0704    0.05533   0.02592
  0.002125 -0.02861  -0.02602 ] ...(size = 59136 end with -0.2880859375, sum = 20.203125)
/text_model/encoder/layers.0/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Reshape_3_output_0
[-0.0842    0.0633    0.08496   0.012596  0.0704    0.05533   0.02592
  0.002125 -0.02861  -0.02602 ] ...(size = 59136 end with -0.2880859375, sum = 20.203125)
/text_model/encoder/layers.0/self_attn/Reshape_4_output_0
[ 0.2164   0.3767   0.406    0.2445  -4.33    -0.3845  -0.8833  -1.265
  0.3843   0.00625] ...(size = 59136 end with -0.69970703125, sum = 1648.0)
/text_model/encoder/layers.0/self_attn/Reshape_5_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.10211181640625, sum = -3.427734375)
/text_model/encoder/layers.0/self_attn/Transpose_3_output_0
[ 0.2164 -0.1075 -0.0677  0.2754  0.721  -0.176   1.418  -0.1335  1.154
 -0.8066] ...(size = 59136 end with -0.69970703125, sum = 1648.0)
/text_model/encoder/layers.0/self_attn/MatMul_output_0
[-1.187    0.00912  1.135   -0.03876  0.106    1.544    0.6406  -0.5537
 -0.2361  -0.804  ] ...(size = 71148 end with 1.818359375, sum = inf)
/text_model/encoder/layers.0/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.0/self_attn/Reshape_6_output_0
[-1.187    0.00912  1.135   -0.03876  0.106    1.544    0.6406  -0.5537
 -0.2361  -0.804  ] ...(size = 71148 end with 1.818359375, sum = inf)
/text_model/encoder/layers.0/self_attn/Add_output_0
[-1.187e+00 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 1.818359375, sum = -inf)
/text_model/encoder/layers.0/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.0/self_attn/Reshape_7_output_0
[-1.187e+00 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 1.818359375, sum = -inf)
/text_model/encoder/layers.0/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0154876708984375, sum = 924.0)
/text_model/encoder/layers.0/self_attn/MatMul_1_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.07928466796875, sum = -108.6875)
/text_model/encoder/layers.0/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.0/self_attn/Reshape_8_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.07928466796875, sum = -108.6875)
/text_model/encoder/layers.0/self_attn/Transpose_4_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.07928466796875, sum = -108.5)
/text_model/encoder/layers.0/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.0/self_attn/Reshape_9_output_0
[-0.1886  -0.0927  -0.0461   0.12164  0.06354  0.0421   0.06146  0.04077
  0.3477  -0.04126] ...(size = 59136 end with -0.07928466796875, sum = -108.5)
/text_model/encoder/layers.0/self_attn/out_proj/MatMul_output_0
[ 0.08746  0.05353 -0.08276  0.12427  0.0482  -0.0554   0.04694  0.05466
  0.03387  0.075  ] ...(size = 59136 end with -0.04705810546875, sum = -6.453125)
/text_model/encoder/layers.0/self_attn/out_proj/Add_output_0
[ 0.0194   0.02055 -0.04092  0.02208  0.0427  -0.0511   0.04306  0.00628
  0.01112  0.0729 ] ...(size = 59136 end with -0.03692626953125, sum = 32.21875)
/text_model/encoder/layers.0/Add_output_0
[ 0.02206   0.02576  -0.04044   0.01807   0.0412   -0.0454    0.04514
  0.001069  0.01456   0.0702  ] ...(size = 59136 end with -0.06268310546875, sum = 43.21875)
/text_model/encoder/layers.0/layer_norm2/ReduceMean_output_0
[0.002989  0.00339   0.002548  0.00378   0.002777  0.0008616 0.0013275
 0.002354  0.001094  0.002253 ] ...(size = 77 end with 0.00017631053924560547, sum = 0.0562744140625)
/text_model/encoder/layers.0/layer_norm2/Sub_output_0
[ 0.01907   0.02278  -0.04343   0.015076  0.0382   -0.0484    0.04218
 -0.00192   0.01157   0.0672  ] ...(size = 59136 end with -0.0628662109375, sum = 0.004131317138671875)
/text_model/encoder/layers.0/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.0/layer_norm2/Pow_output_0
[3.638e-04 5.188e-04 1.886e-03 2.272e-04 1.459e-03 2.342e-03 1.778e-03
 3.695e-06 1.339e-04 4.513e-03] ...(size = 59136 end with 0.0039520263671875, sum = 765.5)
/text_model/encoder/layers.0/layer_norm2/ReduceMean_1_output_0
[0.00647  0.008385 0.01347  0.010445 0.00936  0.04108  0.02295  0.01189
 0.02573  0.00841 ] ...(size = 77 end with 0.014495849609375, sum = 0.9970703125)
/text_model/encoder/layers.0/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.0/layer_norm2/Add_output_0
[0.00648  0.00839  0.01348  0.01045  0.00937  0.04108  0.02296  0.011894
 0.02574  0.008415] ...(size = 77 end with 0.01450347900390625, sum = 0.998046875)
/text_model/encoder/layers.0/layer_norm2/Sqrt_output_0
[0.0805  0.0916  0.1161  0.10223 0.0968  0.2026  0.1515  0.1091  0.1604
 0.09174] ...(size = 77 end with 0.12042236328125, sum = 8.6796875)
/text_model/encoder/layers.0/layer_norm2/Div_output_0
[ 0.2369   0.283   -0.5396   0.1873   0.4746  -0.601    0.524   -0.02385
  0.1438   0.8345 ] ...(size = 59136 end with -0.52197265625, sum = 0.036224365234375)
/text_model/encoder/layers.0/layer_norm2/Mul_output_0
[ 0.3665   0.461   -0.7886   0.2837   0.8047  -0.923    0.892   -0.03934
  0.2408   1.289  ] ...(size = 59136 end with -0.845703125, sum = -1049.0)
/text_model/encoder/layers.0/layer_norm2/Add_1_output_0
[ 0.07825  1.14    -1.026    1.01     1.309   -1.025    0.4993   0.721
  0.523    1.564  ] ...(size = 59136 end with -0.85986328125, sum = 1411.0)
/text_model/encoder/layers.0/mlp/fc1/MatMul_output_0
[-1.421 -1.015 -2.373 -4.348 -1.901 -3.51  -1.612 -2.068 -2.416 -1.125] ...(size = 236544 end with -2.517578125, sum = -inf)
/text_model/encoder/layers.0/mlp/fc1/Add_output_0
[-1.801 -1.421 -2.67  -4.766 -1.856 -3.607 -1.919 -2.344 -2.686 -1.365] ...(size = 236544 end with -2.7109375, sum = -inf)
/text_model/encoder/layers.0/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.0/mlp/activation_fn/Mul_output_0
[-3.064 -2.42  -4.547 -8.11  -3.16  -6.14  -3.268 -3.988 -4.57  -2.324] ...(size = 236544 end with -4.61328125, sum = -inf)
/text_model/encoder/layers.0/mlp/activation_fn/Sigmoid_output_0
[0.04456   0.0817    0.0105    0.0003004 0.0407    0.002148  0.03674
 0.01819   0.01023   0.0891   ] ...(size = 236544 end with 0.00981903076171875, sum = 4026.0)
/text_model/encoder/layers.0/mlp/activation_fn/Mul_1_output_0
[-0.08026  -0.11615  -0.02805  -0.001431 -0.07556  -0.007748 -0.0705
 -0.04263  -0.02748  -0.1217  ] ...(size = 236544 end with -0.026611328125, sum = -3536.0)
/text_model/encoder/layers.0/mlp/fc2/MatMul_output_0
[-4.24    -2.64     5.12     0.7515  -1.033   -4.33    -2.324   -2.457
  3.404    0.07056] ...(size = 59136 end with -0.0462646484375, sum = -58.84375)
/text_model/encoder/layers.0/mlp/fc2/Add_output_0
[-4.23   -2.674   5.125   0.7485 -1.052  -4.363  -2.281  -2.467   3.41
  0.0636] ...(size = 59136 end with -0.06024169921875, sum = 6.078125)
/text_model/encoder/layers.0/Add_1_output_0
[-4.207  -2.648   5.082   0.7666 -1.011  -4.41   -2.236  -2.465   3.426
  0.1338] ...(size = 59136 end with -0.1229248046875, sum = 49.375)
/text_model/encoder/layers.1/layer_norm1/ReduceMean_output_0
[-0.01979    0.005985   0.002928   0.004494   0.00413    0.0007477
  0.001611   0.003239   0.000853   0.003056 ] ...(size = 77 end with 0.0007119178771972656, sum = 0.064208984375)
/text_model/encoder/layers.1/layer_norm1/Sub_output_0
[-4.188  -2.629   5.1     0.7866 -0.9907 -4.39   -2.217  -2.445   3.445
  0.1536] ...(size = 59136 end with -0.12359619140625, sum = -0.0301971435546875)
/text_model/encoder/layers.1/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.1/layer_norm1/Pow_output_0
[1.755e+01 6.906e+00 2.603e+01 6.187e-01 9.810e-01 1.927e+01 4.910e+00
 5.977e+00 1.187e+01 2.357e-02] ...(size = 59136 end with 0.01528167724609375, sum = inf)
/text_model/encoder/layers.1/layer_norm1/ReduceMean_1_output_0
[1.829e+03 3.900e-02 2.620e-02 2.167e-02 1.793e-02 3.973e-02 2.573e-02
 2.086e-02 2.815e-02 1.730e-02] ...(size = 77 end with 0.0171051025390625, sum = 1830.0)
/text_model/encoder/layers.1/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.1/layer_norm1/Add_output_0
[1.829e+03 3.900e-02 2.621e-02 2.168e-02 1.793e-02 3.973e-02 2.573e-02
 2.087e-02 2.815e-02 1.732e-02] ...(size = 77 end with 0.017120361328125, sum = 1830.0)
/text_model/encoder/layers.1/layer_norm1/Sqrt_output_0
[42.78    0.1975  0.1619  0.1472  0.1339  0.1993  0.1604  0.1444  0.1678
  0.1316] ...(size = 77 end with 0.130859375, sum = 52.59375)
/text_model/encoder/layers.1/layer_norm1/Div_output_0
[-0.09796 -0.06143  0.1193   0.01839 -0.02316 -0.10266 -0.05182 -0.05716
  0.08057  0.00359] ...(size = 59136 end with -0.94482421875, sum = -0.12225341796875)
/text_model/encoder/layers.1/layer_norm1/Mul_output_0
[-0.10675 -0.0706   0.1345   0.0188  -0.02719 -0.10944 -0.05713 -0.06396
  0.0855   0.00372] ...(size = 59136 end with -1.109375, sum = 32.46875)
/text_model/encoder/layers.1/layer_norm1/Add_1_output_0
[ 0.02303   -0.03607   -0.04938    0.03098    0.0271    -0.03903
  0.012024  -0.0003798  0.02155    0.02615  ] ...(size = 59136 end with -1.1064453125, sum = -33.21875)
/text_model/encoder/layers.1/self_attn/q_proj/MatMul_output_0
[-0.1725   -0.1033    0.09094  -0.00867   0.0772    0.0722   -0.0028
 -0.01689   0.1649    0.003435] ...(size = 59136 end with -0.1470947265625, sum = -2172.0)
/text_model/encoder/layers.1/self_attn/q_proj/Add_output_0
[ 0.1705  -0.1869   0.1333  -0.1014   0.2659   0.199   -0.1042  -0.02226
 -0.3362   0.08936] ...(size = 59136 end with 0.300537109375, sum = -2288.0)
/text_model/encoder/layers.1/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.1/self_attn/Mul_output_0
[ 0.02132  -0.02336   0.01666  -0.01267   0.03323   0.02487  -0.01302
 -0.002783 -0.04202   0.01117 ] ...(size = 59136 end with 0.037567138671875, sum = -286.0)
/text_model/encoder/layers.1/self_attn/k_proj/MatMul_output_0
[ 0.5054   0.08746  0.04053 -0.1218   0.06113  0.09406 -0.01636  0.01505
 -0.29     0.00501] ...(size = 59136 end with -1.373046875, sum = 1316.0)
/text_model/encoder/layers.1/self_attn/k_proj/Add_output_0
[ 0.5063    0.08295   0.04276  -0.12274   0.0631    0.09985  -0.01839
  0.01308  -0.289     0.003317] ...(size = 59136 end with -1.369140625, sum = 1363.0)
/text_model/encoder/layers.1/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.1/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.1/self_attn/Reshape_output_0
[ 0.5063    0.08295   0.04276  -0.12274   0.0631    0.09985  -0.01839
  0.01308  -0.289     0.003317] ...(size = 59136 end with -1.369140625, sum = 1363.0)
/text_model/encoder/layers.1/self_attn/Transpose_output_0
[ 0.5063    0.08295   0.04276  -0.12274   0.0631    0.09985  -0.01839
  0.01308  -0.289     0.003317] ...(size = 59136 end with -1.369140625, sum = 1362.0)
/text_model/encoder/layers.1/self_attn/v_proj/MatMul_output_0
[ 0.04623   0.01065  -0.02954  -0.001472 -0.03766  -0.055    -0.03001
 -0.004143 -0.02988   0.02682 ] ...(size = 59136 end with -0.000896453857421875, sum = 779.0)
/text_model/encoder/layers.1/self_attn/v_proj/Add_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with 0.01363372802734375, sum = 796.5)
/text_model/encoder/layers.1/self_attn/Reshape_1_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with 0.01363372802734375, sum = 796.5)
/text_model/encoder/layers.1/self_attn/Transpose_1_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with 0.01363372802734375, sum = 796.5)
/text_model/encoder/layers.1/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.1/self_attn/Reshape_2_output_0
[ 0.02132  -0.02336   0.01666  -0.01267   0.03323   0.02487  -0.01302
 -0.002783 -0.04202   0.01117 ] ...(size = 59136 end with 0.037567138671875, sum = -286.0)
/text_model/encoder/layers.1/self_attn/Transpose_2_output_0
[ 0.02132  -0.02336   0.01666  -0.01267   0.03323   0.02487  -0.01302
 -0.002783 -0.04202   0.01117 ] ...(size = 59136 end with 0.037567138671875, sum = -286.0)
/text_model/encoder/layers.1/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Reshape_3_output_0
[ 0.02132  -0.02336   0.01666  -0.01267   0.03323   0.02487  -0.01302
 -0.002783 -0.04202   0.01117 ] ...(size = 59136 end with 0.037567138671875, sum = -286.0)
/text_model/encoder/layers.1/self_attn/Reshape_4_output_0
[ 0.5063    0.08295   0.04276  -0.12274   0.0631    0.09985  -0.01839
  0.01308  -0.289     0.003317] ...(size = 59136 end with -1.369140625, sum = 1362.0)
/text_model/encoder/layers.1/self_attn/Reshape_5_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with 0.01363372802734375, sum = 796.5)
/text_model/encoder/layers.1/self_attn/Transpose_3_output_0
[ 0.5063  -0.3716  -1.072   -1.056   -0.4102  -1.337   -0.2837   0.5435
 -0.11804  1.1875 ] ...(size = 59136 end with -1.369140625, sum = 1363.0)
/text_model/encoder/layers.1/self_attn/MatMul_output_0
[ 0.936  -0.9126 -1.003  -1.104  -0.9795 -1.204  -1.44   -1.333  -1.396
 -1.041 ] ...(size = 71148 end with -2.912109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.1/self_attn/Reshape_6_output_0
[ 0.936  -0.9126 -1.003  -1.104  -0.9795 -1.204  -1.44   -1.333  -1.396
 -1.041 ] ...(size = 71148 end with -2.912109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Add_output_0
[ 9.36e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.912109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.1/self_attn/Reshape_7_output_0
[ 9.36e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.912109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.005001068115234375, sum = 924.0)
/text_model/encoder/layers.1/self_attn/MatMul_1_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with -0.0096282958984375, sum = 59.0625)
/text_model/encoder/layers.1/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.1/self_attn/Reshape_8_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with -0.0096282958984375, sum = 59.0625)
/text_model/encoder/layers.1/self_attn/Transpose_4_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with -0.0096282958984375, sum = 59.15625)
/text_model/encoder/layers.1/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.1/self_attn/Reshape_9_output_0
[ 0.0354   -0.00209  -0.01718   0.009766 -0.010895 -0.02203  -0.00342
 -0.006275 -0.00781   0.01419 ] ...(size = 59136 end with -0.0096282958984375, sum = 59.15625)
/text_model/encoder/layers.1/self_attn/out_proj/MatMul_output_0
[-0.01071  -0.006542 -0.002085  0.012985 -0.02039   0.007263  0.00515
  0.03041  -0.01286   0.007637] ...(size = 59136 end with 0.016845703125, sum = 6.59765625)
/text_model/encoder/layers.1/self_attn/out_proj/Add_output_0
[ 0.01985   0.008484 -0.02322   0.02934  -0.0264   -0.0047    0.04315
  0.0782   -0.02576   0.01938 ] ...(size = 59136 end with 0.01302337646484375, sum = 34.25)
/text_model/encoder/layers.1/Add_output_0
[-4.188  -2.639   5.06    0.796  -1.037  -4.414  -2.193  -2.387   3.4
  0.1531] ...(size = 59136 end with -0.10986328125, sum = 83.9375)
/text_model/encoder/layers.1/layer_norm2/ReduceMean_output_0
[-0.01884   0.006996  0.003452  0.005108  0.005295  0.001624  0.002335
  0.00416   0.00138   0.003592] ...(size = 77 end with 0.00116729736328125, sum = 0.1087646484375)
/text_model/encoder/layers.1/layer_norm2/Sub_output_0
[-4.168 -2.621  5.08   0.815 -1.018 -4.395 -2.174 -2.367  3.418  0.172] ...(size = 59136 end with -0.111083984375, sum = 0.404296875)
/text_model/encoder/layers.1/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.1/layer_norm2/Pow_output_0
[17.39     6.867   25.8      0.664    1.036   19.33     4.727    5.605
 11.69     0.02957] ...(size = 59136 end with 0.01233673095703125, sum = inf)
/text_model/encoder/layers.1/layer_norm2/ReduceMean_1_output_0
[1.829e+03 3.891e-02 2.992e-02 2.405e-02 2.040e-02 4.111e-02 2.756e-02
 2.560e-02 3.143e-02 1.799e-02] ...(size = 77 end with 0.01515960693359375, sum = 1830.0)
/text_model/encoder/layers.1/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.1/layer_norm2/Add_output_0
[1.829e+03 3.894e-02 2.994e-02 2.405e-02 2.042e-02 4.114e-02 2.757e-02
 2.562e-02 3.143e-02 1.801e-02] ...(size = 77 end with 0.01517486572265625, sum = 1830.0)
/text_model/encoder/layers.1/layer_norm2/Sqrt_output_0
[42.75    0.1973  0.173   0.155   0.143   0.2028  0.166   0.16    0.1772
  0.1342] ...(size = 77 end with 0.1231689453125, sum = 52.03125)
/text_model/encoder/layers.1/layer_norm2/Div_output_0
[-0.0975  -0.06128  0.1188   0.01906 -0.0238  -0.1028  -0.05084 -0.05536
  0.07996  0.00402] ...(size = 59136 end with -0.9013671875, sum = 0.0277252197265625)
/text_model/encoder/layers.1/layer_norm2/Mul_output_0
[-0.182   -0.10895  0.2153   0.03625 -0.04333 -0.1887  -0.0982  -0.1054
  0.1605   0.00699] ...(size = 59136 end with -1.6591796875, sum = 970.0)
/text_model/encoder/layers.1/layer_norm2/Add_1_output_0
[-0.0819   0.2174   0.00492 -0.4734  -0.0857  -0.4563   0.8438  -0.3801
 -0.3665  -0.0485 ] ...(size = 59136 end with -1.65625, sum = -269.75)
/text_model/encoder/layers.1/mlp/fc1/MatMul_output_0
[-2.031 -2.59  -1.313 -1.403 -3.49  -1.545 -2.08  -2.32  -1.399 -2.455] ...(size = 236544 end with -2.828125, sum = -inf)
/text_model/encoder/layers.1/mlp/fc1/Add_output_0
[-2.316 -2.926 -1.265 -1.751 -3.727 -2.004 -2.506 -2.686 -1.74  -2.81 ] ...(size = 236544 end with -3.103515625, sum = -inf)
/text_model/encoder/layers.1/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.1/mlp/activation_fn/Mul_output_0
[-3.941 -4.98  -2.152 -2.98  -6.344 -3.41  -4.266 -4.57  -2.963 -4.785] ...(size = 236544 end with -5.28515625, sum = -inf)
/text_model/encoder/layers.1/mlp/activation_fn/Sigmoid_output_0
[0.01904  0.006817 0.10406  0.0483   0.001757 0.03198  0.01386  0.01023
 0.04913  0.008286] ...(size = 236544 end with 0.0050506591796875, sum = 4364.0)
/text_model/encoder/layers.1/mlp/activation_fn/Mul_1_output_0
[-0.0441   -0.01996  -0.1316   -0.0846   -0.006546 -0.0641   -0.03473
 -0.02748  -0.0855   -0.02328 ] ...(size = 236544 end with -0.0156707763671875, sum = -4552.0)
/text_model/encoder/layers.1/mlp/fc2/MatMul_output_0
[ 0.03015 -0.06696  0.061    0.02731 -0.1704  -0.104    0.04428 -0.02522
  0.1414  -0.0196 ] ...(size = 59136 end with 0.0242767333984375, sum = 0.92578125)
/text_model/encoder/layers.1/mlp/fc2/Add_output_0
[ 0.05655 -0.02817  0.02151  0.04202 -0.1611  -0.09357 -0.01746  0.00863
  0.2006  -0.03186] ...(size = 59136 end with 0.008453369140625, sum = 25.28125)
/text_model/encoder/layers.1/Add_1_output_0
[-4.133  -2.668   5.082   0.838  -1.198  -4.508  -2.21   -2.379   3.6
  0.1213] ...(size = 59136 end with -0.1014404296875, sum = 108.9375)
/text_model/encoder/layers.2/layer_norm1/ReduceMean_output_0
[-0.02087    0.00863    0.003448   0.005108   0.005665   0.0009093
  0.002285   0.00502    0.001254   0.003754 ] ...(size = 77 end with 0.0016422271728515625, sum = 0.1417236328125)
/text_model/encoder/layers.2/layer_norm1/Sub_output_0
[-4.11   -2.646   5.1     0.859  -1.177  -4.49   -2.19   -2.357   3.621
  0.1421] ...(size = 59136 end with -0.10308837890625, sum = 0.07537841796875)
/text_model/encoder/layers.2/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.2/layer_norm1/Pow_output_0
[1.691e+01 7.004e+00 2.603e+01 7.378e-01 1.385e+00 2.014e+01 4.793e+00
 5.555e+00 1.311e+01 2.020e-02] ...(size = 59136 end with 0.01062774658203125, sum = inf)
/text_model/encoder/layers.2/layer_norm1/ReduceMean_1_output_0
[1.832e+03 6.873e-02 4.437e-02 3.671e-02 3.084e-02 4.294e-02 3.275e-02
 3.848e-02 3.879e-02 2.084e-02] ...(size = 77 end with 0.0177459716796875, sum = 1833.0)
/text_model/encoder/layers.2/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.2/layer_norm1/Add_output_0
[1.832e+03 6.879e-02 4.440e-02 3.671e-02 3.085e-02 4.297e-02 3.278e-02
 3.848e-02 3.879e-02 2.086e-02] ...(size = 77 end with 0.01776123046875, sum = 1833.0)
/text_model/encoder/layers.2/layer_norm1/Sqrt_output_0
[42.8     0.2622  0.2107  0.1917  0.1757  0.2073  0.181   0.1962  0.1969
  0.1444] ...(size = 77 end with 0.13330078125, sum = 53.15625)
/text_model/encoder/layers.2/layer_norm1/Div_output_0
[-0.096   -0.06183  0.1192   0.02007 -0.0275  -0.1048  -0.05115 -0.05505
  0.0846   0.00332] ...(size = 59136 end with -0.7734375, sum = 0.0167236328125)
/text_model/encoder/layers.2/layer_norm1/Mul_output_0
[-0.1227   -0.08734   0.1578    0.02432  -0.03928  -0.1288   -0.06506
 -0.0666    0.1038    0.003994] ...(size = 59136 end with -1.060546875, sum = -600.0)
/text_model/encoder/layers.2/layer_norm1/Add_1_output_0
[-0.010185 -0.02084   0.00537   0.02373   0.00622  -0.0354    0.02432
 -0.00691   0.0079    0.04056 ] ...(size = 59136 end with -1.0625, sum = -675.5)
/text_model/encoder/layers.2/self_attn/q_proj/MatMul_output_0
[-0.02539 -0.03387 -0.07367 -0.04608  0.0642  -0.0359  -0.0464   0.0385
 -0.04938 -0.2113 ] ...(size = 59136 end with 0.3544921875, sum = -3192.0)
/text_model/encoder/layers.2/self_attn/q_proj/Add_output_0
[-0.4587    0.1316   -0.1256    0.1646    0.598     0.2405   -0.012375
  0.5254    0.03833   1.244   ] ...(size = 59136 end with 0.501953125, sum = -3168.0)
/text_model/encoder/layers.2/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.2/self_attn/Mul_output_0
[-0.05734   0.01645  -0.0157    0.02057   0.07477   0.03006  -0.001547
  0.0657    0.00479   0.1555  ] ...(size = 59136 end with 0.062744140625, sum = -396.0)
/text_model/encoder/layers.2/self_attn/k_proj/MatMul_output_0
[-0.2058    0.1499    0.013725  0.1054    1.343     0.2312   -0.03043
  0.1494    0.06024   1.328   ] ...(size = 59136 end with 0.34375, sum = 522.0)
/text_model/encoder/layers.2/self_attn/k_proj/Add_output_0
[-0.21     0.1504   0.01524  0.1057   1.351    0.236   -0.03967  0.1516
  0.0629   1.342  ] ...(size = 59136 end with 0.345458984375, sum = 526.0)
/text_model/encoder/layers.2/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.2/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.2/self_attn/Reshape_output_0
[-0.21     0.1504   0.01524  0.1057   1.351    0.236   -0.03967  0.1516
  0.0629   1.342  ] ...(size = 59136 end with 0.345458984375, sum = 526.0)
/text_model/encoder/layers.2/self_attn/Transpose_output_0
[-0.21     0.1504   0.01524  0.1057   1.351    0.236   -0.03967  0.1516
  0.0629   1.342  ] ...(size = 59136 end with 0.345458984375, sum = 525.5)
/text_model/encoder/layers.2/self_attn/v_proj/MatMul_output_0
[ 0.03265   0.00597  -0.006756  0.0402    0.03122  -0.005497  0.00993
  0.0762   -0.11914   0.03812 ] ...(size = 59136 end with 0.294677734375, sum = -781.5)
/text_model/encoder/layers.2/self_attn/v_proj/Add_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.3251953125, sum = -768.0)
/text_model/encoder/layers.2/self_attn/Reshape_1_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.3251953125, sum = -768.0)
/text_model/encoder/layers.2/self_attn/Transpose_1_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.3251953125, sum = -767.5)
/text_model/encoder/layers.2/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.2/self_attn/Reshape_2_output_0
[-0.05734   0.01645  -0.0157    0.02057   0.07477   0.03006  -0.001547
  0.0657    0.00479   0.1555  ] ...(size = 59136 end with 0.062744140625, sum = -396.0)
/text_model/encoder/layers.2/self_attn/Transpose_2_output_0
[-0.05734   0.01645  -0.0157    0.02057   0.07477   0.03006  -0.001547
  0.0657    0.00479   0.1555  ] ...(size = 59136 end with 0.062744140625, sum = -396.0)
/text_model/encoder/layers.2/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Reshape_3_output_0
[-0.05734   0.01645  -0.0157    0.02057   0.07477   0.03006  -0.001547
  0.0657    0.00479   0.1555  ] ...(size = 59136 end with 0.062744140625, sum = -396.0)
/text_model/encoder/layers.2/self_attn/Reshape_4_output_0
[-0.21     0.1504   0.01524  0.1057   1.351    0.236   -0.03967  0.1516
  0.0629   1.342  ] ...(size = 59136 end with 0.345458984375, sum = 525.5)
/text_model/encoder/layers.2/self_attn/Reshape_5_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.3251953125, sum = -767.5)
/text_model/encoder/layers.2/self_attn/Transpose_3_output_0
[-0.21   -0.609  -1.129   0.26   -0.3887  0.802  -0.084  -0.3206  0.3855
  0.641 ] ...(size = 59136 end with 0.345458984375, sum = 526.0)
/text_model/encoder/layers.2/self_attn/MatMul_output_0
[ 0.842  -1.509  -0.8013 -1.93   -1.891  -0.691  -0.9146 -1.747  -1.158
 -2.322 ] ...(size = 71148 end with -3.59375, sum = -inf)
/text_model/encoder/layers.2/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.2/self_attn/Reshape_6_output_0
[ 0.842  -1.509  -0.8013 -1.93   -1.891  -0.691  -0.9146 -1.747  -1.158
 -2.322 ] ...(size = 71148 end with -3.59375, sum = -inf)
/text_model/encoder/layers.2/self_attn/Add_output_0
[ 8.42e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.59375, sum = -inf)
/text_model/encoder/layers.2/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.2/self_attn/Reshape_7_output_0
[ 8.42e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.59375, sum = -inf)
/text_model/encoder/layers.2/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0024852752685546875, sum = 924.0)
/text_model/encoder/layers.2/self_attn/MatMul_1_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.0357666015625, sum = -30.234375)
/text_model/encoder/layers.2/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.2/self_attn/Reshape_8_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.0357666015625, sum = -30.234375)
/text_model/encoder/layers.2/self_attn/Transpose_4_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.0357666015625, sum = -30.25)
/text_model/encoder/layers.2/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.2/self_attn/Reshape_9_output_0
[ 0.002485 -0.007595  0.0077    0.01287   0.01584   0.04327   0.001694
  0.0643   -0.1407    0.02911 ] ...(size = 59136 end with 0.0357666015625, sum = -30.25)
/text_model/encoder/layers.2/self_attn/out_proj/MatMul_output_0
[ 0.005726 -0.012115 -0.04114  -0.02722  -0.00306  -0.03424   0.05493
 -0.0077   -0.02048   0.01013 ] ...(size = 59136 end with 0.005214691162109375, sum = -4.296875)
/text_model/encoder/layers.2/self_attn/out_proj/Add_output_0
[ 0.05222  0.02914 -0.0987  -0.02301 -0.01843 -0.0414   0.1268  -0.00433
 -0.00845  0.00841] ...(size = 59136 end with 0.013153076171875, sum = 8.2578125)
/text_model/encoder/layers.2/Add_output_0
[-4.08   -2.639   4.984   0.815  -1.216  -4.55   -2.084  -2.383   3.592
  0.1296] ...(size = 59136 end with -0.0882568359375, sum = 116.75)
/text_model/encoder/layers.2/layer_norm2/ReduceMean_output_0
[-0.02043   0.009056  0.003798  0.00549   0.006237  0.001175  0.002537
  0.005432  0.001304  0.003593] ...(size = 77 end with 0.0016431808471679688, sum = 0.1524658203125)
/text_model/encoder/layers.2/layer_norm2/Sub_output_0
[-4.06   -2.617   5.004   0.8354 -1.195  -4.527  -2.062  -2.361   3.611
  0.1501] ...(size = 59136 end with -0.08990478515625, sum = -0.39501953125)
/text_model/encoder/layers.2/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.2/layer_norm2/Pow_output_0
[1.648e+01 6.852e+00 2.503e+01 6.978e-01 1.430e+00 2.052e+01 4.258e+00
 5.578e+00 1.305e+01 2.254e-02] ...(size = 59136 end with 0.008087158203125, sum = inf)
/text_model/encoder/layers.2/layer_norm2/ReduceMean_1_output_0
[1.833e+03 7.086e-02 4.736e-02 4.288e-02 3.845e-02 4.541e-02 4.376e-02
 5.276e-02 4.147e-02 3.348e-02] ...(size = 77 end with 0.020172119140625, sum = 1835.0)
/text_model/encoder/layers.2/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.2/layer_norm2/Add_output_0
[1.833e+03 7.092e-02 4.736e-02 4.291e-02 3.848e-02 4.541e-02 4.379e-02
 5.276e-02 4.147e-02 3.348e-02] ...(size = 77 end with 0.0201873779296875, sum = 1835.0)
/text_model/encoder/layers.2/layer_norm2/Sqrt_output_0
[42.8     0.2664  0.2177  0.2072  0.1962  0.2131  0.2092  0.2297  0.2037
  0.183 ] ...(size = 77 end with 0.14208984375, sum = 53.96875)
/text_model/encoder/layers.2/layer_norm2/Div_output_0
[-0.09485  -0.06116   0.1169    0.01952  -0.02794  -0.1058   -0.0482
 -0.05518   0.08435   0.003506] ...(size = 59136 end with -0.6328125, sum = 0.03631591796875)
/text_model/encoder/layers.2/layer_norm2/Mul_output_0
[-0.192    -0.12445   0.228     0.03845  -0.0547   -0.2034   -0.0997
 -0.10785   0.1686    0.007267] ...(size = 59136 end with -1.2666015625, sum = 1859.0)
/text_model/encoder/layers.2/layer_norm2/Add_1_output_0
[ 0.02292  0.6226  -0.2097  -0.1534  -0.2483   0.207    0.3484  -0.2141
  0.01894 -0.3333 ] ...(size = 59136 end with -0.8583984375, sum = 2602.0)
/text_model/encoder/layers.2/mlp/fc1/MatMul_output_0
[-2.645  -0.9883 -2.617  -3.705  -1.965  -1.167  -1.261  -2.63    0.936
 -1.645 ] ...(size = 236544 end with -3.1796875, sum = -inf)
/text_model/encoder/layers.2/mlp/fc1/Add_output_0
[-2.814  -1.141  -2.805  -4.05   -2.262  -1.6    -1.535  -2.76    0.5894
 -1.554 ] ...(size = 236544 end with -3.525390625, sum = -inf)
/text_model/encoder/layers.2/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.2/mlp/activation_fn/Mul_output_0
[-4.79  -1.941 -4.773 -6.895 -3.85  -2.723 -2.613 -4.7    1.003 -2.645] ...(size = 236544 end with -6.0, sum = -inf)
/text_model/encoder/layers.2/mlp/activation_fn/Sigmoid_output_0
[0.00825  0.1255   0.00836  0.001013 0.02084  0.06165  0.0683   0.009026
 0.7314   0.0663  ] ...(size = 236544 end with 0.002471923828125, sum = 6044.0)
/text_model/encoder/layers.2/mlp/activation_fn/Mul_1_output_0
[-0.02321 -0.1432  -0.02347 -0.0041  -0.04715 -0.09863 -0.1048  -0.02492
  0.431   -0.103  ] ...(size = 236544 end with -0.0087127685546875, sum = -6296.0)
/text_model/encoder/layers.2/mlp/fc2/MatMul_output_0
[ 0.1177    0.007557 -0.1687    0.05164  -0.06964  -0.05994  -0.1436
 -0.03656   0.1198    0.06934 ] ...(size = 59136 end with 0.052490234375, sum = 2.69921875)
/text_model/encoder/layers.2/mlp/fc2/Add_output_0
[ 0.1032   -0.01189  -0.2212    0.0206   -0.121    -0.02391  -0.1486
 -0.005665  0.05905   0.0654  ] ...(size = 59136 end with 0.01074981689453125, sum = 25.328125)
/text_model/encoder/layers.2/Add_1_output_0
[-3.977  -2.65    4.76    0.8354 -1.337  -4.574  -2.232  -2.389   3.65
  0.1951] ...(size = 59136 end with -0.0775146484375, sum = 142.125)
/text_model/encoder/layers.3/layer_norm1/ReduceMean_output_0
[-0.0203    0.00954   0.004387  0.00639   0.006744  0.001313  0.00299
  0.00698   0.00158   0.004395] ...(size = 77 end with 0.002086639404296875, sum = 0.1854248046875)
/text_model/encoder/layers.3/layer_norm1/Sub_output_0
[-3.957  -2.63    4.78    0.856  -1.317  -4.555  -2.21   -2.367   3.672
  0.2153] ...(size = 59136 end with -0.07958984375, sum = -0.268798828125)
/text_model/encoder/layers.3/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.3/layer_norm1/Pow_output_0
[15.65    6.918  22.86    0.7324  1.734  20.73    4.89    5.605  13.48
  0.0464] ...(size = 59136 end with 0.006336212158203125, sum = inf)
/text_model/encoder/layers.3/layer_norm1/ReduceMean_1_output_0
[1.834e+03 7.812e-02 5.359e-02 6.158e-02 4.822e-02 4.941e-02 4.895e-02
 6.049e-02 4.584e-02 3.619e-02] ...(size = 77 end with 0.021514892578125, sum = 1836.0)
/text_model/encoder/layers.3/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.3/layer_norm1/Add_output_0
[1.834e+03 7.812e-02 5.362e-02 6.158e-02 4.822e-02 4.941e-02 4.895e-02
 6.049e-02 4.584e-02 3.619e-02] ...(size = 77 end with 0.021514892578125, sum = 1836.0)
/text_model/encoder/layers.3/layer_norm1/Sqrt_output_0
[42.8     0.2795  0.2316  0.2482  0.2196  0.2223  0.2213  0.246   0.2141
  0.1903] ...(size = 77 end with 0.146728515625, sum = 54.5)
/text_model/encoder/layers.3/layer_norm1/Div_output_0
[-0.0924   -0.0614    0.1117    0.01999  -0.03075  -0.1063   -0.05164
 -0.0553    0.08575   0.005028] ...(size = 59136 end with -0.54248046875, sum = -0.06341552734375)
/text_model/encoder/layers.3/layer_norm1/Mul_output_0
[-0.1189   -0.0854    0.1483    0.02748  -0.04248  -0.1415   -0.06665
 -0.076     0.1139    0.006424] ...(size = 59136 end with -0.7509765625, sum = -955.5)
/text_model/encoder/layers.3/layer_norm1/Add_1_output_0
[-0.03156  -0.02422   0.03436   0.004288  0.02376  -0.03665  -0.004757
 -0.00902   0.03091   0.03595 ] ...(size = 59136 end with -0.7509765625, sum = -948.0)
/text_model/encoder/layers.3/self_attn/q_proj/MatMul_output_0
[ 0.06744 -0.01549  0.03537  0.01787  0.018    0.0983  -0.1091  -0.2212
 -0.1428  -0.1081 ] ...(size = 59136 end with 0.399169921875, sum = 1650.0)
/text_model/encoder/layers.3/self_attn/q_proj/Add_output_0
[ 0.2422  -0.08496 -0.2145  -0.2332   0.2573  -0.1043  -0.091   -0.05673
  0.2654   0.202  ] ...(size = 59136 end with 0.9052734375, sum = 2024.0)
/text_model/encoder/layers.3/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.3/self_attn/Mul_output_0
[ 0.03027  -0.01062  -0.02681  -0.02914   0.03217  -0.01304  -0.011375
 -0.00709   0.03317   0.02525 ] ...(size = 59136 end with 0.1131591796875, sum = 253.0)
/text_model/encoder/layers.3/self_attn/k_proj/MatMul_output_0
[ 1.51    -0.01501 -0.155   -0.10834  0.1318  -0.1143  -0.2289  -0.05798
  0.3418   0.2041 ] ...(size = 59136 end with -1.1279296875, sum = 151.625)
/text_model/encoder/layers.3/self_attn/k_proj/Add_output_0
[ 1.555   -0.01726 -0.1565  -0.107    0.1299  -0.1243  -0.2335  -0.06256
  0.3508   0.2173 ] ...(size = 59136 end with -1.1240234375, sum = 182.0)
/text_model/encoder/layers.3/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.3/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.3/self_attn/Reshape_output_0
[ 1.555   -0.01726 -0.1565  -0.107    0.1299  -0.1243  -0.2335  -0.06256
  0.3508   0.2173 ] ...(size = 59136 end with -1.1240234375, sum = 182.0)
/text_model/encoder/layers.3/self_attn/Transpose_output_0
[ 1.555   -0.01726 -0.1565  -0.107    0.1299  -0.1243  -0.2335  -0.06256
  0.3508   0.2173 ] ...(size = 59136 end with -1.1240234375, sum = 181.875)
/text_model/encoder/layers.3/self_attn/v_proj/MatMul_output_0
[ 0.08685   0.0798   -0.05347  -0.01352   0.0706    0.03522   0.02914
 -0.02092   0.07587  -0.007153] ...(size = 59136 end with 0.1981201171875, sum = 382.0)
/text_model/encoder/layers.3/self_attn/v_proj/Add_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.263427734375, sum = 348.25)
/text_model/encoder/layers.3/self_attn/Reshape_1_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.263427734375, sum = 348.25)
/text_model/encoder/layers.3/self_attn/Transpose_1_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.263427734375, sum = 348.75)
/text_model/encoder/layers.3/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.3/self_attn/Reshape_2_output_0
[ 0.03027  -0.01062  -0.02681  -0.02914   0.03217  -0.01304  -0.011375
 -0.00709   0.03317   0.02525 ] ...(size = 59136 end with 0.1131591796875, sum = 253.0)
/text_model/encoder/layers.3/self_attn/Transpose_2_output_0
[ 0.03027  -0.01062  -0.02681  -0.02914   0.03217  -0.01304  -0.011375
 -0.00709   0.03317   0.02525 ] ...(size = 59136 end with 0.1131591796875, sum = 253.125)
/text_model/encoder/layers.3/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Reshape_3_output_0
[ 0.03027  -0.01062  -0.02681  -0.02914   0.03217  -0.01304  -0.011375
 -0.00709   0.03317   0.02525 ] ...(size = 59136 end with 0.1131591796875, sum = 253.125)
/text_model/encoder/layers.3/self_attn/Reshape_4_output_0
[ 1.555   -0.01726 -0.1565  -0.107    0.1299  -0.1243  -0.2335  -0.06256
  0.3508   0.2173 ] ...(size = 59136 end with -1.1240234375, sum = 181.875)
/text_model/encoder/layers.3/self_attn/Reshape_5_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.263427734375, sum = 348.75)
/text_model/encoder/layers.3/self_attn/Transpose_3_output_0
[ 1.555 -1.496 -1.528 -1.343 -1.788 -2.92  -2.676 -1.92  -4.33  -2.125] ...(size = 59136 end with -1.1240234375, sum = 181.375)
/text_model/encoder/layers.3/self_attn/MatMul_output_0
[ 0.606  -0.992  -1.453  -1.413  -1.204  -0.8203 -1.291  -1.276  -1.103
 -1.416 ] ...(size = 71148 end with -5.46875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.3/self_attn/Reshape_6_output_0
[ 0.606  -0.992  -1.453  -1.413  -1.204  -0.8203 -1.291  -1.276  -1.103
 -1.416 ] ...(size = 71148 end with -5.46875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Add_output_0
[ 6.06e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -5.46875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.3/self_attn/Reshape_7_output_0
[ 6.06e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -5.46875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0004863739013671875, sum = 924.0)
/text_model/encoder/layers.3/self_attn/MatMul_1_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.0126495361328125, sum = 182.0)
/text_model/encoder/layers.3/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.3/self_attn/Reshape_8_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.0126495361328125, sum = 182.0)
/text_model/encoder/layers.3/self_attn/Transpose_4_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.0126495361328125, sum = 182.0)
/text_model/encoder/layers.3/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.3/self_attn/Reshape_9_output_0
[ 0.03087   0.02135  -0.00548  -0.01898   0.05402  -0.003355  0.01386
  0.01167   0.0742   -0.003   ] ...(size = 59136 end with 0.0126495361328125, sum = 182.0)
/text_model/encoder/layers.3/self_attn/out_proj/MatMul_output_0
[ 0.01796   -0.006893   0.0064    -0.01923    0.005203  -0.01585
  0.02505    0.004543   0.0002599  0.0392   ] ...(size = 59136 end with 0.021484375, sum = -13.015625)
/text_model/encoder/layers.3/self_attn/out_proj/Add_output_0
[ 0.01334  -0.01761   0.002153 -0.03088  -0.0671   -0.004444  0.0909
 -0.02704   0.023     0.09094 ] ...(size = 59136 end with 0.03973388671875, sum = 10.4375)
/text_model/encoder/layers.3/Add_output_0
[-3.963  -2.668   4.76    0.8047 -1.404  -4.58   -2.14   -2.414   3.674
  0.286 ] ...(size = 59136 end with -0.037811279296875, sum = 152.875)
/text_model/encoder/layers.3/layer_norm2/ReduceMean_output_0
[-0.01984   0.01003   0.004883  0.00688   0.007427  0.001675  0.00331
  0.007275  0.002111  0.0048  ] ...(size = 77 end with 0.0021991729736328125, sum = 0.1990966796875)
/text_model/encoder/layers.3/layer_norm2/Sub_output_0
[-3.943  -2.648   4.785   0.8247 -1.385  -4.56   -2.121  -2.395   3.693
  0.306 ] ...(size = 59136 end with -0.040008544921875, sum = 0.0516357421875)
/text_model/encoder/layers.3/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.3/layer_norm2/Pow_output_0
[15.55     7.01    22.88     0.6797   1.917   20.78     4.5      5.74
 13.64     0.09357] ...(size = 59136 end with 0.0016002655029296875, sum = inf)
/text_model/encoder/layers.3/layer_norm2/ReduceMean_1_output_0
[1.834e+03 8.020e-02 5.606e-02 6.354e-02 5.377e-02 5.197e-02 5.737e-02
 8.301e-02 5.771e-02 5.267e-02] ...(size = 77 end with 0.0232391357421875, sum = 1836.0)
/text_model/encoder/layers.3/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.3/layer_norm2/Add_output_0
[1.834e+03 8.020e-02 5.609e-02 6.360e-02 5.380e-02 5.197e-02 5.737e-02
 8.301e-02 5.774e-02 5.267e-02] ...(size = 77 end with 0.02325439453125, sum = 1836.0)
/text_model/encoder/layers.3/layer_norm2/Sqrt_output_0
[42.84    0.2832  0.2368  0.2522  0.2319  0.228   0.2395  0.288   0.2402
  0.2295] ...(size = 77 end with 0.1524658203125, sum = 55.125)
/text_model/encoder/layers.3/layer_norm2/Div_output_0
[-0.09204 -0.06183  0.1117   0.01926 -0.03232 -0.10645 -0.04953 -0.0559
  0.08624  0.00714] ...(size = 59136 end with -0.26220703125, sum = 0.006683349609375)
/text_model/encoder/layers.3/layer_norm2/Mul_output_0
[-0.187    -0.12195   0.231     0.04028  -0.06757  -0.2299   -0.10864
 -0.11707   0.1884    0.014725] ...(size = 59136 end with -0.5673828125, sum = -540.0)
/text_model/encoder/layers.3/layer_norm2/Add_1_output_0
[-0.3506   0.2683  -0.4263   0.11804 -0.4321   0.574    0.5283  -0.2039
 -0.1935  -0.1466 ] ...(size = 59136 end with -0.07086181640625, sum = 1270.0)
/text_model/encoder/layers.3/mlp/fc1/MatMul_output_0
[-1.519  -2.69   -1.151  -1.133  -1.838  -2.14   -2.031  -3.062  -1.735
 -0.1037] ...(size = 236544 end with -2.625, sum = -inf)
/text_model/encoder/layers.3/mlp/fc1/Add_output_0
[-1.853  -3.15   -1.304  -1.401  -2.213  -2.434  -2.352  -3.518  -2.086
 -0.3884] ...(size = 236544 end with -2.935546875, sum = -inf)
/text_model/encoder/layers.3/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.3/mlp/activation_fn/Mul_output_0
[-3.152 -5.363 -2.219 -2.385 -3.766 -4.14  -4.    -5.99  -3.55  -0.661] ...(size = 236544 end with -4.99609375, sum = -inf)
/text_model/encoder/layers.3/mlp/activation_fn/Sigmoid_output_0
[0.041    0.004665 0.098    0.0843   0.02261  0.01564  0.01796  0.002504
 0.0279   0.3406  ] ...(size = 236544 end with 0.006725311279296875, sum = 10840.0)
/text_model/encoder/layers.3/mlp/activation_fn/Mul_1_output_0
[-0.0759   -0.014694 -0.1278   -0.1181   -0.05005  -0.03806  -0.04224
 -0.00881  -0.0582   -0.1322  ] ...(size = 236544 end with -0.0197296142578125, sum = -10560.0)
/text_model/encoder/layers.3/mlp/fc2/MatMul_output_0
[ 0.04285 -0.10614  0.07556  0.01677  0.218   -0.05286 -0.1903   0.02731
  0.1477   0.01535] ...(size = 59136 end with -0.0350341796875, sum = -4.47265625)
/text_model/encoder/layers.3/mlp/fc2/Add_output_0
[ 0.0288    -0.04974    0.01191    0.0011215  0.1478    -0.03226
 -0.1409     0.0234     0.05252   -0.01166  ] ...(size = 59136 end with -0.0083770751953125, sum = 1.572265625)
/text_model/encoder/layers.3/Add_1_output_0
[-3.934  -2.717   4.777   0.8057 -1.257  -4.61   -2.281  -2.39    3.727
  0.2744] ...(size = 59136 end with -0.046173095703125, sum = 154.125)
/text_model/encoder/layers.4/layer_norm1/ReduceMean_output_0
[-0.02011   0.01006   0.004562  0.0068    0.006752  0.001338  0.002974
  0.007668  0.001803  0.005825] ...(size = 77 end with 0.0022563934326171875, sum = 0.2010498046875)
/text_model/encoder/layers.4/layer_norm1/Sub_output_0
[-3.914  -2.697   4.797   0.826  -1.236  -4.59   -2.262  -2.371   3.746
  0.2944] ...(size = 59136 end with -0.048431396484375, sum = -0.258544921875)
/text_model/encoder/layers.4/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.4/layer_norm1/Pow_output_0
[15.32     7.277   23.       0.682    1.528   21.06     5.117    5.625
 14.04     0.08673] ...(size = 59136 end with 0.002346038818359375, sum = inf)
/text_model/encoder/layers.4/layer_norm1/ReduceMean_1_output_0
[1.834e+03 8.374e-02 6.470e-02 7.263e-02 5.978e-02 6.354e-02 7.062e-02
 8.203e-02 6.665e-02 4.819e-02] ...(size = 77 end with 0.025909423828125, sum = 1836.0)
/text_model/encoder/layers.4/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.4/layer_norm1/Add_output_0
[1.834e+03 8.374e-02 6.476e-02 7.263e-02 5.981e-02 6.354e-02 7.062e-02
 8.203e-02 6.665e-02 4.819e-02] ...(size = 77 end with 0.0259246826171875, sum = 1836.0)
/text_model/encoder/layers.4/layer_norm1/Sqrt_output_0
[42.8     0.2893  0.2544  0.2695  0.2445  0.252   0.2659  0.2864  0.2583
  0.2195] ...(size = 77 end with 0.1610107421875, sum = 55.84375)
/text_model/encoder/layers.4/layer_norm1/Div_output_0
[-0.0914   -0.063     0.112     0.01929  -0.02887  -0.1072   -0.05283
 -0.05536   0.08746   0.006874] ...(size = 59136 end with -0.30078125, sum = -0.028167724609375)
/text_model/encoder/layers.4/layer_norm1/Mul_output_0
[-0.1298  -0.09796  0.162    0.02734 -0.0406  -0.1543  -0.07324 -0.0759
  0.1238   0.00936] ...(size = 59136 end with -0.421630859375, sum = -861.0)
/text_model/encoder/layers.4/layer_norm1/Add_1_output_0
[-0.05786   0.000712  0.0389    0.002047 -0.00626  -0.03146  -0.002682
 -0.00402  -0.001578  0.01962 ] ...(size = 59136 end with -0.421630859375, sum = -734.5)
/text_model/encoder/layers.4/self_attn/q_proj/MatMul_output_0
[-0.637     0.003887 -0.05075   0.04813   0.3872    0.11096  -0.005096
  0.1902   -0.1498   -0.00753 ] ...(size = 59136 end with -2.421875, sum = 693.0)
/text_model/encoder/layers.4/self_attn/q_proj/Add_output_0
[ 0.4995   -0.1171    0.09174   0.10846   0.0968   -0.013374 -0.202
 -0.1482    0.01636   0.11426 ] ...(size = 59136 end with -4.62890625, sum = 1812.0)
/text_model/encoder/layers.4/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.4/self_attn/Mul_output_0
[ 0.06244  -0.01464   0.01147   0.01356   0.0121   -0.001672 -0.02525
 -0.01852   0.002045  0.01428 ] ...(size = 59136 end with -0.57861328125, sum = 226.5)
/text_model/encoder/layers.4/self_attn/k_proj/MatMul_output_0
[ 1.466   -0.1613   0.1329   0.137   -0.0381  -0.06976 -0.2281  -0.2172
  0.0384   0.02397] ...(size = 59136 end with 1.642578125, sum = -919.0)
/text_model/encoder/layers.4/self_attn/k_proj/Add_output_0
[ 1.457   -0.162    0.1316   0.1365  -0.04178 -0.07166 -0.2303  -0.212
  0.03287  0.02576] ...(size = 59136 end with 1.6201171875, sum = -901.5)
/text_model/encoder/layers.4/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.4/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.4/self_attn/Reshape_output_0
[ 1.457   -0.162    0.1316   0.1365  -0.04178 -0.07166 -0.2303  -0.212
  0.03287  0.02576] ...(size = 59136 end with 1.6201171875, sum = -901.5)
/text_model/encoder/layers.4/self_attn/Transpose_output_0
[ 1.457   -0.162    0.1316   0.1365  -0.04178 -0.07166 -0.2303  -0.212
  0.03287  0.02576] ...(size = 59136 end with 1.6201171875, sum = -901.5)
/text_model/encoder/layers.4/self_attn/v_proj/MatMul_output_0
[-0.01192   0.00211   0.0473   -0.0259   -0.013985 -0.03079  -0.01282
 -0.003918 -0.0329   -0.03305 ] ...(size = 59136 end with -0.499755859375, sum = 706.0)
/text_model/encoder/layers.4/self_attn/v_proj/Add_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.51708984375, sum = 744.5)
/text_model/encoder/layers.4/self_attn/Reshape_1_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.51708984375, sum = 744.5)
/text_model/encoder/layers.4/self_attn/Transpose_1_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.51708984375, sum = 744.5)
/text_model/encoder/layers.4/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.4/self_attn/Reshape_2_output_0
[ 0.06244  -0.01464   0.01147   0.01356   0.0121   -0.001672 -0.02525
 -0.01852   0.002045  0.01428 ] ...(size = 59136 end with -0.57861328125, sum = 226.5)
/text_model/encoder/layers.4/self_attn/Transpose_2_output_0
[ 0.06244  -0.01464   0.01147   0.01356   0.0121   -0.001672 -0.02525
 -0.01852   0.002045  0.01428 ] ...(size = 59136 end with -0.57861328125, sum = 226.5)
/text_model/encoder/layers.4/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Reshape_3_output_0
[ 0.06244  -0.01464   0.01147   0.01356   0.0121   -0.001672 -0.02525
 -0.01852   0.002045  0.01428 ] ...(size = 59136 end with -0.57861328125, sum = 226.5)
/text_model/encoder/layers.4/self_attn/Reshape_4_output_0
[ 1.457   -0.162    0.1316   0.1365  -0.04178 -0.07166 -0.2303  -0.212
  0.03287  0.02576] ...(size = 59136 end with 1.6201171875, sum = -901.5)
/text_model/encoder/layers.4/self_attn/Reshape_5_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.51708984375, sum = 744.5)
/text_model/encoder/layers.4/self_attn/Transpose_3_output_0
[ 1.457 -3.705 -2.031 -1.161 -1.584 -1.935 -1.332 -1.598 -3.258 -1.304] ...(size = 59136 end with 1.6201171875, sum = -903.5)
/text_model/encoder/layers.4/self_attn/MatMul_output_0
[ 0.4644  -0.433   -0.359   -0.12415 -0.2659  -0.4905  -0.364   -0.08813
 -0.8535  -0.3335 ] ...(size = 71148 end with -3.38671875, sum = -inf)
/text_model/encoder/layers.4/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.4/self_attn/Reshape_6_output_0
[ 0.4644  -0.433   -0.359   -0.12415 -0.2659  -0.4905  -0.364   -0.08813
 -0.8535  -0.3335 ] ...(size = 71148 end with -3.38671875, sum = -inf)
/text_model/encoder/layers.4/self_attn/Add_output_0
[ 4.644e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -3.38671875, sum = -inf)
/text_model/encoder/layers.4/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.4/self_attn/Reshape_7_output_0
[ 4.644e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -3.38671875, sum = -inf)
/text_model/encoder/layers.4/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0031795501708984375, sum = 924.0)
/text_model/encoder/layers.4/self_attn/MatMul_1_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.105224609375, sum = -41.59375)
/text_model/encoder/layers.4/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.4/self_attn/Reshape_8_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.105224609375, sum = -41.59375)
/text_model/encoder/layers.4/self_attn/Transpose_4_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.105224609375, sum = -41.59375)
/text_model/encoder/layers.4/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.4/self_attn/Reshape_9_output_0
[-0.01688  -0.01907   0.0681    0.000747 -0.03091  -0.04593   0.006794
  0.0081   -0.00663  -0.01398 ] ...(size = 59136 end with -0.105224609375, sum = -41.59375)
/text_model/encoder/layers.4/self_attn/out_proj/MatMul_output_0
[ 0.02573   0.02675   0.0236   -0.004303  0.04214  -0.00437   0.02556
  0.0164    0.006733  0.01833 ] ...(size = 59136 end with -0.0439453125, sum = -7.578125)
/text_model/encoder/layers.4/self_attn/out_proj/Add_output_0
[ 0.02122   0.02785  -0.00988  -0.01703  -0.02492   0.06274   0.0943
  0.000992  0.04694   0.0516  ] ...(size = 59136 end with -0.00470733642578125, sum = 35.40625)
/text_model/encoder/layers.4/Add_output_0
[-3.912  -2.69    4.766   0.7886 -1.281  -4.547  -2.188  -2.39    3.773
  0.326 ] ...(size = 59136 end with -0.0509033203125, sum = 189.875)
/text_model/encoder/layers.4/layer_norm2/ReduceMean_output_0
[-0.01933   0.01086   0.00536   0.007626  0.00758   0.002132  0.003778
  0.00847   0.002508  0.006283] ...(size = 77 end with 0.0028076171875, sum = 0.2471923828125)
/text_model/encoder/layers.4/layer_norm2/Sub_output_0
[-3.895  -2.67    4.785   0.808  -1.262  -4.527  -2.168  -2.371   3.793
  0.3452] ...(size = 59136 end with -0.0537109375, sum = 0.056671142578125)
/text_model/encoder/layers.4/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.4/layer_norm2/Pow_output_0
[15.164   7.133  22.89    0.6533  1.593  20.5     4.703   5.62   14.38
  0.1192] ...(size = 59136 end with 0.0028839111328125, sum = inf)
/text_model/encoder/layers.4/layer_norm2/ReduceMean_1_output_0
[1.835e+03 8.582e-02 6.732e-02 7.587e-02 6.348e-02 6.622e-02 7.599e-02
 1.058e-01 6.757e-02 7.135e-02] ...(size = 77 end with 0.0290985107421875, sum = 1838.0)
/text_model/encoder/layers.4/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.4/layer_norm2/Add_output_0
[1.835e+03 8.582e-02 6.732e-02 7.587e-02 6.348e-02 6.622e-02 7.599e-02
 1.058e-01 6.757e-02 7.135e-02] ...(size = 77 end with 0.0290985107421875, sum = 1838.0)
/text_model/encoder/layers.4/layer_norm2/Sqrt_output_0
[42.84    0.293   0.2595  0.2754  0.252   0.2573  0.2756  0.3252  0.26
  0.267 ] ...(size = 77 end with 0.170654296875, sum = 56.8125)
/text_model/encoder/layers.4/layer_norm2/Div_output_0
[-0.0909   -0.06235   0.1117    0.01886  -0.02946  -0.1057   -0.05063
 -0.05536   0.08856   0.008064] ...(size = 59136 end with -0.314697265625, sum = -0.0153656005859375)
/text_model/encoder/layers.4/layer_norm2/Mul_output_0
[-0.1953  -0.1294   0.2448   0.03857 -0.0601  -0.2267  -0.11487 -0.11755
  0.1901   0.01765] ...(size = 59136 end with -0.71728515625, sum = -1721.0)
/text_model/encoder/layers.4/layer_norm2/Add_1_output_0
[-0.6     0.3745 -0.3762  0.229  -0.991   0.2101  0.513  -0.1255 -0.666
 -0.2852] ...(size = 59136 end with -0.1021728515625, sum = -224.0)
/text_model/encoder/layers.4/mlp/fc1/MatMul_output_0
[-1.335  -1.252  -1.641  -2.457  -1.936  -0.8496 -2.28   -0.7715 -2.05
 -1.343 ] ...(size = 236544 end with -1.662109375, sum = -inf)
/text_model/encoder/layers.4/mlp/fc1/Add_output_0
[-1.656  -1.223  -1.924  -2.787  -2.27   -0.9053 -2.531  -0.8984 -2.414
 -1.714 ] ...(size = 236544 end with -1.982421875, sum = -inf)
/text_model/encoder/layers.4/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.4/mlp/activation_fn/Mul_output_0
[-2.818 -2.08  -3.273 -4.742 -3.863 -1.541 -4.31  -1.529 -4.11  -2.918] ...(size = 236544 end with -3.373046875, sum = -inf)
/text_model/encoder/layers.4/mlp/activation_fn/Sigmoid_output_0
[0.05634 0.111   0.03647 0.00863 0.02057 0.1764  0.01326 0.1781  0.01616
 0.05127] ...(size = 236544 end with 0.033111572265625, sum = 16248.0)
/text_model/encoder/layers.4/mlp/activation_fn/Mul_1_output_0
[-0.09326 -0.1356  -0.0701  -0.02405 -0.0467  -0.1597  -0.03357 -0.16
 -0.039   -0.0879 ] ...(size = 236544 end with -0.065673828125, sum = -15128.0)
/text_model/encoder/layers.4/mlp/fc2/MatMul_output_0
[-0.0635   0.00835  0.08844  0.01764  0.1115  -0.2206  -0.1108   0.11835
 -0.1475   0.07184] ...(size = 59136 end with 0.050018310546875, sum = -15.7421875)
/text_model/encoder/layers.4/mlp/fc2/Add_output_0
[-0.01729  0.0668   0.03705  0.03577  0.097   -0.1053  -0.0379   0.1034
 -0.0956   0.0484 ] ...(size = 59136 end with 0.090576171875, sum = 1.5927734375)
/text_model/encoder/layers.4/Add_1_output_0
[-3.93   -2.623   4.8     0.8247 -1.185  -4.652  -2.227  -2.287   3.678
  0.3743] ...(size = 59136 end with 0.039703369140625, sum = 191.375)
/text_model/encoder/layers.5/layer_norm1/ReduceMean_output_0
[-0.01935   0.010574  0.00531   0.007656  0.007576  0.002039  0.00417
  0.0097    0.001899  0.00746 ] ...(size = 77 end with 0.002788543701171875, sum = 0.249267578125)
/text_model/encoder/layers.5/layer_norm1/Sub_output_0
[-3.91   -2.604   4.82    0.8438 -1.165  -4.633  -2.207  -2.268   3.697
  0.3938] ...(size = 59136 end with 0.03692626953125, sum = -0.1968994140625)
/text_model/encoder/layers.5/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.5/layer_norm1/Pow_output_0
[15.3     6.777  23.25    0.7124  1.357  21.47    4.867   5.145  13.67
  0.155 ] ...(size = 59136 end with 0.0013628005981445312, sum = inf)
/text_model/encoder/layers.5/layer_norm1/ReduceMean_1_output_0
[1.834e+03 8.716e-02 7.892e-02 8.051e-02 6.628e-02 8.771e-02 9.961e-02
 1.188e-01 8.600e-02 7.269e-02] ...(size = 77 end with 0.02789306640625, sum = 1837.0)
/text_model/encoder/layers.5/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.5/layer_norm1/Add_output_0
[1.834e+03 8.716e-02 7.892e-02 8.051e-02 6.628e-02 8.777e-02 9.961e-02
 1.188e-01 8.600e-02 7.275e-02] ...(size = 77 end with 0.02789306640625, sum = 1837.0)
/text_model/encoder/layers.5/layer_norm1/Sqrt_output_0
[42.8     0.2952  0.281   0.2837  0.2576  0.2961  0.3157  0.3447  0.2932
  0.2698] ...(size = 77 end with 0.1669921875, sum = 56.46875)
/text_model/encoder/layers.5/layer_norm1/Div_output_0
[-0.0913  -0.0608   0.1126   0.01971 -0.0272  -0.1082  -0.0515  -0.05295
  0.08636  0.00919] ...(size = 59136 end with 0.2210693359375, sum = 0.062408447265625)
/text_model/encoder/layers.5/layer_norm1/Mul_output_0
[-0.1313   -0.0942    0.1626    0.0283   -0.03998  -0.173    -0.07623
 -0.0792    0.13      0.013054] ...(size = 59136 end with 0.317138671875, sum = -956.0)
/text_model/encoder/layers.5/layer_norm1/Add_1_output_0
[-0.03635  -0.03192   0.05173   0.00971   0.0407   -0.03687  -0.007195
 -0.04227  -0.00561   0.01039 ] ...(size = 59136 end with 0.282470703125, sum = -823.0)
/text_model/encoder/layers.5/self_attn/q_proj/MatMul_output_0
[ 0.11237 -0.2091   0.1675  -0.037    0.01466  0.1608   0.4539  -0.2394
  0.267   -0.02846] ...(size = 59136 end with 0.474853515625, sum = 1567.0)
/text_model/encoder/layers.5/self_attn/q_proj/Add_output_0
[-0.2087   0.02164  0.11993 -0.11523  0.1979   0.01461 -0.1251  -0.1425
  0.2686  -0.5117 ] ...(size = 59136 end with 0.315185546875, sum = 2822.0)
/text_model/encoder/layers.5/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.5/self_attn/Mul_output_0
[-0.0261    0.002705  0.01499  -0.014404  0.02473   0.001826 -0.01564
 -0.0178    0.03357  -0.06396 ] ...(size = 59136 end with 0.039398193359375, sum = 352.75)
/text_model/encoder/layers.5/self_attn/k_proj/MatMul_output_0
[-0.2428   0.1646  -0.0389  -0.01701  0.04276 -0.1316  -0.51     0.07513
  0.0374  -0.3318 ] ...(size = 59136 end with 2.28515625, sum = -876.5)
/text_model/encoder/layers.5/self_attn/k_proj/Add_output_0
[-0.2463   0.1666  -0.03696 -0.017    0.04504 -0.1328  -0.512    0.07764
  0.03696 -0.3276 ] ...(size = 59136 end with 2.283203125, sum = -880.0)
/text_model/encoder/layers.5/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.5/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.5/self_attn/Reshape_output_0
[-0.2463   0.1666  -0.03696 -0.017    0.04504 -0.1328  -0.512    0.07764
  0.03696 -0.3276 ] ...(size = 59136 end with 2.283203125, sum = -880.0)
/text_model/encoder/layers.5/self_attn/Transpose_output_0
[-0.2463   0.1666  -0.03696 -0.017    0.04504 -0.1328  -0.512    0.07764
  0.03696 -0.3276 ] ...(size = 59136 end with 2.283203125, sum = -880.0)
/text_model/encoder/layers.5/self_attn/v_proj/MatMul_output_0
[-0.0001663  0.0793    -0.002537  -0.03098   -0.09235    0.00693
 -0.04886   -0.0004106  0.04004    0.03357  ] ...(size = 59136 end with -0.4990234375, sum = 709.5)
/text_model/encoder/layers.5/self_attn/v_proj/Add_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.5126953125, sum = 698.5)
/text_model/encoder/layers.5/self_attn/Reshape_1_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.5126953125, sum = 698.5)
/text_model/encoder/layers.5/self_attn/Transpose_1_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.5126953125, sum = 698.5)
/text_model/encoder/layers.5/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.5/self_attn/Reshape_2_output_0
[-0.0261    0.002705  0.01499  -0.014404  0.02473   0.001826 -0.01564
 -0.0178    0.03357  -0.06396 ] ...(size = 59136 end with 0.039398193359375, sum = 352.75)
/text_model/encoder/layers.5/self_attn/Transpose_2_output_0
[-0.0261    0.002705  0.01499  -0.014404  0.02473   0.001826 -0.01564
 -0.0178    0.03357  -0.06396 ] ...(size = 59136 end with 0.039398193359375, sum = 352.75)
/text_model/encoder/layers.5/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Reshape_3_output_0
[-0.0261    0.002705  0.01499  -0.014404  0.02473   0.001826 -0.01564
 -0.0178    0.03357  -0.06396 ] ...(size = 59136 end with 0.039398193359375, sum = 352.75)
/text_model/encoder/layers.5/self_attn/Reshape_4_output_0
[-0.2463   0.1666  -0.03696 -0.017    0.04504 -0.1328  -0.512    0.07764
  0.03696 -0.3276 ] ...(size = 59136 end with 2.283203125, sum = -880.0)
/text_model/encoder/layers.5/self_attn/Reshape_5_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.5126953125, sum = 698.5)
/text_model/encoder/layers.5/self_attn/Transpose_3_output_0
[-0.2463   1.9375   0.643    1.957    1.438   -0.05072  1.567    1.519
  0.311    1.174  ] ...(size = 59136 end with 2.283203125, sum = -880.5)
/text_model/encoder/layers.5/self_attn/MatMul_output_0
[ 0.609  -0.6973 -0.692  -0.56   -0.8877 -0.83   -1.08   -1.043  -1.206
 -1.2705] ...(size = 71148 end with -4.83203125, sum = -inf)
/text_model/encoder/layers.5/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.5/self_attn/Reshape_6_output_0
[ 0.609  -0.6973 -0.692  -0.56   -0.8877 -0.83   -1.08   -1.043  -1.206
 -1.2705] ...(size = 71148 end with -4.83203125, sum = -inf)
/text_model/encoder/layers.5/self_attn/Add_output_0
[ 6.09e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -4.83203125, sum = -inf)
/text_model/encoder/layers.5/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.5/self_attn/Reshape_7_output_0
[ 6.09e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -4.83203125, sum = -inf)
/text_model/encoder/layers.5/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0008301734924316406, sum = 924.0)
/text_model/encoder/layers.5/self_attn/MatMul_1_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.06982421875, sum = 99.8125)
/text_model/encoder/layers.5/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.5/self_attn/Reshape_8_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.06982421875, sum = 99.8125)
/text_model/encoder/layers.5/self_attn/Transpose_4_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.06982421875, sum = 100.0)
/text_model/encoder/layers.5/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.5/self_attn/Reshape_9_output_0
[ 0.01102   0.04166   0.005665 -0.00887  -0.03586  -0.004627 -0.0246
 -0.00623   0.03004   0.00678 ] ...(size = 59136 end with -0.06982421875, sum = 100.0)
/text_model/encoder/layers.5/self_attn/out_proj/MatMul_output_0
[-0.001359  0.02394   0.0194   -0.00433  -0.02261  -0.0533    0.00858
  0.03598  -0.0443   -0.02963 ] ...(size = 59136 end with 0.1007080078125, sum = 18.53125)
/text_model/encoder/layers.5/self_attn/out_proj/Add_output_0
[ 0.0276    0.03674   0.02878  -0.00879  -0.05194  -0.066    -0.006237
 -0.02306  -0.0669    0.012085] ...(size = 59136 end with 0.10943603515625, sum = 49.25)
/text_model/encoder/layers.5/Add_output_0
[-3.902  -2.586   4.832   0.816  -1.236  -4.72   -2.232  -2.31    3.611
  0.3865] ...(size = 59136 end with 0.149169921875, sum = 240.25)
/text_model/encoder/layers.5/layer_norm2/ReduceMean_output_0
[-0.0189    0.011024  0.005768  0.008125  0.00804   0.002462  0.004696
  0.009995  0.003206  0.00824 ] ...(size = 77 end with 0.00399017333984375, sum = 0.313232421875)
/text_model/encoder/layers.5/layer_norm2/Sub_output_0
[-3.885  -2.566   4.85    0.8345 -1.218  -4.7    -2.213  -2.291   3.629
  0.4053] ...(size = 59136 end with 0.1451416015625, sum = -0.35302734375)
/text_model/encoder/layers.5/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.5/layer_norm2/Pow_output_0
[15.086   6.59   23.53    0.697   1.481  22.1     4.9     5.25   13.17
  0.1643] ...(size = 59136 end with 0.02105712890625, sum = inf)
/text_model/encoder/layers.5/layer_norm2/ReduceMean_1_output_0
[1.8340e+03 9.0881e-02 8.1909e-02 8.1421e-02 6.7932e-02 9.1125e-02
 1.0254e-01 1.3940e-01 9.3811e-02 7.8491e-02] ...(size = 77 end with 0.0389404296875, sum = 1837.0)
/text_model/encoder/layers.5/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.5/layer_norm2/Add_output_0
[1.8340e+03 9.0942e-02 8.1909e-02 8.1421e-02 6.7932e-02 9.1125e-02
 1.0254e-01 1.3940e-01 9.3811e-02 7.8491e-02] ...(size = 77 end with 0.0389404296875, sum = 1837.0)
/text_model/encoder/layers.5/layer_norm2/Sqrt_output_0
[42.8     0.3015  0.2861  0.2854  0.2607  0.302   0.3203  0.3733  0.3064
  0.2803] ...(size = 77 end with 0.1973876953125, sum = 58.59375)
/text_model/encoder/layers.5/layer_norm2/Div_output_0
[-0.0907  -0.05994  0.1133   0.01949 -0.02843 -0.10974 -0.05167 -0.0535
  0.0848   0.00947] ...(size = 59136 end with 0.7353515625, sum = 0.005062103271484375)
/text_model/encoder/layers.5/layer_norm2/Mul_output_0
[-0.1932  -0.1257   0.2454   0.0406  -0.05103 -0.237   -0.1138  -0.11194
  0.1893   0.0204 ] ...(size = 59136 end with 1.6904296875, sum = -1994.0)
/text_model/encoder/layers.5/layer_norm2/Add_1_output_0
[-0.1382  0.2161 -0.3538  0.098  -0.6436  0.384   0.609  -0.4954  0.72
 -0.3245] ...(size = 59136 end with 2.3359375, sum = -2544.0)
/text_model/encoder/layers.5/mlp/fc1/MatMul_output_0
[-1.458  -1.552  -1.57   -2.205  -1.541  -1.492  -0.5215 -1.933  -0.793
 -1.491 ] ...(size = 236544 end with -0.7236328125, sum = -inf)
/text_model/encoder/layers.5/mlp/fc1/Add_output_0
[-1.832  -1.96   -1.888  -2.469  -1.801  -1.865  -0.3318 -2.297  -0.8906
 -1.782 ] ...(size = 236544 end with -1.0341796875, sum = -inf)
/text_model/encoder/layers.5/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.5/mlp/activation_fn/Mul_output_0
[-3.12  -3.336 -3.213 -4.203 -3.064 -3.174 -0.565 -3.908 -1.516 -3.033] ...(size = 236544 end with -1.7607421875, sum = -inf)
/text_model/encoder/layers.5/mlp/activation_fn/Sigmoid_output_0
[0.04233 0.03433 0.0387  0.01472 0.0446  0.04016 0.3625  0.01967 0.18
 0.04593] ...(size = 236544 end with 0.146728515625, sum = 24832.0)
/text_model/encoder/layers.5/mlp/activation_fn/Mul_1_output_0
[-0.0776  -0.0673  -0.073   -0.03635 -0.08026 -0.0749  -0.12024 -0.04517
 -0.1604  -0.08185] ...(size = 236544 end with -0.1517333984375, sum = -18640.0)
/text_model/encoder/layers.5/mlp/fc2/MatMul_output_0
[-0.06247  -0.2095    0.0437    0.0116   -0.007248 -0.1411    0.04297
  0.11505   0.1677   -0.04672 ] ...(size = 59136 end with -0.11163330078125, sum = -15.4375)
/text_model/encoder/layers.5/mlp/fc2/Add_output_0
[-0.0084  -0.07935 -0.01429  0.02731  0.02547 -0.04556  0.05576  0.04758
  0.0424  -0.04056] ...(size = 59136 end with -0.01641845703125, sum = -5.27734375)
/text_model/encoder/layers.5/Add_1_output_0
[-3.912  -2.666   4.816   0.8433 -1.211  -4.766  -2.176  -2.262   3.652
  0.346 ] ...(size = 59136 end with 0.1326904296875, sum = 235.75)
/text_model/encoder/layers.6/layer_norm1/ReduceMean_output_0
[-0.019     0.011154  0.0065    0.00914   0.009     0.002905  0.00526
  0.010475  0.00261   0.00875 ] ...(size = 77 end with 0.0037746429443359375, sum = 0.306396484375)
/text_model/encoder/layers.6/layer_norm1/Sub_output_0
[-3.893  -2.646   4.836   0.8623 -1.191  -4.746  -2.156  -2.244   3.672
  0.3647] ...(size = 59136 end with 0.12890625, sum = 0.265380859375)
/text_model/encoder/layers.6/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.6/layer_norm1/Pow_output_0
[15.15    7.004  23.39    0.743   1.42   22.52    4.652   5.035  13.484
  0.1332] ...(size = 59136 end with 0.0166168212890625, sum = inf)
/text_model/encoder/layers.6/layer_norm1/ReduceMean_1_output_0
[1.8340e+03 8.8440e-02 9.9609e-02 8.4961e-02 7.7393e-02 1.1816e-01
 1.1176e-01 1.3098e-01 1.0767e-01 7.7820e-02] ...(size = 77 end with 0.040069580078125, sum = 1838.0)
/text_model/encoder/layers.6/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.6/layer_norm1/Add_output_0
[1.8340e+03 8.8501e-02 9.9670e-02 8.4961e-02 7.7454e-02 1.1816e-01
 1.1176e-01 1.3098e-01 1.0767e-01 7.7820e-02] ...(size = 77 end with 0.040069580078125, sum = 1838.0)
/text_model/encoder/layers.6/layer_norm1/Sqrt_output_0
[42.8     0.2974  0.3157  0.2915  0.2783  0.3438  0.3342  0.362   0.3281
  0.279 ] ...(size = 77 end with 0.2001953125, sum = 58.84375)
/text_model/encoder/layers.6/layer_norm1/Div_output_0
[-0.0909  -0.0618   0.1129   0.02013 -0.02783 -0.11084 -0.05038 -0.0524
  0.08575  0.00852] ...(size = 59136 end with 0.64404296875, sum = 0.1123046875)
/text_model/encoder/layers.6/layer_norm1/Mul_output_0
[-0.142   -0.10065  0.1709   0.0317  -0.04514 -0.1749  -0.08    -0.0825
  0.138    0.01362] ...(size = 59136 end with 1.021484375, sum = -1360.0)
/text_model/encoder/layers.6/layer_norm1/Add_1_output_0
[-0.03793 -0.00363  0.01484  0.02344  0.05716 -0.03387  0.02298 -0.02827
 -0.02856  0.00485] ...(size = 59136 end with 1.0283203125, sum = -1144.0)
/text_model/encoder/layers.6/self_attn/q_proj/MatMul_output_0
[ 0.03004 -0.00822  0.05966  0.2634  -0.11426  0.01004 -0.2056   0.0529
 -0.0582   0.0883 ] ...(size = 59136 end with 0.3955078125, sum = 2920.0)
/text_model/encoder/layers.6/self_attn/q_proj/Add_output_0
[ 0.15    -0.1372   0.2573   0.01909 -0.0586  -0.1965  -0.0784   0.2942
  0.0375   0.1621 ] ...(size = 59136 end with 0.464111328125, sum = 3978.0)
/text_model/encoder/layers.6/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.6/self_attn/Mul_output_0
[ 0.01875  -0.01715   0.03217   0.002386 -0.007324 -0.02457  -0.0098
  0.03677   0.00469   0.02026 ] ...(size = 59136 end with 0.058013916015625, sum = 497.25)
/text_model/encoder/layers.6/self_attn/k_proj/MatMul_output_0
[ 0.07306  -0.06238   0.164    -0.18      0.0898   -0.0608   -0.0734
  0.1625    0.005714  0.002718] ...(size = 59136 end with 1.443359375, sum = -3674.0)
/text_model/encoder/layers.6/self_attn/k_proj/Add_output_0
[ 0.0794   -0.0597    0.1582   -0.1738    0.0884   -0.0594   -0.0736
  0.1564    0.00926  -0.002241] ...(size = 59136 end with 1.447265625, sum = -3698.0)
/text_model/encoder/layers.6/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.6/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.6/self_attn/Reshape_output_0
[ 0.0794   -0.0597    0.1582   -0.1738    0.0884   -0.0594   -0.0736
  0.1564    0.00926  -0.002241] ...(size = 59136 end with 1.447265625, sum = -3698.0)
/text_model/encoder/layers.6/self_attn/Transpose_output_0
[ 0.0794   -0.0597    0.1582   -0.1738    0.0884   -0.0594   -0.0736
  0.1564    0.00926  -0.002241] ...(size = 59136 end with 1.447265625, sum = -3702.0)
/text_model/encoder/layers.6/self_attn/v_proj/MatMul_output_0
[-0.04987  -0.01374  -0.003803 -0.06216  -0.03528   0.0634    0.04947
 -0.05676   0.006847  0.04053 ] ...(size = 59136 end with -0.71875, sum = -758.5)
/text_model/encoder/layers.6/self_attn/v_proj/Add_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.72509765625, sum = -639.0)
/text_model/encoder/layers.6/self_attn/Reshape_1_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.72509765625, sum = -639.0)
/text_model/encoder/layers.6/self_attn/Transpose_1_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.72509765625, sum = -638.5)
/text_model/encoder/layers.6/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.6/self_attn/Reshape_2_output_0
[ 0.01875  -0.01715   0.03217   0.002386 -0.007324 -0.02457  -0.0098
  0.03677   0.00469   0.02026 ] ...(size = 59136 end with 0.058013916015625, sum = 497.25)
/text_model/encoder/layers.6/self_attn/Transpose_2_output_0
[ 0.01875  -0.01715   0.03217   0.002386 -0.007324 -0.02457  -0.0098
  0.03677   0.00469   0.02026 ] ...(size = 59136 end with 0.058013916015625, sum = 497.25)
/text_model/encoder/layers.6/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Reshape_3_output_0
[ 0.01875  -0.01715   0.03217   0.002386 -0.007324 -0.02457  -0.0098
  0.03677   0.00469   0.02026 ] ...(size = 59136 end with 0.058013916015625, sum = 497.25)
/text_model/encoder/layers.6/self_attn/Reshape_4_output_0
[ 0.0794   -0.0597    0.1582   -0.1738    0.0884   -0.0594   -0.0736
  0.1564    0.00926  -0.002241] ...(size = 59136 end with 1.447265625, sum = -3702.0)
/text_model/encoder/layers.6/self_attn/Reshape_5_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.72509765625, sum = -638.5)
/text_model/encoder/layers.6/self_attn/Transpose_3_output_0
[ 0.0794   1.0625  -0.595   -0.1976   0.00963 -1.305   -0.7495   0.3047
 -1.783   -0.9673 ] ...(size = 59136 end with 1.447265625, sum = -3700.0)
/text_model/encoder/layers.6/self_attn/MatMul_output_0
[ 0.4475 -0.635  -0.7275 -1.023  -0.8857 -0.334  -0.537  -0.6187 -0.683
 -0.6704] ...(size = 71148 end with -4.50390625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.6/self_attn/Reshape_6_output_0
[ 0.4475 -0.635  -0.7275 -1.023  -0.8857 -0.334  -0.537  -0.6187 -0.683
 -0.6704] ...(size = 71148 end with -4.50390625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Add_output_0
[ 4.475e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.50390625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.6/self_attn/Reshape_7_output_0
[ 4.475e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.50390625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0023975372314453125, sum = 924.0)
/text_model/encoder/layers.6/self_attn/MatMul_1_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.15087890625, sum = -262.5)
/text_model/encoder/layers.6/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.6/self_attn/Reshape_8_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.15087890625, sum = -262.5)
/text_model/encoder/layers.6/self_attn/Transpose_4_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.15087890625, sum = -262.5)
/text_model/encoder/layers.6/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.6/self_attn/Reshape_9_output_0
[-0.02275   -0.01251    0.0005302 -0.02103   -0.01493    0.0564
  0.02946   -0.02966    0.01123    0.02786  ] ...(size = 59136 end with -0.15087890625, sum = -262.5)
/text_model/encoder/layers.6/self_attn/out_proj/MatMul_output_0
[-0.02545    0.0003433  0.02292   -0.003393   0.001038  -0.014244
  0.0253     0.01775    0.02112    0.00693  ] ...(size = 59136 end with -0.0712890625, sum = -8.359375)
/text_model/encoder/layers.6/self_attn/out_proj/Add_output_0
[-0.0046  -0.02028 -0.0274  -0.01924  0.01971 -0.02284  0.04224 -0.02504
 -0.00986  0.03583] ...(size = 59136 end with -0.10174560546875, sum = 28.609375)
/text_model/encoder/layers.6/Add_output_0
[-3.916  -2.686   4.79    0.8237 -1.191  -4.785  -2.135  -2.287   3.643
  0.3816] ...(size = 59136 end with 0.0309600830078125, sum = 263.75)
/text_model/encoder/layers.6/layer_norm2/ReduceMean_output_0
[-0.01825   0.01192   0.007225  0.00974   0.00966   0.003641  0.005917
  0.01025   0.003153  0.0089  ] ...(size = 77 end with 0.004299163818359375, sum = 0.34375)
/text_model/encoder/layers.6/layer_norm2/Sub_output_0
[-3.898  -2.668   4.81    0.8423 -1.173  -4.77   -2.115  -2.27    3.662
  0.4   ] ...(size = 59136 end with 0.0266571044921875, sum = -0.451416015625)
/text_model/encoder/layers.6/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.6/layer_norm2/Pow_output_0
[15.19    7.117  23.11    0.709   1.375  22.73    4.477   5.152  13.41
  0.1599] ...(size = 59136 end with 0.0007104873657226562, sum = inf)
/text_model/encoder/layers.6/layer_norm2/ReduceMean_1_output_0
[1.8340e+03 9.4177e-02 1.0406e-01 9.2651e-02 8.2458e-02 1.2067e-01
 1.1578e-01 1.8103e-01 1.1462e-01 1.4062e-01] ...(size = 77 end with 0.057342529296875, sum = 1839.0)
/text_model/encoder/layers.6/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.6/layer_norm2/Add_output_0
[1.8340e+03 9.4177e-02 1.0406e-01 9.2651e-02 8.2520e-02 1.2067e-01
 1.1584e-01 1.8103e-01 1.1462e-01 1.4062e-01] ...(size = 77 end with 0.057342529296875, sum = 1839.0)
/text_model/encoder/layers.6/layer_norm2/Sqrt_output_0
[42.8     0.307   0.3225  0.3044  0.287   0.3474  0.3403  0.4255  0.3386
  0.375 ] ...(size = 77 end with 0.239501953125, sum = 62.75)
/text_model/encoder/layers.6/layer_norm2/Div_output_0
[-0.091   -0.0623   0.11224  0.01967 -0.02739 -0.1113  -0.0494  -0.05298
  0.0855   0.00934] ...(size = 59136 end with 0.111328125, sum = 0.031402587890625)
/text_model/encoder/layers.6/layer_norm2/Mul_output_0
[-0.1998  -0.1398   0.2454   0.04172 -0.0449  -0.2434  -0.10693 -0.121
  0.1892   0.0207 ] ...(size = 59136 end with 0.261474609375, sum = -2224.0)
/text_model/encoder/layers.6/layer_norm2/Add_1_output_0
[-0.06696  0.909   -0.1946  -0.309   -0.2023  -0.1387   0.2393  -0.4817
 -0.342   -0.09436] ...(size = 59136 end with 1.3232421875, sum = -2162.0)
/text_model/encoder/layers.6/mlp/fc1/MatMul_output_0
[-0.3057 -1.797  -2.139  -1.34   -1.785  -1.82   -1.828  -1.74   -2.072
 -1.113 ] ...(size = 236544 end with -0.1229248046875, sum = -inf)
/text_model/encoder/layers.6/mlp/fc1/Add_output_0
[-0.6016 -2.127  -2.488  -1.594  -2.123  -2.174  -2.182  -2.078  -2.373
 -1.461 ] ...(size = 236544 end with -0.4580078125, sum = -inf)
/text_model/encoder/layers.6/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.6/mlp/activation_fn/Mul_output_0
[-1.023 -3.62  -4.234 -2.713 -3.613 -3.7   -3.715 -3.537 -4.04  -2.486] ...(size = 236544 end with -0.77978515625, sum = -inf)
/text_model/encoder/layers.6/mlp/activation_fn/Sigmoid_output_0
[0.2644  0.02611 0.01429 0.0622  0.02625 0.02415 0.0238  0.02824 0.01727
 0.0768 ] ...(size = 236544 end with 0.314453125, sum = 21920.0)
/text_model/encoder/layers.6/mlp/activation_fn/Mul_1_output_0
[-0.1589  -0.0555  -0.03555 -0.0992  -0.05573 -0.0525  -0.05194 -0.05872
 -0.04102 -0.1122 ] ...(size = 236544 end with -0.14404296875, sum = -16248.0)
/text_model/encoder/layers.6/mlp/fc2/MatMul_output_0
[-0.0751    0.1018    0.1957   -0.02463  -0.0956   -0.2129   -0.0835
  0.0737    0.003391 -0.02335 ] ...(size = 59136 end with 0.036865234375, sum = 32.65625)
/text_model/encoder/layers.6/mlp/fc2/Add_output_0
[ 0.00134   0.1412    0.05832   0.0335   -0.05597  -0.1387   -0.02641
  0.07007  -0.002762 -0.01125 ] ...(size = 59136 end with 0.055023193359375, sum = 53.9375)
/text_model/encoder/layers.6/Add_1_output_0
[-3.914  -2.545   4.848   0.8574 -1.247  -4.926  -2.16   -2.217   3.64
  0.3704] ...(size = 59136 end with 0.08599853515625, sum = 318.25)
/text_model/encoder/layers.7/layer_norm1/ReduceMean_output_0
[-0.01776   0.01282   0.007603  0.01049   0.01096   0.004215  0.00638
  0.01274   0.004303  0.009865] ...(size = 77 end with 0.005092620849609375, sum = 0.413818359375)
/text_model/encoder/layers.7/layer_norm1/Sub_output_0
[-3.896  -2.527   4.867   0.875  -1.2295 -4.906  -2.143  -2.2     3.658
  0.3882] ...(size = 59136 end with 0.08087158203125, sum = 0.1929931640625)
/text_model/encoder/layers.7/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.7/layer_norm1/Pow_output_0
[15.19    6.387  23.67    0.7656  1.511  24.1     4.59    4.84   13.38
  0.1508] ...(size = 59136 end with 0.006542205810546875, sum = inf)
/text_model/encoder/layers.7/layer_norm1/ReduceMean_1_output_0
[1.8330e+03 9.3445e-02 1.0419e-01 9.5886e-02 8.5815e-02 1.4734e-01
 1.2177e-01 1.7883e-01 1.5137e-01 1.5833e-01] ...(size = 77 end with 0.05816650390625, sum = 1838.0)
/text_model/encoder/layers.7/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.7/layer_norm1/Add_output_0
[1.8330e+03 9.3445e-02 1.0419e-01 9.5886e-02 8.5876e-02 1.4734e-01
 1.2177e-01 1.7883e-01 1.5149e-01 1.5833e-01] ...(size = 77 end with 0.058197021484375, sum = 1838.0)
/text_model/encoder/layers.7/layer_norm1/Sqrt_output_0
[42.8     0.3057  0.3228  0.3096  0.293   0.3838  0.3489  0.4229  0.3892
  0.398 ] ...(size = 77 end with 0.2412109375, sum = 62.90625)
/text_model/encoder/layers.7/layer_norm1/Div_output_0
[-0.091   -0.05902  0.11365  0.02043 -0.0287  -0.1146  -0.05005 -0.0514
  0.08545  0.00906] ...(size = 59136 end with 0.335205078125, sum = 0.038604736328125)
/text_model/encoder/layers.7/layer_norm1/Mul_output_0
[-0.141    -0.09674   0.1818    0.03247  -0.04688  -0.188    -0.0772
 -0.08215   0.1361    0.014725] ...(size = 59136 end with 0.55126953125, sum = -1587.0)
/text_model/encoder/layers.7/layer_norm1/Add_1_output_0
[-0.04178  -0.05292   0.004284  0.0645    0.03296   0.0324    0.01624
 -0.04517   0.02173   0.002363] ...(size = 59136 end with 0.546875, sum = -1359.0)
/text_model/encoder/layers.7/self_attn/q_proj/MatMul_output_0
[-0.1454  -0.0768   0.1035   0.1969  -0.191   -0.568   -0.0636  -0.08704
 -0.1581   0.179  ] ...(size = 59136 end with 0.09625244140625, sum = 572.5)
/text_model/encoder/layers.7/self_attn/q_proj/Add_output_0
[-0.386    0.2208   0.4797   0.04498 -0.4226   0.3289   0.2196  -0.2576
  0.01616 -0.1646 ] ...(size = 59136 end with 0.11993408203125, sum = -194.0)
/text_model/encoder/layers.7/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.7/self_attn/Mul_output_0
[-0.04825   0.0276    0.05997   0.005623 -0.05283   0.0411    0.02745
 -0.0322    0.00202  -0.02057 ] ...(size = 59136 end with 0.01499176025390625, sum = -24.25)
/text_model/encoder/layers.7/self_attn/k_proj/MatMul_output_0
[-0.201   0.2756  0.205  -0.0438 -0.2522  0.9746  0.2374 -0.0698  0.0757
 -0.2307] ...(size = 59136 end with -0.60107421875, sum = 1533.0)
/text_model/encoder/layers.7/self_attn/k_proj/Add_output_0
[-0.2103   0.2878   0.2026  -0.03784 -0.2542   1.015    0.255   -0.0691
  0.092   -0.2344 ] ...(size = 59136 end with -0.6064453125, sum = 1571.0)
/text_model/encoder/layers.7/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.7/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.7/self_attn/Reshape_output_0
[-0.2103   0.2878   0.2026  -0.03784 -0.2542   1.015    0.255   -0.0691
  0.092   -0.2344 ] ...(size = 59136 end with -0.6064453125, sum = 1571.0)
/text_model/encoder/layers.7/self_attn/Transpose_output_0
[-0.2103   0.2878   0.2026  -0.03784 -0.2542   1.015    0.255   -0.0691
  0.092   -0.2344 ] ...(size = 59136 end with -0.6064453125, sum = 1571.0)
/text_model/encoder/layers.7/self_attn/v_proj/MatMul_output_0
[ 0.0437   0.00611 -0.05756  0.05096  0.0805   0.03128  0.1071  -0.0216
 -0.02551 -0.0808 ] ...(size = 59136 end with 0.9716796875, sum = 903.5)
/text_model/encoder/layers.7/self_attn/v_proj/Add_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.99609375, sum = 1009.5)
/text_model/encoder/layers.7/self_attn/Reshape_1_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.99609375, sum = 1009.5)
/text_model/encoder/layers.7/self_attn/Transpose_1_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.99609375, sum = 1009.5)
/text_model/encoder/layers.7/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.7/self_attn/Reshape_2_output_0
[-0.04825   0.0276    0.05997   0.005623 -0.05283   0.0411    0.02745
 -0.0322    0.00202  -0.02057 ] ...(size = 59136 end with 0.01499176025390625, sum = -24.25)
/text_model/encoder/layers.7/self_attn/Transpose_2_output_0
[-0.04825   0.0276    0.05997   0.005623 -0.05283   0.0411    0.02745
 -0.0322    0.00202  -0.02057 ] ...(size = 59136 end with 0.01499176025390625, sum = -24.265625)
/text_model/encoder/layers.7/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Reshape_3_output_0
[-0.04825   0.0276    0.05997   0.005623 -0.05283   0.0411    0.02745
 -0.0322    0.00202  -0.02057 ] ...(size = 59136 end with 0.01499176025390625, sum = -24.265625)
/text_model/encoder/layers.7/self_attn/Reshape_4_output_0
[-0.2103   0.2878   0.2026  -0.03784 -0.2542   1.015    0.255   -0.0691
  0.092   -0.2344 ] ...(size = 59136 end with -0.6064453125, sum = 1571.0)
/text_model/encoder/layers.7/self_attn/Reshape_5_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.99609375, sum = 1009.5)
/text_model/encoder/layers.7/self_attn/Transpose_3_output_0
[-0.2103  -0.2947  -0.485   -0.1395   1.444    0.9478   1.497    1.48
 -0.04373  0.1901 ] ...(size = 59136 end with -0.6064453125, sum = 1570.0)
/text_model/encoder/layers.7/self_attn/MatMul_output_0
[ 0.5454 -0.7573 -0.2559 -0.204  -0.896  -0.738  -1.109  -0.7524 -1.295
 -1.007 ] ...(size = 71148 end with -5.67578125, sum = -inf)
/text_model/encoder/layers.7/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.7/self_attn/Reshape_6_output_0
[ 0.5454 -0.7573 -0.2559 -0.204  -0.896  -0.738  -1.109  -0.7524 -1.295
 -1.007 ] ...(size = 71148 end with -5.67578125, sum = -inf)
/text_model/encoder/layers.7/self_attn/Add_output_0
[ 5.454e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -5.67578125, sum = -inf)
/text_model/encoder/layers.7/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.7/self_attn/Reshape_7_output_0
[ 5.454e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -5.67578125, sum = -inf)
/text_model/encoder/layers.7/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.000514984130859375, sum = 924.0)
/text_model/encoder/layers.7/self_attn/MatMul_1_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.094970703125, sum = 585.0)
/text_model/encoder/layers.7/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.7/self_attn/Reshape_8_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.094970703125, sum = 585.0)
/text_model/encoder/layers.7/self_attn/Transpose_4_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.094970703125, sum = 585.0)
/text_model/encoder/layers.7/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.7/self_attn/Reshape_9_output_0
[ 0.005737   0.00915   -0.02934    0.01697    0.02826   -0.004013
  0.01137   -0.0004787  0.02115   -0.03314  ] ...(size = 59136 end with 0.094970703125, sum = 585.0)
/text_model/encoder/layers.7/self_attn/out_proj/MatMul_output_0
[-0.00571  -0.06836   0.03943  -0.00996   0.000526 -0.02069  -0.0147
 -0.01084  -0.0165   -0.01465 ] ...(size = 59136 end with 0.0780029296875, sum = 5.33203125)
/text_model/encoder/layers.7/self_attn/out_proj/Add_output_0
[-0.007366 -0.1365    0.03317  -0.01108   0.01846  -0.05005   0.01122
 -0.02676   0.001466 -0.03415 ] ...(size = 59136 end with 0.033416748046875, sum = 45.59375)
/text_model/encoder/layers.7/Add_output_0
[-3.922  -2.682   4.883   0.846  -1.229  -4.977  -2.148  -2.244   3.643
  0.3362] ...(size = 59136 end with 0.119384765625, sum = 363.25)
/text_model/encoder/layers.7/layer_norm2/ReduceMean_output_0
[-0.01721  0.01334  0.00812  0.01106  0.01151  0.00494  0.007    0.01356
  0.00505  0.01092] ...(size = 77 end with 0.0058441162109375, sum = 0.473388671875)
/text_model/encoder/layers.7/layer_norm2/Sub_output_0
[-3.904  -2.664   4.9     0.8633 -1.211  -4.957  -2.13   -2.227   3.66
  0.3535] ...(size = 59136 end with 0.11358642578125, sum = -0.388671875)
/text_model/encoder/layers.7/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.7/layer_norm2/Pow_output_0
[15.24     7.098   24.       0.7456   1.468   24.6      4.543    4.96
 13.39     0.12494] ...(size = 59136 end with 0.0128936767578125, sum = inf)
/text_model/encoder/layers.7/layer_norm2/ReduceMean_1_output_0
[1.834e+03 9.973e-02 1.086e-01 1.044e-01 8.942e-02 1.506e-01 1.261e-01
 2.014e-01 1.515e-01 1.735e-01] ...(size = 77 end with 0.0777587890625, sum = 1841.0)
/text_model/encoder/layers.7/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.7/layer_norm2/Add_output_0
[1.8340e+03 9.9731e-02 1.0858e-01 1.0443e-01 8.9417e-02 1.5063e-01
 1.2610e-01 2.0142e-01 1.5149e-01 1.7346e-01] ...(size = 77 end with 0.0777587890625, sum = 1841.0)
/text_model/encoder/layers.7/layer_norm2/Sqrt_output_0
[42.8     0.3157  0.3296  0.3232  0.299   0.3882  0.355   0.4487  0.3892
  0.4165] ...(size = 77 end with 0.27880859375, sum = 65.75)
/text_model/encoder/layers.7/layer_norm2/Div_output_0
[-0.0912   -0.0622    0.1144    0.02016  -0.02829  -0.1158   -0.04977
 -0.052     0.08545   0.008255] ...(size = 59136 end with 0.4072265625, sum = -0.0293731689453125)
/text_model/encoder/layers.7/layer_norm2/Mul_output_0
[-0.2064  -0.1342   0.2598   0.0452  -0.04892 -0.2578  -0.11066 -0.1141
  0.1959   0.01903] ...(size = 59136 end with 0.96142578125, sum = -2118.0)
/text_model/encoder/layers.7/layer_norm2/Add_1_output_0
[-0.04428   -0.00204   -0.6025     0.011604   0.10126   -0.2036
  0.07623   -0.0661     0.3093     0.0017805] ...(size = 59136 end with 1.6015625, sum = -1295.0)
/text_model/encoder/layers.7/mlp/fc1/MatMul_output_0
[-1.356  -1.582  -0.8105 -0.6016 -1.263  -1.343  -1.243  -1.146  -1.358
 -0.9463] ...(size = 236544 end with -1.576171875, sum = -inf)
/text_model/encoder/layers.7/mlp/fc1/Add_output_0
[-1.71  -1.86  -1.197 -0.828 -1.65  -1.716 -1.551 -1.535 -1.696 -1.269] ...(size = 236544 end with -1.8017578125, sum = -inf)
/text_model/encoder/layers.7/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.7/mlp/activation_fn/Mul_output_0
[-2.91  -3.168 -2.037 -1.41  -2.809 -2.92  -2.64  -2.613 -2.887 -2.158] ...(size = 236544 end with -3.068359375, sum = -inf)
/text_model/encoder/layers.7/mlp/activation_fn/Sigmoid_output_0
[0.0516  0.04044 0.11536 0.1963  0.05682 0.05118 0.0666  0.0683  0.0528
 0.1035 ] ...(size = 236544 end with 0.044464111328125, sum = 15664.0)
/text_model/encoder/layers.7/mlp/activation_fn/Mul_1_output_0
[-0.08826 -0.0752  -0.1381  -0.1626  -0.0938  -0.08777 -0.10333 -0.10486
 -0.08954 -0.1313 ] ...(size = 236544 end with -0.08013916015625, sum = -13608.0)
/text_model/encoder/layers.7/mlp/fc2/MatMul_output_0
[ 0.01755 -0.09076  0.1039  -0.0721   0.0612  -0.04526 -0.0809   0.0873
  0.03928  0.1395 ] ...(size = 59136 end with 0.042083740234375, sum = -0.37353515625)
/text_model/encoder/layers.7/mlp/fc2/Add_output_0
[ 0.06155  -0.04678   0.06354   0.006145  0.0644   -0.0522   -0.01741
  0.08795   0.0625    0.0893  ] ...(size = 59136 end with 0.027801513671875, sum = 9.3671875)
/text_model/encoder/layers.7/Add_1_output_0
[-3.86   -2.729   4.945   0.8525 -1.164  -5.027  -2.166  -2.156   3.705
  0.4255] ...(size = 59136 end with 0.147216796875, sum = 372.75)
/text_model/encoder/layers.8/layer_norm1/ReduceMean_output_0
[-0.01697   0.01401   0.00844   0.01203   0.01254   0.00473   0.007236
  0.014656  0.00459   0.01255 ] ...(size = 77 end with 0.005977630615234375, sum = 0.485595703125)
/text_model/encoder/layers.8/layer_norm1/Sub_output_0
[-3.844  -2.71    4.96    0.8696 -1.147  -5.01   -2.15   -2.139   3.72
  0.4426] ...(size = 59136 end with 0.1412353515625, sum = -0.169921875)
/text_model/encoder/layers.8/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.8/layer_norm1/Pow_output_0
[14.77    7.348  24.62    0.756   1.316  25.11    4.62    4.58   13.85
  0.1958] ...(size = 59136 end with 0.0199432373046875, sum = inf)
/text_model/encoder/layers.8/layer_norm1/ReduceMean_1_output_0
[1.8370e+03 9.6069e-02 1.0156e-01 1.0431e-01 9.6497e-02 1.7285e-01
 1.3940e-01 1.8762e-01 1.9836e-01 1.7224e-01] ...(size = 77 end with 0.07440185546875, sum = 1844.0)
/text_model/encoder/layers.8/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.8/layer_norm1/Add_output_0
[1.837e+03 9.607e-02 1.016e-01 1.044e-01 9.656e-02 1.729e-01 1.394e-01
 1.876e-01 1.984e-01 1.722e-01] ...(size = 77 end with 0.07440185546875, sum = 1844.0)
/text_model/encoder/layers.8/layer_norm1/Sqrt_output_0
[42.88    0.31    0.3188  0.323   0.3108  0.4158  0.3735  0.433   0.4453
  0.415 ] ...(size = 77 end with 0.272705078125, sum = 65.5)
/text_model/encoder/layers.8/layer_norm1/Div_output_0
[-0.08966 -0.06323  0.1157   0.02028 -0.02676 -0.1169  -0.05014 -0.04993
  0.0868   0.01032] ...(size = 59136 end with 0.517578125, sum = -0.07763671875)
/text_model/encoder/layers.8/layer_norm1/Mul_output_0
[-0.1608  -0.1128   0.206    0.03412 -0.0433  -0.2125  -0.0917  -0.09064
  0.158    0.01805] ...(size = 59136 end with 0.8916015625, sum = -1255.0)
/text_model/encoder/layers.8/layer_norm1/Add_1_output_0
[-0.05127   0.007526 -0.02037   0.04773   0.03384  -0.00492   0.03564
 -0.03723  -0.02966   0.01429 ] ...(size = 59136 end with 0.90185546875, sum = -1020.0)
/text_model/encoder/layers.8/self_attn/q_proj/MatMul_output_0
[ 0.1354  -0.446    0.153    0.3008  -0.1758  -0.01735 -0.04083 -0.1271
  0.1803  -0.10834] ...(size = 59136 end with 0.62646484375, sum = 154.75)
/text_model/encoder/layers.8/self_attn/q_proj/Add_output_0
[ 0.1015   0.1492  -0.194   -0.0749   0.0634   0.01235  0.1521   0.1283
  0.2812   0.3713 ] ...(size = 59136 end with 0.372314453125, sum = -429.75)
/text_model/encoder/layers.8/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.8/self_attn/Mul_output_0
[ 0.01269   0.01865  -0.02425  -0.00936   0.00793   0.001544  0.01901
  0.01604   0.03516   0.04642 ] ...(size = 59136 end with 0.046539306640625, sum = -53.71875)
/text_model/encoder/layers.8/self_attn/k_proj/MatMul_output_0
[ 0.0206   0.552   -0.1616  -0.271    0.305    0.0863   0.1024   0.302
  0.06027  0.52   ] ...(size = 59136 end with -0.9794921875, sum = -151.75)
/text_model/encoder/layers.8/self_attn/k_proj/Add_output_0
[-0.003145  0.511    -0.139    -0.2416    0.2333    0.0825    0.1042
  0.2695    0.0577    0.4873  ] ...(size = 59136 end with -0.97509765625, sum = -134.75)
/text_model/encoder/layers.8/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.8/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.8/self_attn/Reshape_output_0
[-0.003145  0.511    -0.139    -0.2416    0.2333    0.0825    0.1042
  0.2695    0.0577    0.4873  ] ...(size = 59136 end with -0.97509765625, sum = -134.75)
/text_model/encoder/layers.8/self_attn/Transpose_output_0
[-0.003145  0.511    -0.139    -0.2416    0.2333    0.0825    0.1042
  0.2695    0.0577    0.4873  ] ...(size = 59136 end with -0.97509765625, sum = -134.875)
/text_model/encoder/layers.8/self_attn/v_proj/MatMul_output_0
[-0.0253  -0.09534 -0.01471  0.07056 -0.0283  -0.0684  -0.02138 -0.02512
  0.05804  0.09314] ...(size = 59136 end with -0.37158203125, sum = -99.5625)
/text_model/encoder/layers.8/self_attn/v_proj/Add_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.3642578125, sum = -205.5)
/text_model/encoder/layers.8/self_attn/Reshape_1_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.3642578125, sum = -205.5)
/text_model/encoder/layers.8/self_attn/Transpose_1_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.3642578125, sum = -205.625)
/text_model/encoder/layers.8/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.8/self_attn/Reshape_2_output_0
[ 0.01269   0.01865  -0.02425  -0.00936   0.00793   0.001544  0.01901
  0.01604   0.03516   0.04642 ] ...(size = 59136 end with 0.046539306640625, sum = -53.71875)
/text_model/encoder/layers.8/self_attn/Transpose_2_output_0
[ 0.01269   0.01865  -0.02425  -0.00936   0.00793   0.001544  0.01901
  0.01604   0.03516   0.04642 ] ...(size = 59136 end with 0.046539306640625, sum = -54.0)
/text_model/encoder/layers.8/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Reshape_3_output_0
[ 0.01269   0.01865  -0.02425  -0.00936   0.00793   0.001544  0.01901
  0.01604   0.03516   0.04642 ] ...(size = 59136 end with 0.046539306640625, sum = -54.0)
/text_model/encoder/layers.8/self_attn/Reshape_4_output_0
[-0.003145  0.511    -0.139    -0.2416    0.2333    0.0825    0.1042
  0.2695    0.0577    0.4873  ] ...(size = 59136 end with -0.97509765625, sum = -134.875)
/text_model/encoder/layers.8/self_attn/Reshape_5_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.3642578125, sum = -205.625)
/text_model/encoder/layers.8/self_attn/Transpose_3_output_0
[-0.003145  0.3042   -0.758    -0.8936    1.52      0.3008    0.541
 -0.1586    0.2064    1.292   ] ...(size = 59136 end with -0.97509765625, sum = -134.625)
/text_model/encoder/layers.8/self_attn/MatMul_output_0
[ 0.4958 -1.291  -1.303  -1.3955 -1.492   0.3242  0.1843 -0.9624 -0.3376
 -0.1335] ...(size = 71148 end with -4.515625, sum = -inf)
/text_model/encoder/layers.8/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.8/self_attn/Reshape_6_output_0
[ 0.4958 -1.291  -1.303  -1.3955 -1.492   0.3242  0.1843 -0.9624 -0.3376
 -0.1335] ...(size = 71148 end with -4.515625, sum = -inf)
/text_model/encoder/layers.8/self_attn/Add_output_0
[ 4.958e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.515625, sum = -inf)
/text_model/encoder/layers.8/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.8/self_attn/Reshape_7_output_0
[ 4.958e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.515625, sum = -inf)
/text_model/encoder/layers.8/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0005121231079101562, sum = 924.0)
/text_model/encoder/layers.8/self_attn/MatMul_1_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.4833984375, sum = -226.0)
/text_model/encoder/layers.8/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.8/self_attn/Reshape_8_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.4833984375, sum = -226.0)
/text_model/encoder/layers.8/self_attn/Transpose_4_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.4833984375, sum = -225.75)
/text_model/encoder/layers.8/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.8/self_attn/Reshape_9_output_0
[-0.012146 -0.05066  -0.0216    0.04395  -0.012505 -0.03192  -0.01464
 -0.00558   0.03714   0.0333  ] ...(size = 59136 end with -0.4833984375, sum = -225.75)
/text_model/encoder/layers.8/self_attn/out_proj/MatMul_output_0
[-0.0195    0.001048  0.001806 -0.0044   -0.05728   0.001192 -0.02747
  0.01012   0.00907   0.00779 ] ...(size = 59136 end with -0.003383636474609375, sum = -34.5)
/text_model/encoder/layers.8/self_attn/out_proj/Add_output_0
[-0.05225 -0.03622  0.07245 -0.0538  -0.143   -0.11615 -0.02464  0.0454
  0.03656 -0.0661 ] ...(size = 59136 end with -0.037933349609375, sum = -29.171875)
/text_model/encoder/layers.8/Add_output_0
[-3.912  -2.764   5.016   0.799  -1.307  -5.145  -2.191  -2.111   3.74
  0.3594] ...(size = 59136 end with 0.1092529296875, sum = 343.75)
/text_model/encoder/layers.8/layer_norm2/ReduceMean_output_0
[-0.01657   0.01442   0.00882   0.012314  0.01278   0.00508   0.00762
  0.01468   0.004955  0.01382 ] ...(size = 77 end with 0.0054931640625, sum = 0.447509765625)
/text_model/encoder/layers.8/layer_norm2/Sub_output_0
[-3.896 -2.748  5.035  0.815 -1.29  -5.13  -2.174 -2.094  3.758  0.376] ...(size = 59136 end with 0.103759765625, sum = -0.0875244140625)
/text_model/encoder/layers.8/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.8/layer_norm2/Pow_output_0
[15.18    7.55   25.34    0.6646  1.665  26.3     4.73    4.387  14.12
  0.1414] ...(size = 59136 end with 0.010772705078125, sum = inf)
/text_model/encoder/layers.8/layer_norm2/ReduceMean_1_output_0
[1.8380e+03 1.0327e-01 1.0992e-01 1.1163e-01 1.0101e-01 1.7834e-01
 1.4771e-01 2.3962e-01 2.0520e-01 2.1802e-01] ...(size = 77 end with 0.11212158203125, sum = 1848.0)
/text_model/encoder/layers.8/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.8/layer_norm2/Add_output_0
[1.8380e+03 1.0327e-01 1.0992e-01 1.1163e-01 1.0101e-01 1.7834e-01
 1.4771e-01 2.3962e-01 2.0520e-01 2.1802e-01] ...(size = 77 end with 0.11212158203125, sum = 1848.0)
/text_model/encoder/layers.8/layer_norm2/Sqrt_output_0
[42.88    0.3213  0.3315  0.3342  0.3179  0.4224  0.3843  0.4895  0.4531
  0.467 ] ...(size = 77 end with 0.334716796875, sum = 70.25)
/text_model/encoder/layers.8/layer_norm2/Div_output_0
[-0.0909  -0.0641   0.11743  0.01901 -0.0301  -0.11957 -0.05072 -0.04886
  0.08765  0.00877] ...(size = 59136 end with 0.31005859375, sum = -0.07171630859375)
/text_model/encoder/layers.8/layer_norm2/Mul_output_0
[-0.2153  -0.143    0.2559   0.043   -0.05652 -0.2927  -0.1129  -0.1109
  0.2041   0.02151] ...(size = 59136 end with 0.73388671875, sum = -2039.0)
/text_model/encoder/layers.8/layer_norm2/Add_1_output_0
[-0.435     0.1925   -0.2219    0.2727   -0.3137   -0.571     0.1552
 -0.006752 -0.178    -0.2625  ] ...(size = 59136 end with 0.99755859375, sum = -3280.0)
/text_model/encoder/layers.8/mlp/fc1/MatMul_output_0
[-2.344  -0.7246 -1.064  -1.143  -2.139  -0.891  -0.645  -1.822  -1.45
 -1.031 ] ...(size = 236544 end with -1.9638671875, sum = -inf)
/text_model/encoder/layers.8/mlp/fc1/Add_output_0
[-2.59   -1.064  -1.45   -1.431  -2.432  -1.038  -0.7056 -2.162  -1.77
 -1.352 ] ...(size = 236544 end with -2.107421875, sum = -inf)
/text_model/encoder/layers.8/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.8/mlp/activation_fn/Mul_output_0
[-4.406  -1.8125 -2.469  -2.434  -4.14   -1.768  -1.2    -3.68   -3.012
 -2.3   ] ...(size = 236544 end with -3.5859375, sum = -inf)
/text_model/encoder/layers.8/mlp/activation_fn/Sigmoid_output_0
[0.01205 0.1404  0.07806 0.08057 0.01569 0.1459  0.2313  0.02461 0.04688
 0.091  ] ...(size = 236544 end with 0.0269775390625, sum = 19728.0)
/text_model/encoder/layers.8/mlp/activation_fn/Mul_1_output_0
[-0.03119 -0.1494  -0.1132  -0.11523 -0.03815 -0.1515  -0.1632  -0.0532
 -0.08295 -0.12305] ...(size = 236544 end with -0.05682373046875, sum = -14976.0)
/text_model/encoder/layers.8/mlp/fc2/MatMul_output_0
[-0.0759   0.261   -0.1737   0.1489  -0.02068  0.3408  -0.1459  -0.2219
 -0.1945   0.2903 ] ...(size = 59136 end with 0.0533447265625, sum = -1.5537109375)
/text_model/encoder/layers.8/mlp/fc2/Add_output_0
[-0.05432  0.2219  -0.1266   0.1096  -0.06934  0.292   -0.0768  -0.1693
 -0.14     0.2578 ] ...(size = 59136 end with 0.052642822265625, sum = 19.0)
/text_model/encoder/layers.8/Add_1_output_0
[-3.967 -2.543  4.89   0.908 -1.376 -4.85  -2.268 -2.281  3.602  0.617] ...(size = 59136 end with 0.161865234375, sum = 363.0)
/text_model/encoder/layers.9/layer_norm1/ReduceMean_output_0
[-0.01547   0.01523   0.01082   0.01391   0.01388   0.00561   0.00838
  0.01646   0.006065  0.01415 ] ...(size = 77 end with 0.00569915771484375, sum = 0.47216796875)
/text_model/encoder/layers.9/layer_norm1/Sub_output_0
[-3.951 -2.527  4.906  0.924 -1.361 -4.836 -2.252 -2.266  3.617  0.633] ...(size = 59136 end with 0.15625, sum = 0.1290283203125)
/text_model/encoder/layers.9/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.9/layer_norm1/Pow_output_0
[15.61    6.383  24.06    0.853   1.853  23.39    5.074   5.13   13.08
  0.4004] ...(size = 59136 end with 0.0243988037109375, sum = inf)
/text_model/encoder/layers.9/layer_norm1/ReduceMean_1_output_0
[1.838e+03 1.125e-01 1.328e-01 1.299e-01 1.173e-01 1.940e-01 1.879e-01
 2.788e-01 2.299e-01 2.925e-01] ...(size = 77 end with 0.11517333984375, sum = 1849.0)
/text_model/encoder/layers.9/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.9/layer_norm1/Add_output_0
[1.838e+03 1.125e-01 1.328e-01 1.299e-01 1.174e-01 1.940e-01 1.879e-01
 2.788e-01 2.299e-01 2.925e-01] ...(size = 77 end with 0.11517333984375, sum = 1849.0)
/text_model/encoder/layers.9/layer_norm1/Sqrt_output_0
[42.88    0.3354  0.3645  0.3604  0.3425  0.4404  0.4333  0.528   0.4795
  0.5405] ...(size = 77 end with 0.33935546875, sum = 71.1875)
/text_model/encoder/layers.9/layer_norm1/Div_output_0
[-0.09216  -0.05893   0.11444   0.02155  -0.03174  -0.1128   -0.05255
 -0.05283   0.08435   0.014755] ...(size = 59136 end with 0.460205078125, sum = 0.0202789306640625)
/text_model/encoder/layers.9/layer_norm1/Mul_output_0
[-0.1503  -0.106    0.1906   0.03607 -0.05157 -0.1967  -0.0859  -0.0842
  0.1504   0.02531] ...(size = 59136 end with 0.7578125, sum = -1412.0)
/text_model/encoder/layers.9/layer_norm1/Add_1_output_0
[-0.01546  -0.05652  -0.008675  0.01089   0.1321   -0.05054   0.055
 -0.0157   -0.008995 -0.0369  ] ...(size = 59136 end with 0.744140625, sum = -1074.0)
/text_model/encoder/layers.9/self_attn/q_proj/MatMul_output_0
[ 0.09906 -0.3503  -0.1323  -0.09705  0.2047  -0.06537  0.2632   0.1367
 -0.2522   0.0882 ] ...(size = 59136 end with -0.14306640625, sum = 1303.0)
/text_model/encoder/layers.9/self_attn/q_proj/Add_output_0
[-0.2996  -0.10114  0.0569  -0.1105   0.3     -0.00313  0.3127  -0.03323
 -0.2076  -0.2034 ] ...(size = 59136 end with 0.37109375, sum = 202.375)
/text_model/encoder/layers.9/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.9/self_attn/Mul_output_0
[-0.03745   -0.01264    0.00711   -0.01381    0.0375    -0.0003912
  0.0391    -0.004154  -0.02596   -0.02542  ] ...(size = 59136 end with 0.04638671875, sum = 25.296875)
/text_model/encoder/layers.9/self_attn/k_proj/MatMul_output_0
[-0.3477   0.223    0.3713  -0.01078  0.07263  0.1161   0.0896  -0.2231
 -0.03049 -0.2465 ] ...(size = 59136 end with 0.66650390625, sum = 3508.0)
/text_model/encoder/layers.9/self_attn/k_proj/Add_output_0
[-0.3047   0.2026   0.3618  -0.0189   0.09644  0.1045   0.10254 -0.2102
 -0.0535  -0.244  ] ...(size = 59136 end with 0.51220703125, sum = 3586.0)
/text_model/encoder/layers.9/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.9/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.9/self_attn/Reshape_output_0
[-0.3047   0.2026   0.3618  -0.0189   0.09644  0.1045   0.10254 -0.2102
 -0.0535  -0.244  ] ...(size = 59136 end with 0.51220703125, sum = 3586.0)
/text_model/encoder/layers.9/self_attn/Transpose_output_0
[-0.3047   0.2026   0.3618  -0.0189   0.09644  0.1045   0.10254 -0.2102
 -0.0535  -0.244  ] ...(size = 59136 end with 0.51220703125, sum = 3584.0)
/text_model/encoder/layers.9/self_attn/v_proj/MatMul_output_0
[ 0.0375    0.0693   -0.002901 -0.03223  -0.02946   0.02068  -0.03375
 -0.010956 -0.1165   -0.2651  ] ...(size = 59136 end with -0.12261962890625, sum = 1598.0)
/text_model/encoder/layers.9/self_attn/v_proj/Add_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.129638671875, sum = 1712.0)
/text_model/encoder/layers.9/self_attn/Reshape_1_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.129638671875, sum = 1712.0)
/text_model/encoder/layers.9/self_attn/Transpose_1_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.129638671875, sum = 1713.0)
/text_model/encoder/layers.9/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.9/self_attn/Reshape_2_output_0
[-0.03745   -0.01264    0.00711   -0.01381    0.0375    -0.0003912
  0.0391    -0.004154  -0.02596   -0.02542  ] ...(size = 59136 end with 0.04638671875, sum = 25.296875)
/text_model/encoder/layers.9/self_attn/Transpose_2_output_0
[-0.03745   -0.01264    0.00711   -0.01381    0.0375    -0.0003912
  0.0391    -0.004154  -0.02596   -0.02542  ] ...(size = 59136 end with 0.04638671875, sum = 25.3125)
/text_model/encoder/layers.9/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Reshape_3_output_0
[-0.03745   -0.01264    0.00711   -0.01381    0.0375    -0.0003912
  0.0391    -0.004154  -0.02596   -0.02542  ] ...(size = 59136 end with 0.04638671875, sum = 25.3125)
/text_model/encoder/layers.9/self_attn/Reshape_4_output_0
[-0.3047   0.2026   0.3618  -0.0189   0.09644  0.1045   0.10254 -0.2102
 -0.0535  -0.244  ] ...(size = 59136 end with 0.51220703125, sum = 3584.0)
/text_model/encoder/layers.9/self_attn/Reshape_5_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.129638671875, sum = 1713.0)
/text_model/encoder/layers.9/self_attn/Transpose_3_output_0
[-0.3047 -0.0711 -0.4753 -1.149  -0.1499  0.6216  0.554   1.05   -0.536
  1.371 ] ...(size = 59136 end with 0.51220703125, sum = 3586.0)
/text_model/encoder/layers.9/self_attn/MatMul_output_0
[ 0.358  -0.4963 -0.645  -0.432  -0.9224 -0.4023 -0.451  -0.5913 -0.513
 -0.3179] ...(size = 71148 end with -1.1875, sum = -inf)
/text_model/encoder/layers.9/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.9/self_attn/Reshape_6_output_0
[ 0.358  -0.4963 -0.645  -0.432  -0.9224 -0.4023 -0.451  -0.5913 -0.513
 -0.3179] ...(size = 71148 end with -1.1875, sum = -inf)
/text_model/encoder/layers.9/self_attn/Add_output_0
[ 3.58e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -1.1875, sum = -inf)
/text_model/encoder/layers.9/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.9/self_attn/Reshape_7_output_0
[ 3.58e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -1.1875, sum = -inf)
/text_model/encoder/layers.9/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.00901031494140625, sum = 924.0)
/text_model/encoder/layers.9/self_attn/MatMul_1_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.04681396484375, sum = 737.5)
/text_model/encoder/layers.9/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.9/self_attn/Reshape_8_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.04681396484375, sum = 737.5)
/text_model/encoder/layers.9/self_attn/Transpose_4_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.04681396484375, sum = 737.5)
/text_model/encoder/layers.9/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.9/self_attn/Reshape_9_output_0
[ 0.002584  0.0283    0.0282   -0.01031  -0.00893   0.01791  -0.03009
 -0.04074  -0.0535   -0.2124  ] ...(size = 59136 end with -0.04681396484375, sum = 737.5)
/text_model/encoder/layers.9/self_attn/out_proj/MatMul_output_0
[-0.01923   -0.001891  -0.007496   0.01493    0.0002577 -0.0077
 -0.016     -0.04626    0.00871    0.010544 ] ...(size = 59136 end with -0.1427001953125, sum = -47.40625)
/text_model/encoder/layers.9/self_attn/out_proj/Add_output_0
[-0.0899  -0.04767  0.0835  -0.07794 -0.1053  -0.1095  -0.0418  -0.06573
  0.1078  -0.04926] ...(size = 59136 end with -0.11883544921875, sum = -27.59375)
/text_model/encoder/layers.9/Add_output_0
[-4.06  -2.59   4.973  0.83  -1.481 -4.96  -2.31  -2.346  3.709  0.568] ...(size = 59136 end with 0.0430908203125, sum = 335.0)
/text_model/encoder/layers.9/layer_norm2/ReduceMean_output_0
[-0.01572   0.01494   0.010475  0.01354   0.01356   0.005463  0.00826
  0.01636   0.005985  0.01336 ] ...(size = 77 end with 0.005626678466796875, sum = 0.436279296875)
/text_model/encoder/layers.9/layer_norm2/Sub_output_0
[-4.04   -2.574   4.99    0.846  -1.466  -4.945  -2.293  -2.33    3.725
  0.5835] ...(size = 59136 end with 0.0374755859375, sum = 0.06634521484375)
/text_model/encoder/layers.9/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.9/layer_norm2/Pow_output_0
[16.33    6.625  24.89    0.716   2.148  24.45    5.26    5.43   13.875
  0.3406] ...(size = 59136 end with 0.00140380859375, sum = inf)
/text_model/encoder/layers.9/layer_norm2/ReduceMean_1_output_0
[1.8390e+03 1.1664e-01 1.3855e-01 1.3574e-01 1.2317e-01 2.0276e-01
 1.9238e-01 3.1543e-01 2.3303e-01 3.7964e-01] ...(size = 77 end with 0.307373046875, sum = 1862.0)
/text_model/encoder/layers.9/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.9/layer_norm2/Add_output_0
[1.8390e+03 1.1670e-01 1.3855e-01 1.3574e-01 1.2317e-01 2.0288e-01
 1.9238e-01 3.1543e-01 2.3303e-01 3.7964e-01] ...(size = 77 end with 0.307373046875, sum = 1862.0)
/text_model/encoder/layers.9/layer_norm2/Sqrt_output_0
[42.88    0.3416  0.3723  0.3684  0.351   0.4504  0.4387  0.5615  0.4827
  0.616 ] ...(size = 77 end with 0.55419921875, sum = 84.875)
/text_model/encoder/layers.9/layer_norm2/Div_output_0
[-0.09424 -0.06003  0.11633  0.01973 -0.03418 -0.1153  -0.0535  -0.05435
  0.08685  0.01361] ...(size = 59136 end with 0.06756591796875, sum = -0.019073486328125)
/text_model/encoder/layers.9/layer_norm2/Mul_output_0
[-0.2411  -0.1399   0.276    0.0473  -0.06683 -0.3025  -0.1287  -0.1315
  0.2208   0.0312 ] ...(size = 59136 end with 0.1651611328125, sum = -2100.0)
/text_model/encoder/layers.9/layer_norm2/Add_1_output_0
[-0.2112 -0.4414  0.417  -0.299  -0.3179 -0.865   0.0977  0.1145  0.3855
 -0.3894] ...(size = 59136 end with 0.2347412109375, sum = -2760.0)
/text_model/encoder/layers.9/mlp/fc1/MatMul_output_0
[-1.997  -0.5864 -0.6387 -1.245  -0.966  -1.584  -1.9    -1.041  -2.127
 -0.8447] ...(size = 236544 end with -1.39453125, sum = -inf)
/text_model/encoder/layers.9/mlp/fc1/Add_output_0
[-2.236  -0.9487 -0.725  -1.492  -1.353  -1.833  -2.123  -1.351  -2.5
 -1.1   ] ...(size = 236544 end with -1.5146484375, sum = -inf)
/text_model/encoder/layers.9/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.9/mlp/activation_fn/Mul_output_0
[-3.807 -1.615 -1.234 -2.54  -2.303 -3.12  -3.613 -2.299 -4.258 -1.871] ...(size = 236544 end with -2.578125, sum = -inf)
/text_model/encoder/layers.9/mlp/activation_fn/Sigmoid_output_0
[0.02176 0.1659  0.2255  0.0731  0.09094 0.04233 0.02625 0.09125 0.01397
 0.1334 ] ...(size = 236544 end with 0.070556640625, sum = 25152.0)
/text_model/encoder/layers.9/mlp/activation_fn/Mul_1_output_0
[-0.04865 -0.1573  -0.1635  -0.1091  -0.123   -0.0776  -0.05573 -0.1232
 -0.03494 -0.1466 ] ...(size = 236544 end with -0.10687255859375, sum = -16216.0)
/text_model/encoder/layers.9/mlp/fc2/MatMul_output_0
[ 0.1267   0.1515  -0.0923   0.1974   0.07     0.06146  0.3074  -0.086
 -0.1836   0.1396 ] ...(size = 59136 end with -0.2110595703125, sum = 49.84375)
/text_model/encoder/layers.9/mlp/fc2/Add_output_0
[ 0.1427    0.1616   -0.10095   0.153    -0.000597  0.07263   0.2712
 -0.1417   -0.0938    0.06113 ] ...(size = 59136 end with -0.1705322265625, sum = 55.65625)
/text_model/encoder/layers.9/Add_1_output_0
[-3.914  -2.428   4.875   0.9834 -1.482  -4.89   -2.04   -2.488   3.615
  0.629 ] ...(size = 59136 end with -0.12744140625, sum = 390.5)
/text_model/encoder/layers.10/layer_norm1/ReduceMean_output_0
[-0.01503   0.02017   0.014595  0.01826   0.01886   0.006123  0.00836
  0.01987   0.00652   0.01572 ] ...(size = 77 end with 0.006336212158203125, sum = 0.5087890625)
/text_model/encoder/layers.10/layer_norm1/Sub_output_0
[-3.898  -2.414   4.887   0.9985 -1.467  -4.875  -2.023  -2.473   3.63
  0.644 ] ...(size = 59136 end with -0.1336669921875, sum = -0.34228515625)
/text_model/encoder/layers.10/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.10/layer_norm1/Pow_output_0
[15.2     5.824  23.89    0.9966  2.152  23.75    4.094   6.113  13.18
  0.4148] ...(size = 59136 end with 0.01788330078125, sum = inf)
/text_model/encoder/layers.10/layer_norm1/ReduceMean_1_output_0
[1.841e+03 1.754e-01 1.896e-01 1.776e-01 1.694e-01 2.832e-01 2.329e-01
 3.787e-01 2.957e-01 5.161e-01] ...(size = 77 end with 0.378662109375, sum = 1870.0)
/text_model/encoder/layers.10/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.10/layer_norm1/Add_output_0
[1.841e+03 1.754e-01 1.896e-01 1.776e-01 1.694e-01 2.832e-01 2.329e-01
 3.787e-01 2.957e-01 5.161e-01] ...(size = 77 end with 0.378662109375, sum = 1870.0)
/text_model/encoder/layers.10/layer_norm1/Sqrt_output_0
[42.9     0.419   0.4353  0.4214  0.4116  0.532   0.4827  0.615   0.5435
  0.7183] ...(size = 77 end with 0.615234375, sum = 89.9375)
/text_model/encoder/layers.10/layer_norm1/Div_output_0
[-0.0909   -0.05624   0.11395   0.02327  -0.0342   -0.1136   -0.04715
 -0.05765   0.0846    0.015015] ...(size = 59136 end with -0.21728515625, sum = -0.03509521484375)
/text_model/encoder/layers.10/layer_norm1/Mul_output_0
[-0.1692  -0.1014   0.2017   0.04144 -0.0527  -0.2     -0.0832  -0.09595
  0.1445   0.02655] ...(size = 59136 end with -0.379150390625, sum = -1548.0)
/text_model/encoder/layers.10/layer_norm1/Add_1_output_0
[-0.01213   0.003834 -0.0168    0.0051    0.1293   -0.02753   0.04977
 -0.02516  -0.04813  -0.0656  ] ...(size = 59136 end with -0.380859375, sum = -1158.0)
/text_model/encoder/layers.10/self_attn/q_proj/MatMul_output_0
[ 0.3525   0.1635  -0.256   -0.08344  0.1238  -0.4194   0.2188   0.2345
  0.1531   0.2917 ] ...(size = 59136 end with -0.7685546875, sum = 1022.5)
/text_model/encoder/layers.10/self_attn/q_proj/Add_output_0
[ 0.2383  0.3567 -0.1356  0.1561  0.0658 -0.0516 -0.1709  0.2769  0.1373
  0.2252] ...(size = 59136 end with -0.7490234375, sum = 1783.0)
/text_model/encoder/layers.10/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.10/self_attn/Mul_output_0
[ 0.02979   0.0446   -0.01695   0.01952   0.008224 -0.00645  -0.02136
  0.0346    0.01717   0.02815 ] ...(size = 59136 end with -0.0936279296875, sum = 222.875)
/text_model/encoder/layers.10/self_attn/k_proj/MatMul_output_0
[-0.1381   0.3687   0.1351   0.441   -0.07306  0.4512  -0.651   -0.02846
 -0.0689  -0.224  ] ...(size = 59136 end with 1.220703125, sum = -949.0)
/text_model/encoder/layers.10/self_attn/k_proj/Add_output_0
[-0.1372   0.3706   0.1287   0.4434  -0.0708   0.4507  -0.6436  -0.01947
 -0.05856 -0.2257 ] ...(size = 59136 end with 1.2744140625, sum = -903.5)
/text_model/encoder/layers.10/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.10/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.10/self_attn/Reshape_output_0
[-0.1372   0.3706   0.1287   0.4434  -0.0708   0.4507  -0.6436  -0.01947
 -0.05856 -0.2257 ] ...(size = 59136 end with 1.2744140625, sum = -903.5)
/text_model/encoder/layers.10/self_attn/Transpose_output_0
[-0.1372   0.3706   0.1287   0.4434  -0.0708   0.4507  -0.6436  -0.01947
 -0.05856 -0.2257 ] ...(size = 59136 end with 1.2744140625, sum = -903.5)
/text_model/encoder/layers.10/self_attn/v_proj/MatMul_output_0
[ 0.03928  0.05057 -0.01374  0.11646  0.04404  0.0316  -0.043    0.03888
 -0.06525  0.05035] ...(size = 59136 end with 0.3935546875, sum = 1414.0)
/text_model/encoder/layers.10/self_attn/v_proj/Add_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.426513671875, sum = 1260.0)
/text_model/encoder/layers.10/self_attn/Reshape_1_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.426513671875, sum = 1260.0)
/text_model/encoder/layers.10/self_attn/Transpose_1_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.426513671875, sum = 1261.0)
/text_model/encoder/layers.10/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.10/self_attn/Reshape_2_output_0
[ 0.02979   0.0446   -0.01695   0.01952   0.008224 -0.00645  -0.02136
  0.0346    0.01717   0.02815 ] ...(size = 59136 end with -0.0936279296875, sum = 222.875)
/text_model/encoder/layers.10/self_attn/Transpose_2_output_0
[ 0.02979   0.0446   -0.01695   0.01952   0.008224 -0.00645  -0.02136
  0.0346    0.01717   0.02815 ] ...(size = 59136 end with -0.0936279296875, sum = 222.75)
/text_model/encoder/layers.10/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Reshape_3_output_0
[ 0.02979   0.0446   -0.01695   0.01952   0.008224 -0.00645  -0.02136
  0.0346    0.01717   0.02815 ] ...(size = 59136 end with -0.0936279296875, sum = 222.75)
/text_model/encoder/layers.10/self_attn/Reshape_4_output_0
[-0.1372   0.3706   0.1287   0.4434  -0.0708   0.4507  -0.6436  -0.01947
 -0.05856 -0.2257 ] ...(size = 59136 end with 1.2744140625, sum = -903.5)
/text_model/encoder/layers.10/self_attn/Reshape_5_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.426513671875, sum = 1261.0)
/text_model/encoder/layers.10/self_attn/Transpose_3_output_0
[-0.1372  -0.4978   0.05475 -0.7373   0.5767  -0.858    1.552    0.885
  0.0668   1.058  ] ...(size = 59136 end with 1.2744140625, sum = -904.0)
/text_model/encoder/layers.10/self_attn/MatMul_output_0
[ 0.1418  -0.1404   0.214    0.0655  -0.03595 -0.00996  0.07513  0.1376
 -0.2192   0.3594 ] ...(size = 71148 end with -2.2578125, sum = -inf)
/text_model/encoder/layers.10/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.10/self_attn/Reshape_6_output_0
[ 0.1418  -0.1404   0.214    0.0655  -0.03595 -0.00996  0.07513  0.1376
 -0.2192   0.3594 ] ...(size = 71148 end with -2.2578125, sum = -inf)
/text_model/encoder/layers.10/self_attn/Add_output_0
[ 1.418e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -2.2578125, sum = -inf)
/text_model/encoder/layers.10/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.10/self_attn/Reshape_7_output_0
[ 1.418e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -2.2578125, sum = -inf)
/text_model/encoder/layers.10/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.003978729248046875, sum = 924.0)
/text_model/encoder/layers.10/self_attn/MatMul_1_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.09454345703125, sum = 846.5)
/text_model/encoder/layers.10/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.10/self_attn/Reshape_8_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.09454345703125, sum = 846.5)
/text_model/encoder/layers.10/self_attn/Transpose_4_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.09454345703125, sum = 846.5)
/text_model/encoder/layers.10/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.10/self_attn/Reshape_9_output_0
[ 0.0689    0.07196  -0.03955   0.136     0.0569   -0.015526 -0.01994
  0.0024   -0.0803    0.1676  ] ...(size = 59136 end with 0.09454345703125, sum = 846.5)
/text_model/encoder/layers.10/self_attn/out_proj/MatMul_output_0
[-0.01982  -0.03555  -0.002943  0.04172  -0.02464  -0.05225   0.05054
  0.01826  -0.06854  -0.02487 ] ...(size = 59136 end with 0.00262451171875, sum = 13.6640625)
/text_model/encoder/layers.10/self_attn/out_proj/Add_output_0
[-0.1272   0.0689   0.0705  -0.02623 -0.11755 -0.1389  -0.0705  -0.0353
  0.1077  -0.03119] ...(size = 59136 end with 0.08465576171875, sum = 67.375)
/text_model/encoder/layers.10/Add_output_0
[-4.043  -2.36    4.945   0.957  -1.6    -5.027  -2.11   -2.523   3.723
  0.5977] ...(size = 59136 end with -0.042724609375, sum = 458.25)
/text_model/encoder/layers.10/layer_norm2/ReduceMean_output_0
[-0.01478   0.02045   0.01521   0.01857   0.01926   0.006554  0.00898
  0.02084   0.006977  0.01628 ] ...(size = 77 end with 0.0081329345703125, sum = 0.5966796875)
/text_model/encoder/layers.10/layer_norm2/Sub_output_0
[-4.027  -2.344   4.957   0.9717 -1.585  -5.01   -2.094  -2.508   3.738
  0.613 ] ...(size = 59136 end with -0.050872802734375, sum = 0.306640625)
/text_model/encoder/layers.10/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.10/layer_norm2/Pow_output_0
[16.22    5.496  24.58    0.9443  2.512  25.12    4.387   6.293  13.97
  0.3752] ...(size = 59136 end with 0.0025882720947265625, sum = inf)
/text_model/encoder/layers.10/layer_norm2/ReduceMean_1_output_0
[1.843e+03 1.893e-01 2.100e-01 1.895e-01 1.832e-01 3.040e-01 2.505e-01
 4.055e-01 3.108e-01 5.552e-01] ...(size = 77 end with 0.5390625, sum = 1883.0)
/text_model/encoder/layers.10/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.10/layer_norm2/Add_output_0
[1.843e+03 1.895e-01 2.100e-01 1.895e-01 1.832e-01 3.040e-01 2.505e-01
 4.055e-01 3.108e-01 5.552e-01] ...(size = 77 end with 0.5390625, sum = 1883.0)
/text_model/encoder/layers.10/layer_norm2/Sqrt_output_0
[42.94    0.4353  0.4583  0.4353  0.428   0.5513  0.5005  0.6367  0.5576
  0.745 ] ...(size = 77 end with 0.734375, sum = 98.0625)
/text_model/encoder/layers.10/layer_norm2/Div_output_0
[-0.0938   -0.05463   0.1155    0.02264  -0.03693  -0.11676  -0.04877
 -0.05844   0.08704   0.014275] ...(size = 59136 end with -0.06927490234375, sum = -0.07220458984375)
/text_model/encoder/layers.10/layer_norm2/Mul_output_0
[-0.2141  -0.12354  0.2627   0.0515  -0.08374 -0.2908  -0.1212  -0.1385
  0.2201   0.03192] ...(size = 59136 end with -0.16552734375, sum = -1164.0)
/text_model/encoder/layers.10/layer_norm2/Add_1_output_0
[-0.1276  -0.4165   0.4602  -0.0701  -0.4727  -0.5093  -0.2456   0.00977
  0.2844  -0.0459 ] ...(size = 59136 end with -0.043731689453125, sum = -2566.0)
/text_model/encoder/layers.10/mlp/fc1/MatMul_output_0
[-1.403   0.4927 -0.8716 -1.908  -1.53   -2.543  -0.5825 -0.9526 -0.1785
 -0.976 ] ...(size = 236544 end with -1.3330078125, sum = -inf)
/text_model/encoder/layers.10/mlp/fc1/Add_output_0
[-1.73    0.2546 -1.264  -2.299  -1.763  -2.855  -0.684  -1.19   -0.4375
 -1.221 ] ...(size = 236544 end with -1.6259765625, sum = -inf)
/text_model/encoder/layers.10/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.10/mlp/activation_fn/Mul_output_0
[-2.945   0.4336 -2.152  -3.914  -3.     -4.86   -1.165  -2.025  -0.7446
 -2.078 ] ...(size = 236544 end with -2.767578125, sum = -inf)
/text_model/encoder/layers.10/mlp/activation_fn/Sigmoid_output_0
[0.04996 0.607   0.1042  0.01958 0.04742 0.00769 0.2378  0.1165  0.322
 0.11127] ...(size = 236544 end with 0.05908203125, sum = 33408.0)
/text_model/encoder/layers.10/mlp/activation_fn/Mul_1_output_0
[-0.0864   0.1545  -0.1317  -0.045   -0.08356 -0.02196 -0.1627  -0.1387
 -0.1409  -0.1359 ] ...(size = 236544 end with -0.0960693359375, sum = -14560.0)
/text_model/encoder/layers.10/mlp/fc2/MatMul_output_0
[ 0.186    -0.3147   -0.1667    0.1447    0.3035   -0.0466   -0.118
 -0.007473 -0.3718   -0.1016  ] ...(size = 59136 end with -0.45458984375, sum = 69.8125)
/text_model/encoder/layers.10/mlp/fc2/Add_output_0
[ 0.1495  -0.152   -0.227    0.1349   0.259    0.07117 -0.02373 -0.1409
 -0.3357  -0.07263] ...(size = 59136 end with -0.39306640625, sum = 20.953125)
/text_model/encoder/layers.10/Add_1_output_0
[-3.893  -2.512   4.715   1.092  -1.341  -4.957  -2.133  -2.664   3.387
  0.5254] ...(size = 59136 end with -0.435791015625, sum = 478.75)
/text_model/encoder/layers.11/layer_norm1/ReduceMean_output_0
[-0.01616   0.02553   0.02448   0.03069   0.03004   0.003231  0.01375
  0.02803   0.006176  0.01953 ] ...(size = 77 end with 0.007762908935546875, sum = 0.62353515625)
/text_model/encoder/layers.11/layer_norm1/Sub_output_0
[-3.875  -2.494   4.734   1.108  -1.324  -4.94   -2.117  -2.648   3.402
  0.5415] ...(size = 59136 end with -0.443603515625, sum = -0.406494140625)
/text_model/encoder/layers.11/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.11/layer_norm1/Pow_output_0
[15.016   6.227  22.4     1.228   1.754  24.4     4.48    7.01   11.586
  0.2932] ...(size = 59136 end with 0.19677734375, sum = inf)
/text_model/encoder/layers.11/layer_norm1/ReduceMean_1_output_0
[1.844e+03 2.157e-01 2.397e-01 2.705e-01 2.487e-01 3.137e-01 2.888e-01
 5.337e-01 3.967e-01 7.666e-01] ...(size = 77 end with 0.5986328125, sum = 1890.0)
/text_model/encoder/layers.11/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.11/layer_norm1/Add_output_0
[1.844e+03 2.157e-01 2.397e-01 2.705e-01 2.487e-01 3.137e-01 2.888e-01
 5.337e-01 3.967e-01 7.666e-01] ...(size = 77 end with 0.5986328125, sum = 1890.0)
/text_model/encoder/layers.11/layer_norm1/Sqrt_output_0
[42.94    0.4644  0.4897  0.52    0.4985  0.56    0.5376  0.7305  0.63
  0.8755] ...(size = 77 end with 0.77392578125, sum = 101.8125)
/text_model/encoder/layers.11/layer_norm1/Div_output_0
[-0.0903  -0.0581   0.1102   0.0258  -0.03084 -0.11505 -0.0493  -0.06168
  0.0793   0.01261] ...(size = 59136 end with -0.5732421875, sum = -0.0007982254028320312)
/text_model/encoder/layers.11/layer_norm1/Mul_output_0
[-0.17    -0.1066   0.2069   0.04852 -0.048   -0.2167  -0.0932  -0.11163
  0.1575   0.02394] ...(size = 59136 end with -1.0498046875, sum = -1391.0)
/text_model/encoder/layers.11/layer_norm1/Add_1_output_0
[-0.02032 -0.0158   0.09454  0.02446  0.1646   0.00996  0.064    0.1066
 -0.0883  -0.06445] ...(size = 59136 end with -0.97119140625, sum = -1016.5)
/text_model/encoder/layers.11/self_attn/q_proj/MatMul_output_0
[-0.5156  -0.631    0.1045  -0.02405 -0.1616  -0.517   -0.02834 -0.08014
  1.646   -0.1085 ] ...(size = 59136 end with -0.4013671875, sum = 2586.0)
/text_model/encoder/layers.11/self_attn/q_proj/Add_output_0
[-0.3445  -0.3872   0.3047  -0.1332  -0.349   -0.5273   0.02611 -0.1108
 -0.1927   0.02954] ...(size = 59136 end with -0.432861328125, sum = 3516.0)
/text_model/encoder/layers.11/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.11/self_attn/Mul_output_0
[-0.04306  -0.0484    0.0381   -0.01665  -0.04364  -0.0659    0.003263
 -0.01385  -0.0241    0.003693] ...(size = 59136 end with -0.054107666015625, sum = 439.5)
/text_model/encoder/layers.11/self_attn/k_proj/MatMul_output_0
[ 0.4172   0.2401   0.2076  -0.1823  -0.5186  -0.2578  -0.1594  -0.04968
 -1.016    0.2925 ] ...(size = 59136 end with 0.146728515625, sum = -3378.0)
/text_model/encoder/layers.11/self_attn/k_proj/Add_output_0
[ 0.4177  0.2375  0.2123 -0.179  -0.5205 -0.2559 -0.1588 -0.0501 -1.034
  0.292 ] ...(size = 59136 end with 0.147216796875, sum = -3372.0)
/text_model/encoder/layers.11/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.11/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.11/self_attn/Reshape_output_0
[ 0.4177  0.2375  0.2123 -0.179  -0.5205 -0.2559 -0.1588 -0.0501 -1.034
  0.292 ] ...(size = 59136 end with 0.147216796875, sum = -3372.0)
/text_model/encoder/layers.11/self_attn/Transpose_output_0
[ 0.4177  0.2375  0.2123 -0.179  -0.5205 -0.2559 -0.1588 -0.0501 -1.034
  0.292 ] ...(size = 59136 end with 0.147216796875, sum = -3372.0)
/text_model/encoder/layers.11/self_attn/v_proj/MatMul_output_0
[ 0.0183    0.001024 -0.2104   -0.01552  -0.0915   -0.345    -0.1627
  0.3381   -0.1465   -0.1289  ] ...(size = 59136 end with 0.56005859375, sum = -2202.0)
/text_model/encoder/layers.11/self_attn/v_proj/Add_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.486328125, sum = -2158.0)
/text_model/encoder/layers.11/self_attn/Reshape_1_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.486328125, sum = -2158.0)
/text_model/encoder/layers.11/self_attn/Transpose_1_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.486328125, sum = -2158.0)
/text_model/encoder/layers.11/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.11/self_attn/Reshape_2_output_0
[-0.04306  -0.0484    0.0381   -0.01665  -0.04364  -0.0659    0.003263
 -0.01385  -0.0241    0.003693] ...(size = 59136 end with -0.054107666015625, sum = 439.5)
/text_model/encoder/layers.11/self_attn/Transpose_2_output_0
[-0.04306  -0.0484    0.0381   -0.01665  -0.04364  -0.0659    0.003263
 -0.01385  -0.0241    0.003693] ...(size = 59136 end with -0.054107666015625, sum = 440.0)
/text_model/encoder/layers.11/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Reshape_3_output_0
[-0.04306  -0.0484    0.0381   -0.01665  -0.04364  -0.0659    0.003263
 -0.01385  -0.0241    0.003693] ...(size = 59136 end with -0.054107666015625, sum = 440.0)
/text_model/encoder/layers.11/self_attn/Reshape_4_output_0
[ 0.4177  0.2375  0.2123 -0.179  -0.5205 -0.2559 -0.1588 -0.0501 -1.034
  0.292 ] ...(size = 59136 end with 0.147216796875, sum = -3372.0)
/text_model/encoder/layers.11/self_attn/Reshape_5_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.486328125, sum = -2158.0)
/text_model/encoder/layers.11/self_attn/Transpose_3_output_0
[ 0.4177  0.0691 -1.559  -0.7134  0.3318 -0.688  -0.2122 -1.437   1.184
  0.461 ] ...(size = 59136 end with 0.147216796875, sum = -3372.0)
/text_model/encoder/layers.11/self_attn/MatMul_output_0
[ 0.2095   0.01235  0.0784  -0.00932  0.0945   0.4646   0.6104   0.315
  0.0847   0.3628 ] ...(size = 71148 end with -2.95703125, sum = -inf)
/text_model/encoder/layers.11/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.11/self_attn/Reshape_6_output_0
[ 0.2095   0.01235  0.0784  -0.00932  0.0945   0.4646   0.6104   0.315
  0.0847   0.3628 ] ...(size = 71148 end with -2.95703125, sum = -inf)
/text_model/encoder/layers.11/self_attn/Add_output_0
[ 2.095e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -2.95703125, sum = -inf)
/text_model/encoder/layers.11/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.11/self_attn/Reshape_7_output_0
[ 2.095e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -2.95703125, sum = -inf)
/text_model/encoder/layers.11/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.004116058349609375, sum = 924.0)
/text_model/encoder/layers.11/self_attn/MatMul_1_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.6494140625, sum = -1218.0)
/text_model/encoder/layers.11/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.11/self_attn/Reshape_8_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.6494140625, sum = -1218.0)
/text_model/encoder/layers.11/self_attn/Transpose_4_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.6494140625, sum = -1218.0)
/text_model/encoder/layers.11/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.11/self_attn/Reshape_9_output_0
[ 0.068     0.04672  -0.1638    0.001479 -0.08716  -0.2317   -0.13
  0.293    -0.0712   -0.1597  ] ...(size = 59136 end with 0.6494140625, sum = -1218.0)
/text_model/encoder/layers.11/self_attn/out_proj/MatMul_output_0
[ 0.08966  -0.07007   0.03876   0.0747    0.04132  -0.1136    0.000965
  0.1129   -0.04657   0.097   ] ...(size = 59136 end with 0.9365234375, sum = -105.5)
/text_model/encoder/layers.11/self_attn/out_proj/Add_output_0
[-0.2397    0.3157   -0.1202   -0.005005 -0.0854   -0.2756    0.1069
 -0.1832    0.1836    0.1334  ] ...(size = 59136 end with 1.1953125, sum = -64.625)
/text_model/encoder/layers.11/Add_output_0
[-4.133  -2.195   4.598   1.087  -1.426  -5.23   -2.025  -2.848   3.57
  0.6587] ...(size = 59136 end with 0.75927734375, sum = 414.25)
/text_model/encoder/layers.11/layer_norm2/ReduceMean_output_0
[-0.014854  0.02696   0.02599   0.0324    0.03165   0.00455   0.014084
  0.02832   0.00695   0.02042 ] ...(size = 77 end with 0.00592803955078125, sum = 0.53955078125)
/text_model/encoder/layers.11/layer_norm2/Sub_output_0
[-4.117 -2.182  4.61   1.102 -1.411 -5.22  -2.012 -2.832  3.586  0.674] ...(size = 59136 end with 0.75341796875, sum = -0.427001953125)
/text_model/encoder/layers.11/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.11/layer_norm2/Pow_output_0
[16.94    4.754  21.27    1.214   1.991  27.22    4.043   8.02   12.86
  0.4536] ...(size = 59136 end with 0.5673828125, sum = inf)
/text_model/encoder/layers.11/layer_norm2/ReduceMean_1_output_0
[1.846e+03 2.817e-01 4.224e-01 3.853e-01 3.342e-01 4.229e-01 4.771e-01
 7.690e-01 5.273e-01 1.045e+00] ...(size = 77 end with 1.0634765625, sum = 1922.0)
/text_model/encoder/layers.11/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.11/layer_norm2/Add_output_0
[1.846e+03 2.817e-01 4.224e-01 3.853e-01 3.342e-01 4.229e-01 4.771e-01
 7.690e-01 5.273e-01 1.045e+00] ...(size = 77 end with 1.0634765625, sum = 1922.0)
/text_model/encoder/layers.11/layer_norm2/Sqrt_output_0
[42.97    0.531   0.65    0.6206  0.578   0.6504  0.691   0.877   0.726
  1.022 ] ...(size = 77 end with 1.03125, sum = 118.25)
/text_model/encoder/layers.11/layer_norm2/Div_output_0
[-0.0958  -0.05075  0.10736  0.02565 -0.03284 -0.12146 -0.0468  -0.0659
  0.08344  0.01569] ...(size = 59136 end with 0.73046875, sum = 0.0178070068359375)
/text_model/encoder/layers.11/layer_norm2/Mul_output_0
[-0.1672  -0.09094  0.1917   0.04376 -0.0731  -0.2148  -0.077   -0.1123
  0.1498   0.02687] ...(size = 59136 end with 1.271484375, sum = 459.0)
/text_model/encoder/layers.11/layer_norm2/Add_1_output_0
[-0.1827   -0.1827    0.0512    0.0729   -0.368     0.01753   0.06946
  0.0259    0.009705 -0.08563 ] ...(size = 59136 end with 1.4462890625, sum = 356.5)
/text_model/encoder/layers.11/mlp/fc1/MatMul_output_0
[ 0.2097 -0.3809 -1.634  -2.459  -0.2825 -1.477  -1.086  -2.223  -0.9966
 -1.573 ] ...(size = 236544 end with 0.78271484375, sum = -inf)
/text_model/encoder/layers.11/mlp/fc1/Add_output_0
[ 0.08264 -0.5303  -1.863   -2.84    -0.389   -1.72    -1.262   -2.428
 -1.263   -1.663  ] ...(size = 236544 end with 0.740234375, sum = -inf)
/text_model/encoder/layers.11/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.11/mlp/activation_fn/Mul_output_0
[ 0.1407 -0.9023 -3.172  -4.832  -0.6616 -2.928  -2.146  -4.133  -2.15
 -2.832 ] ...(size = 236544 end with 1.259765625, sum = -inf)
/text_model/encoder/layers.11/mlp/activation_fn/Sigmoid_output_0
[0.535    0.2886   0.04028  0.007904 0.3403   0.05084  0.10455  0.01578
 0.1044   0.05566 ] ...(size = 236544 end with 0.779296875, sum = 44992.0)
/text_model/encoder/layers.11/mlp/activation_fn/Mul_1_output_0
[ 0.04422 -0.153   -0.075   -0.02245 -0.1323  -0.0874  -0.132   -0.0383
 -0.1318  -0.0926 ] ...(size = 236544 end with 0.57666015625, sum = -14904.0)
/text_model/encoder/layers.11/mlp/fc2/MatMul_output_0
[ 0.4062  -0.4993   0.2925   0.00378  0.2214   0.02711 -0.2374   0.0886
 -0.0909  -0.03976] ...(size = 59136 end with -0.22900390625, sum = -60.28125)
/text_model/encoder/layers.11/mlp/fc2/Add_output_0
[ 0.662   -0.761    0.5273   0.143    0.22     0.072   -0.12134  0.1006
 -0.3154   0.0796 ] ...(size = 59136 end with -0.2890625, sum = -140.0)
/text_model/encoder/layers.11/Add_1_output_0
[-3.469  -2.957   5.125   1.2295 -1.206  -5.16   -2.146  -2.746   3.256
  0.7383] ...(size = 59136 end with 0.47021484375, sum = 274.25)
/text_model/final_layer_norm/ReduceMean_output_0
[-0.0217    0.01872   0.01878   0.02533   0.026    -0.001082  0.00907
  0.02516   0.002619  0.01534 ] ...(size = 77 end with 0.003322601318359375, sum = 0.357177734375)
/text_model/final_layer_norm/Sub_output_0
[-3.447  -2.936   5.145   1.252  -1.185  -5.137  -2.125  -2.725   3.277
  0.7603] ...(size = 59136 end with 0.466796875, sum = 0.027618408203125)
/text_model/final_layer_norm/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/final_layer_norm/Pow_output_0
[11.88    8.62   26.47    1.566   1.402  26.4     4.516   7.426  10.74
  0.5776] ...(size = 59136 end with 0.2178955078125, sum = inf)
/text_model/final_layer_norm/ReduceMean_1_output_0
[1.841e+03 2.864e-01 3.789e-01 4.207e-01 3.694e-01 3.708e-01 4.397e-01
 6.880e-01 4.336e-01 9.414e-01] ...(size = 77 end with 0.8359375, sum = 1901.0)
/text_model/final_layer_norm/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/final_layer_norm/Add_output_0
[1.841e+03 2.864e-01 3.789e-01 4.207e-01 3.694e-01 3.708e-01 4.399e-01
 6.880e-01 4.336e-01 9.414e-01] ...(size = 77 end with 0.8359375, sum = 1901.0)
/text_model/final_layer_norm/Sqrt_output_0
[42.9     0.535   0.6157  0.6484  0.608   0.609   0.663   0.829   0.6587
  0.97  ] ...(size = 77 end with 0.9140625, sum = 110.1875)
/text_model/final_layer_norm/Div_output_0
[-0.0803  -0.0684   0.11993  0.02917 -0.0276  -0.11975 -0.04953 -0.06354
  0.07635  0.01772] ...(size = 59136 end with 0.5107421875, sum = -0.066650390625)
/text_model/final_layer_norm/Mul_output_0
[-0.0787  -0.06354  0.126    0.02869 -0.03763 -0.1176  -0.04437 -0.06287
  0.0742   0.01807] ...(size = 59136 end with 0.499267578125, sum = 182.375)
last_hidden_state
[-0.3884   0.02298 -0.0521  -0.1841  -0.02733 -0.3357  -0.01758 -0.187
  0.1877  -0.09064] ...(size = 59136 end with 0.5947265625, sum = -6364.0)
/text_model/Cast_1_output_0
[49406   320  1125   539   550 18376  6765   320  4558   525] ...(size = 77 end with 49407, sum = 3350842)
/text_model/ArgMax_output_0
[11] ...(size = 1 end with 11, sum = 11)
/text_model/Shape_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/Constant_4_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Gather_output_0
[77] ...(size = 1 end with 77, sum = 77)
/text_model/Constant_5_output_0
[2] ...(size = 1 end with 2, sum = 2)
/text_model/Gather_1_output_0
[768] ...(size = 1 end with 768, sum = 768)
/text_model/Flatten_output_0
[-0.3884   0.02298 -0.0521  -0.1841  -0.02733 -0.3357  -0.01758 -0.187
  0.1877  -0.09064] ...(size = 59136 end with 0.5947265625, sum = -6364.0)
/text_model/Constant_6_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Mul_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Add_output_0
[11] ...(size = 1 end with 11, sum = 11)
/text_model/Gather_2_output_0
[-2.629    0.362    0.2937   0.9526  -1.535    1.501   -1.932   -0.07025
 -0.155   -0.4287 ] ...(size = 768 end with -0.1319580078125, sum = -83.6875)
/text_model/Shape_1_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Constant_7_output_0
[-1] ...(size = 1 end with -1, sum = -1)
/text_model/Concat_output_0
[ -1 768] ...(size = 2 end with 768, sum = 767)
/text_model/Reshape_1_output_0
[-2.629    0.362    0.2937   0.9526  -1.535    1.501   -1.932   -0.07025
 -0.155   -0.4287 ] ...(size = 768 end with -0.1319580078125, sum = -83.6875)
/text_model/Concat_1_output_0
[  1 768] ...(size = 2 end with 768, sum = 769)
pooler_output
[-2.629    0.362    0.2937   0.9526  -1.535    1.501   -1.932   -0.07025
 -0.155   -0.4287 ] ...(size = 768 end with -0.1319580078125, sum = -83.6875)
text_model.embeddings.token_embedding.weight
[-0.0012045  0.0368     0.02213   -0.004208  -0.013     -0.007435
 -0.009056  -0.01979    0.03262   -0.01813  ] ...(size = 37945344 end with 0.005207061767578125, sum = -644.0)
text_model.embeddings.position_embedding.weight
[ 0.001584  0.002008  0.000208 -0.001874 -0.000706  0.002995  0.000633
 -0.002918  0.001847 -0.001681] ...(size = 59136 end with -0.0309600830078125, sum = -17.984375)
text_model.encoder.layers.0.self_attn.k_proj.bias
[-0.00285   -0.003304   0.005978   0.000769   0.02065    0.0007424
  0.00816   -0.01054    0.00806   -0.001903 ] ...(size = 768 end with -0.0131072998046875, sum = 0.51806640625)
text_model.encoder.layers.0.self_attn.v_proj.bias
[ 0.005116  0.003235  0.01415  -0.007545  0.01133  -0.03128   0.02686
 -0.01204  -0.01013   0.01665 ] ...(size = 768 end with -0.0143890380859375, sum = -0.5986328125)
text_model.encoder.layers.0.self_attn.q_proj.bias
[-0.2406   0.149    0.4639   0.0679   0.6553   0.2399   0.05664 -0.1252
 -0.02408  0.02257] ...(size = 768 end with -0.0065765380859375, sum = 20.03125)
text_model.encoder.layers.0.self_attn.out_proj.bias
[-0.06805  -0.033     0.0418   -0.1022   -0.005493  0.004288 -0.003868
 -0.04837  -0.02275  -0.002125] ...(size = 768 end with 0.0101318359375, sum = 0.50244140625)
text_model.encoder.layers.0.layer_norm1.weight
[1.84  1.65  1.795 1.78  1.766 1.768 1.86  1.823 1.752 1.736] ...(size = 768 end with 1.7626953125, sum = 1333.0)
text_model.encoder.layers.0.layer_norm1.bias
[-0.06396 -0.1891  -0.0663   0.11584 -0.0194  -0.0768  -0.09247  0.1501
 -0.154    0.05362] ...(size = 768 end with -0.08819580078125, sum = 15.8984375)
text_model.encoder.layers.0.mlp.fc1.bias
[-0.38    -0.4065  -0.2979  -0.417    0.04556 -0.0985  -0.3064  -0.2754
 -0.2705  -0.2405 ] ...(size = 3072 end with -0.1925048828125, sum = -973.5)
text_model.encoder.layers.0.mlp.fc2.bias
[ 0.00779  -0.0326    0.002337 -0.002743 -0.01785  -0.03696   0.04355
 -0.008736  0.005966 -0.006954] ...(size = 768 end with -0.0139617919921875, sum = 0.83935546875)
text_model.encoder.layers.0.layer_norm2.weight
[1.547 1.629 1.462 1.516 1.696 1.535 1.703 1.649 1.676 1.545] ...(size = 768 end with 1.6201171875, sum = 1265.0)
text_model.encoder.layers.0.layer_norm2.bias
[-0.2883  0.6787 -0.2378  0.7256  0.5034 -0.1025 -0.3928  0.7607  0.2822
  0.2751] ...(size = 768 end with -0.014129638671875, sum = 31.953125)
text_model.encoder.layers.1.self_attn.k_proj.bias
[ 0.001078  -0.004513   0.002207  -0.0009294  0.001965   0.005806
 -0.002028  -0.001972   0.0009737 -0.001694 ] ...(size = 768 end with 0.00342559814453125, sum = 0.62548828125)
text_model.encoder.layers.1.self_attn.v_proj.bias
[-0.01084  -0.01274   0.01237   0.01124   0.02676   0.03296   0.0266
 -0.002132  0.02206  -0.012634] ...(size = 768 end with 0.01453399658203125, sum = 0.224609375)
text_model.encoder.layers.1.self_attn.q_proj.bias
[ 0.343    -0.08356   0.04236  -0.0927    0.1887    0.1268   -0.1014
 -0.005375 -0.501     0.08594 ] ...(size = 768 end with 0.44775390625, sum = -1.4951171875)
text_model.encoder.layers.1.self_attn.out_proj.bias
[ 0.03056   0.01502  -0.02113   0.01636  -0.00601  -0.01196   0.038
  0.0478   -0.01289   0.011734] ...(size = 768 end with -0.003826141357421875, sum = 0.358642578125)
text_model.encoder.layers.1.layer_norm1.weight
[1.09  1.149 1.128 1.022 1.174 1.066 1.103 1.119 1.062 1.036] ...(size = 768 end with 1.173828125, sum = 857.0)
text_model.encoder.layers.1.layer_norm1.bias
[ 0.1298   0.03455 -0.184    0.01218  0.0543   0.07043  0.06915  0.0636
 -0.06396  0.02243] ...(size = 768 end with 0.0024051666259765625, sum = -0.85400390625)
text_model.encoder.layers.1.mlp.fc1.bias
[-0.2842  -0.3364   0.04828 -0.3481  -0.2357  -0.4583  -0.425   -0.366
 -0.3408  -0.356  ] ...(size = 3072 end with -0.275146484375, sum = -912.5)
text_model.encoder.layers.1.mlp.fc2.bias
[ 0.02638   0.0388   -0.0395    0.014725  0.00939   0.010445 -0.06174
  0.03384   0.05927  -0.01226 ] ...(size = 768 end with -0.0158233642578125, sum = 0.31640625)
text_model.encoder.layers.1.layer_norm2.weight
[1.866 1.778 1.813 1.903 1.82  1.836 1.932 1.903 2.008 1.737] ...(size = 768 end with 1.8408203125, sum = 1450.0)
text_model.encoder.layers.1.layer_norm2.bias
[ 0.10004  0.3264  -0.2104  -0.51    -0.0424  -0.2676   0.942   -0.2747
 -0.527   -0.05548] ...(size = 768 end with 0.0030536651611328125, sum = -16.09375)
text_model.encoder.layers.2.self_attn.k_proj.bias
[-0.004074   0.0004334  0.001524   0.0003138  0.00771    0.004726
 -0.009254   0.002254   0.002716   0.01347  ] ...(size = 768 end with 0.001834869384765625, sum = 0.05169677734375)
text_model.encoder.layers.2.self_attn.v_proj.bias
[-0.03018  -0.013565  0.01446  -0.02733  -0.01538   0.04877  -0.00824
 -0.01189  -0.02164  -0.008995] ...(size = 768 end with 0.03057861328125, sum = 0.1776123046875)
text_model.encoder.layers.2.self_attn.q_proj.bias
[-0.4333   0.1654  -0.05194  0.2106   0.5337   0.2764   0.03403  0.487
  0.0877   1.455  ] ...(size = 768 end with 0.1474609375, sum = 0.31982421875)
text_model.encoder.layers.2.self_attn.out_proj.bias
[ 0.04648   0.04126  -0.0576    0.004215 -0.01538  -0.007195  0.07196
  0.003372  0.01203  -0.001722] ...(size = 768 end with 0.00794219970703125, sum = 0.1630859375)
text_model.encoder.layers.2.layer_norm1.weight
[1.277 1.413 1.324 1.212 1.429 1.229 1.271 1.209 1.228 1.203] ...(size = 768 end with 1.37109375, sum = 1018.5)
text_model.encoder.layers.2.layer_norm1.bias
[ 0.1125     0.0665    -0.1525    -0.0005875  0.0455     0.0934
  0.08936    0.05966   -0.09595    0.03656  ] ...(size = 768 end with -0.002166748046875, sum = -0.9755859375)
text_model.encoder.layers.2.mlp.fc1.bias
[-0.1687  -0.1522  -0.1874  -0.3452  -0.2966  -0.4329  -0.2751  -0.1289
 -0.3467   0.09045] ...(size = 3072 end with -0.34521484375, sum = -891.5)
text_model.encoder.layers.2.mlp.fc2.bias
[-0.01445  -0.01944  -0.05246  -0.03102  -0.0513    0.03604  -0.004982
  0.03088  -0.0608   -0.003902] ...(size = 768 end with -0.041748046875, sum = 0.2939453125)
text_model.encoder.layers.2.layer_norm2.weight
[2.025 2.035 1.951 1.97  1.958 1.922 2.068 1.955 1.998 2.072] ...(size = 768 end with 2.001953125, sum = 1540.0)
text_model.encoder.layers.2.layer_norm2.bias
[ 0.215   0.747  -0.4377 -0.1919 -0.1936  0.4104  0.448  -0.1062 -0.1497
 -0.3406] ...(size = 768 end with 0.408447265625, sum = 9.6796875)
text_model.encoder.layers.3.self_attn.k_proj.bias
[ 0.04437  -0.00226  -0.00145   0.001346 -0.001952 -0.01     -0.004665
 -0.00454   0.00898   0.01318 ] ...(size = 768 end with 0.00384521484375, sum = 0.3916015625)
text_model.encoder.layers.3.self_attn.v_proj.bias
[-0.056    -0.0584    0.04797  -0.00546  -0.0166   -0.03857  -0.01528
  0.0326   -0.001681  0.004154] ...(size = 768 end with 0.0654296875, sum = -0.433349609375)
text_model.encoder.layers.3.self_attn.q_proj.bias
[ 0.1748  -0.06946 -0.2499  -0.251    0.2393  -0.2026   0.0181   0.1644
  0.4082   0.31   ] ...(size = 768 end with 0.505859375, sum = 4.875)
text_model.encoder.layers.3.self_attn.out_proj.bias
[-0.00462  -0.01071  -0.004246 -0.01166  -0.07227   0.011406  0.0658
 -0.0316    0.02274   0.0517  ] ...(size = 768 end with 0.0182342529296875, sum = 0.304443359375)
text_model.encoder.layers.3.layer_norm1.weight
[1.287 1.391 1.328 1.375 1.381 1.331 1.291 1.374 1.328 1.277] ...(size = 768 end with 1.3837890625, sum = 1029.0)
text_model.encoder.layers.3.layer_norm1.bias
[ 0.08734  0.0612  -0.11395 -0.0232   0.0662   0.10486  0.06192  0.06696
 -0.08295  0.02953] ...(size = 768 end with 0.00017511844635009766, sum = 0.09710693359375)
text_model.encoder.layers.3.mlp.fc1.bias
[-0.3335 -0.4612 -0.1525 -0.2683 -0.3743 -0.2935 -0.32   -0.455  -0.351
 -0.2847] ...(size = 3072 end with -0.310302734375, sum = -874.5)
text_model.encoder.layers.3.mlp.fc2.bias
[-0.01406  0.0564  -0.06366 -0.01566 -0.0701   0.0206   0.04938 -0.00391
 -0.0952  -0.02701] ...(size = 768 end with 0.0266571044921875, sum = 0.07843017578125)
text_model.encoder.layers.3.layer_norm2.weight
[2.031 1.973 2.068 2.092 2.09  2.16  2.193 2.094 2.184 2.062] ...(size = 768 end with 2.162109375, sum = 1594.0)
text_model.encoder.layers.3.layer_norm2.bias
[-0.1635   0.3904  -0.657    0.07776 -0.3645   0.804    0.6367  -0.08673
 -0.3818  -0.1614 ] ...(size = 768 end with 0.496337890625, sum = 23.5)
text_model.encoder.layers.4.self_attn.k_proj.bias
[-0.008316  -0.0007076 -0.001325  -0.0004635 -0.003689  -0.001901
 -0.002121   0.00513   -0.00554    0.001782 ] ...(size = 768 end with -0.022796630859375, sum = 0.2208251953125)
text_model.encoder.layers.4.self_attn.v_proj.bias
[-0.00495  -0.02118   0.02083   0.02664  -0.01692  -0.015144  0.0196
  0.01202   0.02626   0.01907 ] ...(size = 768 end with -0.01751708984375, sum = 0.509765625)
text_model.encoder.layers.4.self_attn.q_proj.bias
[ 1.137   -0.12103  0.1425   0.06033 -0.2903  -0.1243  -0.1969  -0.3384
  0.1661   0.12177] ...(size = 768 end with -2.20703125, sum = 14.5390625)
text_model.encoder.layers.4.self_attn.out_proj.bias
[-0.004513  0.001089 -0.03348  -0.01272  -0.0671    0.06714   0.0687
 -0.01541   0.0402    0.03326 ] ...(size = 768 end with 0.03924560546875, sum = 0.55810546875)
text_model.encoder.layers.4.layer_norm1.weight
[1.42  1.556 1.446 1.418 1.406 1.439 1.387 1.371 1.415 1.361] ...(size = 768 end with 1.4013671875, sum = 1102.0)
text_model.encoder.layers.4.layer_norm1.bias
[ 0.0719   0.0987  -0.12305 -0.0253   0.03433  0.1228   0.07056  0.0719
 -0.1254   0.01027] ...(size = 768 end with -0.0001195073127746582, sum = 1.654296875)
text_model.encoder.layers.4.mlp.fc1.bias
[-0.3206   0.02988 -0.2832  -0.3298  -0.334   -0.05557 -0.2524  -0.1273
 -0.3623  -0.371  ] ...(size = 3072 end with -0.320556640625, sum = -884.5)
text_model.encoder.layers.4.mlp.fc2.bias
[ 0.0462   0.05844 -0.0514   0.01813 -0.0145   0.1153   0.0729  -0.01498
  0.05185 -0.0234 ] ...(size = 768 end with 0.04058837890625, sum = 0.22509765625)
text_model.encoder.layers.4.layer_norm2.weight
[2.148 2.076 2.191 2.045 2.04  2.145 2.27  2.123 2.146 2.19 ] ...(size = 768 end with 2.279296875, sum = 1632.0)
text_model.encoder.layers.4.layer_norm2.bias
[-0.4048  0.504  -0.621   0.1904 -0.931   0.4368  0.628  -0.0079 -0.856
 -0.3027] ...(size = 768 end with 0.615234375, sum = 19.453125)
text_model.encoder.layers.5.self_attn.k_proj.bias
[-3.517e-03  2.033e-03  1.968e-03  1.490e-05  2.279e-03 -1.303e-03
 -2.371e-03  2.520e-03 -4.497e-04  4.120e-03] ...(size = 768 end with -0.002262115478515625, sum = -0.0498046875)
text_model.encoder.layers.5.self_attn.v_proj.bias
[ 0.011185 -0.03763   0.0082    0.0221    0.05646  -0.01156   0.02426
 -0.005817 -0.01001  -0.02678 ] ...(size = 768 end with -0.01401519775390625, sum = -0.148681640625)
text_model.encoder.layers.5.self_attn.q_proj.bias
[-0.321     0.2307   -0.04752  -0.07825   0.1832   -0.1461   -0.579
  0.0969    0.001486 -0.4832  ] ...(size = 768 end with -0.15966796875, sum = 16.28125)
text_model.encoder.layers.5.self_attn.out_proj.bias
[ 0.02896   0.01279   0.00939  -0.00446  -0.02933  -0.012665 -0.014824
 -0.05902  -0.02261   0.04172 ] ...(size = 768 end with 0.00867462158203125, sum = 0.398681640625)
text_model.encoder.layers.5.layer_norm1.weight
[1.438  1.549  1.444  1.437  1.47   1.599  1.4795 1.496  1.506  1.42  ] ...(size = 768 end with 1.4345703125, sum = 1149.0)
text_model.encoder.layers.5.layer_norm1.bias
[ 0.09503  0.06226 -0.1109  -0.0186   0.0807   0.1361   0.06903  0.03696
 -0.1356  -0.00266] ...(size = 768 end with -0.0345458984375, sum = 1.716796875)
text_model.encoder.layers.5.mlp.fc1.bias
[-0.3743 -0.409  -0.3171 -0.2642 -0.2595 -0.3726  0.1897 -0.364  -0.0976
 -0.2915] ...(size = 3072 end with -0.310302734375, sum = -875.5)
text_model.encoder.layers.5.mlp.fc2.bias
[ 0.05408   0.1301   -0.05798   0.01572   0.0327    0.0955    0.012794
 -0.06744  -0.1254    0.00614 ] ...(size = 768 end with 0.09521484375, sum = 0.1318359375)
text_model.encoder.layers.5.layer_norm2.weight
[2.13  2.098 2.166 2.082 1.795 2.16  2.201 2.092 2.234 2.156] ...(size = 768 end with 2.298828125, sum = 1631.0)
text_model.encoder.layers.5.layer_norm2.bias
[ 0.05502  0.3418  -0.599    0.05743 -0.593    0.621    0.7227  -0.3835
  0.531   -0.345  ] ...(size = 768 end with 0.6455078125, sum = -7.16015625)
text_model.encoder.layers.6.self_attn.k_proj.bias
[ 0.006336   0.002693  -0.005703   0.006226  -0.001444   0.001412
 -0.0001743 -0.00612    0.003546  -0.00496  ] ...(size = 768 end with 0.00455474853515625, sum = -0.345947265625)
text_model.encoder.layers.6.self_attn.v_proj.bias
[ 0.02711   0.001228  0.004333  0.04114   0.02036  -0.006992 -0.02
  0.02708   0.004387 -0.012665] ...(size = 768 end with -0.006359100341796875, sum = 1.5576171875)
text_model.encoder.layers.6.self_attn.q_proj.bias
[ 0.11993 -0.129    0.1978  -0.2443   0.0557  -0.2065   0.1271   0.2412
  0.0957   0.07385] ...(size = 768 end with 0.06854248046875, sum = 13.765625)
text_model.encoder.layers.6.self_attn.out_proj.bias
[ 0.02086 -0.02063 -0.05032 -0.01585  0.01868 -0.0086   0.01694 -0.0428
 -0.03098  0.0289 ] ...(size = 768 end with -0.030487060546875, sum = 0.47998046875)
text_model.encoder.layers.6.layer_norm1.weight
[1.562 1.629 1.513 1.575 1.622 1.579 1.589 1.575 1.608 1.599] ...(size = 768 end with 1.5859375, sum = 1217.0)
text_model.encoder.layers.6.layer_norm1.bias
[ 0.104    0.09705 -0.156   -0.00828  0.1023   0.1411   0.103    0.05426
 -0.1665  -0.00877] ...(size = 768 end with 0.007232666015625, sum = 2.80859375)
text_model.encoder.layers.6.mlp.fc1.bias
[-0.2957 -0.3293 -0.348  -0.254  -0.3374 -0.353  -0.3538 -0.3384 -0.3015
 -0.348 ] ...(size = 3072 end with -0.335205078125, sum = -892.0)
text_model.encoder.layers.6.mlp.fc2.bias
[ 0.0764    0.03943  -0.1373    0.05814   0.03958   0.07416   0.0571
 -0.00368  -0.006153  0.01209 ] ...(size = 768 end with 0.0181732177734375, sum = 0.276123046875)
text_model.encoder.layers.6.layer_norm2.weight
[2.195 2.244 2.186 2.121 1.639 2.186 2.164 2.283 2.213 2.217] ...(size = 768 end with 2.349609375, sum = 1669.0)
text_model.encoder.layers.6.layer_norm2.bias
[ 0.1328   1.049   -0.44    -0.3508  -0.1573   0.1047   0.3462  -0.3606
 -0.5312  -0.11505] ...(size = 768 end with 1.0615234375, sum = 0.79833984375)
text_model.encoder.layers.7.self_attn.k_proj.bias
[-0.00931    0.01232   -0.002289   0.005943  -0.001903   0.03967
  0.01732    0.0007343  0.0163    -0.003777 ] ...(size = 768 end with -0.005168914794921875, sum = 0.49169921875)
text_model.encoder.layers.7.self_attn.v_proj.bias
[-0.03796   0.003035  0.0282   -0.034    -0.05225  -0.0353   -0.09576
  0.02113   0.04666   0.04767 ] ...(size = 768 end with 0.0243072509765625, sum = 1.3759765625)
text_model.encoder.layers.7.self_attn.q_proj.bias
[-0.2406  0.2976  0.3762 -0.1519 -0.2314  0.8965  0.2832 -0.1705  0.1742
 -0.3435] ...(size = 768 end with 0.023681640625, sum = -9.9609375)
text_model.encoder.layers.7.self_attn.out_proj.bias
[-0.001656  -0.0682    -0.006268  -0.0011215  0.01794   -0.02936
  0.02592   -0.01593    0.01796   -0.0195   ] ...(size = 768 end with -0.0445556640625, sum = 0.5234375)
text_model.encoder.layers.7.layer_norm1.weight
[1.549 1.64  1.6   1.589 1.633 1.64  1.543 1.599 1.594 1.624] ...(size = 768 end with 1.64453125, sum = 1225.0)
text_model.encoder.layers.7.layer_norm1.bias
[ 0.0992   0.04385 -0.1775   0.032    0.07983  0.2203   0.09344  0.03696
 -0.11444 -0.01236] ...(size = 768 end with -0.004535675048828125, sum = 2.95703125)
text_model.encoder.layers.7.mlp.fc1.bias
[-0.354  -0.2788 -0.3865 -0.2266 -0.3882 -0.3728 -0.3074 -0.3887 -0.3381
 -0.322 ] ...(size = 3072 end with -0.2264404296875, sum = -888.0)
text_model.encoder.layers.7.mlp.fc2.bias
[ 0.044     0.044    -0.04034   0.07825   0.003208 -0.006916  0.0635
  0.000622  0.02325  -0.05026 ] ...(size = 768 end with -0.0142974853515625, sum = 0.126708984375)
text_model.encoder.layers.7.layer_norm2.weight
[2.264  2.156  2.271  2.242  1.7295 2.227  2.223  2.193  2.293  2.305 ] ...(size = 768 end with 2.361328125, sum = 1722.0)
text_model.encoder.layers.7.layer_norm2.bias
[ 0.1621   0.1321  -0.8623  -0.0336   0.1501   0.05414  0.1869   0.04797
  0.1135  -0.01724] ...(size = 768 end with 0.64013671875, sum = 10.703125)
text_model.encoder.layers.8.self_attn.k_proj.bias
[-0.02374  -0.04013   0.0226    0.02937  -0.0718   -0.003748  0.001768
 -0.03247  -0.002567 -0.0328  ] ...(size = 768 end with 0.004638671875, sum = 0.22119140625)
text_model.encoder.layers.8.self_attn.v_proj.bias
[ 0.01316   0.0447   -0.006905 -0.0266    0.0158    0.03647   0.006744
  0.01953  -0.02092  -0.0598  ] ...(size = 768 end with 0.007251739501953125, sum = -1.376953125)
text_model.encoder.layers.8.self_attn.q_proj.bias
[-0.03387  0.595   -0.347   -0.3757   0.2393   0.02971  0.1929   0.2554
  0.1009   0.4797 ] ...(size = 768 end with -0.25390625, sum = -7.58984375)
text_model.encoder.layers.8.self_attn.out_proj.bias
[-0.03275  -0.03726   0.0706   -0.0494   -0.08563  -0.1174    0.002825
  0.03528   0.02748  -0.0739  ] ...(size = 768 end with -0.0345458984375, sum = 0.0689697265625)
text_model.encoder.layers.8.layer_norm1.weight
[1.793 1.783 1.78  1.682 1.618 1.818 1.828 1.816 1.819 1.749] ...(size = 768 end with 1.7216796875, sum = 1341.0)
text_model.encoder.layers.8.layer_norm1.bias
[ 0.1095    0.1203   -0.2264    0.01363   0.07715   0.2076    0.1273
  0.05344  -0.1876   -0.003767] ...(size = 768 end with 0.0107269287109375, sum = 3.05078125)
text_model.encoder.layers.8.mlp.fc1.bias
[-0.2454  -0.34    -0.386   -0.2878  -0.2932  -0.1472  -0.06012 -0.3394
 -0.3198  -0.3203 ] ...(size = 3072 end with -0.1424560546875, sum = -913.0)
text_model.encoder.layers.8.mlp.fc2.bias
[ 0.02159 -0.03897  0.04706 -0.03928 -0.04865 -0.04865  0.0691   0.05264
  0.05444 -0.03244] ...(size = 768 end with -0.0007009506225585938, sum = 0.267333984375)
text_model.encoder.layers.8.layer_norm2.weight
[2.37  2.23  2.18  2.262 1.878 2.447 2.227 2.27  2.328 2.453] ...(size = 768 end with 2.3671875, sum = 1770.0)
text_model.encoder.layers.8.layer_norm2.bias
[-0.2197  0.3354 -0.4778  0.2296 -0.257  -0.278   0.268   0.1041 -0.382
 -0.284 ] ...(size = 768 end with 0.263671875, sum = -16.09375)
text_model.encoder.layers.9.self_attn.k_proj.bias
[ 0.04285  -0.0204   -0.00933  -0.00813   0.0238   -0.01161   0.012924
  0.013016 -0.023     0.002428] ...(size = 768 end with -0.1544189453125, sum = 0.9970703125)
text_model.encoder.layers.9.self_attn.v_proj.bias
[-0.0349   -0.041     0.0311    0.02191   0.02054  -0.002764  0.00368
 -0.02979   0.06305   0.05273 ] ...(size = 768 end with -0.006984710693359375, sum = 1.494140625)
text_model.encoder.layers.9.self_attn.q_proj.bias
[-0.3987    0.2491    0.1892   -0.013466  0.09534   0.06223   0.04962
 -0.1699    0.04456  -0.2915  ] ...(size = 768 end with 0.51416015625, sum = -14.296875)
text_model.encoder.layers.9.self_attn.out_proj.bias
[-0.0707  -0.04578  0.091   -0.0929  -0.1055  -0.1018  -0.0258  -0.0195
  0.09906 -0.05978] ...(size = 768 end with 0.023834228515625, sum = 0.2578125)
text_model.encoder.layers.9.layer_norm1.weight
[1.63  1.799 1.665 1.674 1.625 1.743 1.635 1.595 1.783 1.715] ...(size = 768 end with 1.646484375, sum = 1312.0)
text_model.encoder.layers.9.layer_norm1.bias
[ 0.1348   0.0495  -0.1992  -0.02518  0.1837   0.1461   0.1409   0.06854
 -0.1594  -0.0622 ] ...(size = 768 end with -0.01383209228515625, sum = 4.38671875)
text_model.encoder.layers.9.mlp.fc1.bias
[-0.2388  -0.3625  -0.08655 -0.247   -0.3867  -0.2485  -0.2224  -0.3096
 -0.374   -0.2546 ] ...(size = 3072 end with -0.12060546875, sum = -903.5)
text_model.encoder.layers.9.mlp.fc2.bias
[ 0.01605  0.0102  -0.00866 -0.04434 -0.0706   0.01116 -0.03613 -0.0557
  0.0898  -0.07855] ...(size = 768 end with 0.040557861328125, sum = 0.07568359375)
text_model.encoder.layers.9.layer_norm2.weight
[2.559 2.33  2.371 2.398 1.955 2.623 2.406 2.42  2.543 2.293] ...(size = 768 end with 2.443359375, sum = 1856.0)
text_model.encoder.layers.9.layer_norm2.bias
[ 0.02994 -0.3015   0.1412  -0.3464  -0.251   -0.563    0.2264   0.246
  0.1647  -0.4207 ] ...(size = 768 end with 0.069580078125, sum = -8.5703125)
text_model.encoder.layers.10.self_attn.k_proj.bias
[ 0.000829   0.002005  -0.006413   0.002409   0.002234  -0.0005426
  0.007      0.00899    0.01036   -0.001621 ] ...(size = 768 end with 0.054168701171875, sum = 0.59228515625)
text_model.encoder.layers.10.self_attn.v_proj.bias
[ 0.02965  0.02142 -0.0258   0.01959  0.01284 -0.04712  0.02307 -0.03647
 -0.01506  0.1173 ] ...(size = 768 end with 0.032806396484375, sum = -1.9951171875)
text_model.encoder.layers.10.self_attn.q_proj.bias
[-0.11414  0.1932   0.1205   0.2396  -0.05798  0.368   -0.3896   0.04245
 -0.01573 -0.0666 ] ...(size = 768 end with 0.019317626953125, sum = 9.8828125)
text_model.encoder.layers.10.self_attn.out_proj.bias
[-0.10736   0.10443   0.0734   -0.06793  -0.0929   -0.0867   -0.12103
 -0.0536    0.1763   -0.006317] ...(size = 768 end with 0.08203125, sum = 0.6962890625)
text_model.encoder.layers.10.layer_norm1.weight
[1.862  1.803  1.7705 1.781  1.541  1.761  1.764  1.665  1.708  1.769 ] ...(size = 768 end with 1.744140625, sum = 1353.0)
text_model.encoder.layers.10.layer_norm1.bias
[ 0.1571   0.1052  -0.2185  -0.03635  0.182    0.1725   0.1329   0.0708
 -0.1926  -0.09216] ...(size = 768 end with -0.00167083740234375, sum = 5.05859375)
text_model.encoder.layers.10.mlp.fc1.bias
[-0.327  -0.238  -0.3926 -0.3909 -0.2324 -0.3132 -0.1016 -0.2375 -0.259
 -0.245 ] ...(size = 3072 end with -0.293212890625, sum = -860.5)
text_model.encoder.layers.10.mlp.fc2.bias
[-0.03647  0.1627  -0.06024 -0.00979 -0.0443   0.1178   0.09424 -0.1334
  0.03613  0.02902] ...(size = 768 end with 0.061553955078125, sum = -0.634765625)
text_model.encoder.layers.10.layer_norm2.weight
[2.283 2.262 2.273 2.275 2.268 2.49  2.484 2.371 2.527 2.236] ...(size = 768 end with 2.388671875, sum = 1806.0)
text_model.encoder.layers.10.layer_norm2.bias
[ 0.0866  -0.293    0.1976  -0.12164 -0.389   -0.2184  -0.1244   0.1483
  0.06433 -0.0778 ] ...(size = 768 end with 0.12176513671875, sum = -18.203125)
text_model.encoder.layers.11.self_attn.k_proj.bias
[ 0.000508  -0.00256    0.004627   0.00334   -0.00197    0.001952
  0.000587  -0.0004306 -0.01877   -0.0004332] ...(size = 768 end with 0.0004892349243164062, sum = 0.067626953125)
text_model.encoder.layers.11.self_attn.v_proj.bias
[ 0.04968   0.0457    0.0467    0.017     0.004368  0.1133    0.03278
 -0.0453    0.07526  -0.03075 ] ...(size = 768 end with -0.0736083984375, sum = 0.58349609375)
text_model.encoder.layers.11.self_attn.q_proj.bias
[ 0.1714    0.2435    0.2001   -0.10913  -0.1874   -0.010254  0.05444
 -0.03065  -1.839     0.1381  ] ...(size = 768 end with -0.031402587890625, sum = 12.1328125)
text_model.encoder.layers.11.self_attn.out_proj.bias
[-0.3293   0.3857  -0.1589  -0.0797  -0.1267  -0.162    0.1059  -0.2961
  0.2302   0.03647] ...(size = 768 end with 0.258544921875, sum = 0.53076171875)
text_model.encoder.layers.11.layer_norm1.weight
[1.885 1.835 1.877 1.881 1.557 1.884 1.892 1.811 1.987 1.898] ...(size = 768 end with 1.8310546875, sum = 1444.0)
text_model.encoder.layers.11.layer_norm1.bias
[ 0.1498   0.0908  -0.1123  -0.02408  0.2125   0.2267   0.1572   0.2183
 -0.2458  -0.0884 ] ...(size = 768 end with 0.0787353515625, sum = 4.86328125)
text_model.encoder.layers.11.mlp.fc1.bias
[-0.1271 -0.1493 -0.2289 -0.3806 -0.1064 -0.2434 -0.1759 -0.2068 -0.266
 -0.0898] ...(size = 3072 end with -0.042388916015625, sum = -803.0)
text_model.encoder.layers.11.mlp.fc2.bias
[ 0.2559   -0.262     0.2349    0.1392   -0.00136   0.04492   0.11615
  0.011955 -0.2246    0.1194  ] ...(size = 768 end with -0.06005859375, sum = -1.0361328125)
text_model.encoder.layers.11.layer_norm2.weight
[1.745  1.792  1.786  1.706  2.227  1.77   1.6455 1.703  1.794  1.714 ] ...(size = 768 end with 1.740234375, sum = 1348.0)
text_model.encoder.layers.11.layer_norm2.bias
[-0.01553 -0.09174 -0.1405   0.02913 -0.2947   0.2324   0.1465   0.1382
 -0.14    -0.1125 ] ...(size = 768 end with 0.175048828125, sum = -1.33203125)
text_model.final_layer_norm.weight
[0.979  0.929  1.051  0.9834 1.363  0.982  0.896  0.99   0.972  1.02  ] ...(size = 768 end with 0.97802734375, sum = 763.5)
text_model.final_layer_norm.bias
[-0.3098   0.08655 -0.1781  -0.2128   0.01031 -0.218    0.02681 -0.1241
  0.11346 -0.1087 ] ...(size = 768 end with 0.09539794921875, sum = -85.0625)
onnx::Gather_2078
[0 1 2 3 4 5 6 7 8 9] ...(size = 77 end with 76, sum = 2926)
onnx::MatMul_2079
[ 0.01387  -0.05862  -0.02113   0.001622 -0.01461   0.00587  -0.0089
  0.02641  -0.0192   -0.02936 ] ...(size = 589824 end with 0.04248046875, sum = 14.1796875)
onnx::MatMul_2080
[-0.004616 -0.02571  -0.01325   0.001405 -0.0126    0.02467   0.01444
 -0.0194    0.01913  -0.02888 ] ...(size = 589824 end with 0.0048828125, sum = -11.890625)
onnx::MatMul_2091
[ 0.00655   0.003769  0.008736 -0.02274  -0.003893  0.001189  0.005108
  0.01107  -0.01677   0.001584] ...(size = 589824 end with 0.0030460357666015625, sum = -4.00390625)
onnx::MatMul_2127
[ 0.003212  -0.00932    0.0005665 -0.02193   -0.007694   0.004013
 -0.010796  -0.003586  -0.005844  -0.00641  ] ...(size = 589824 end with 0.007434844970703125, sum = 0.69873046875)
onnx::MatMul_2128
[ 0.04016    0.03204   -0.007206   0.02037   -0.008064  -0.0002044
 -0.01064   -0.001217  -0.00568   -0.01247  ] ...(size = 2359296 end with -0.01172637939453125, sum = -656.5)
onnx::MatMul_2129
[-0.000947  0.00071   0.001316  0.003325 -0.003906 -0.02774   0.00888
  0.01229   0.0097    0.02342 ] ...(size = 2359296 end with -0.0009479522705078125, sum = 18.953125)
onnx::MatMul_2130
[ 0.003275   0.005028   0.0001836 -0.005215   0.02411   -0.0225
  0.0642     0.01918    0.0559    -0.02936  ] ...(size = 589824 end with 0.0004582405090332031, sum = -1.1611328125)
onnx::MatMul_2131
[-0.00819  -0.002577 -0.01907   0.04016   0.001599  0.00588  -0.04495
 -0.001029  0.01974   0.01011 ] ...(size = 589824 end with -0.0077667236328125, sum = -1.5390625)
onnx::MatMul_2142
[ 0.0353    0.02858   0.0019   -0.003832 -0.01359   0.01962  -0.01067
 -0.002241 -0.004936 -0.002628] ...(size = 589824 end with -0.00940704345703125, sum = -4.60546875)
onnx::MatMul_2178
[ 0.0056    0.02176   0.00069   0.02724   0.004948  0.0348    0.007084
 -0.02173  -0.01159   0.02597 ] ...(size = 589824 end with 0.01329803466796875, sum = -2.78125)
onnx::MatMul_2179
[ 0.0344   -0.01005  -0.0169   -0.013756  0.01323  -0.0191    0.003515
  0.0224    0.013916 -0.002207] ...(size = 2359296 end with -0.019561767578125, sum = 376.25)
onnx::MatMul_2180
[ 0.002384 -0.003323 -0.02031   0.007812 -0.01361  -0.00735   0.00153
  0.00908  -0.01359  -0.000916] ...(size = 2359296 end with -0.011077880859375, sum = 8.3125)
onnx::MatMul_2181
[-0.03342  -0.006687 -0.00802  -0.00522   0.006012  0.004177 -0.009254
  0.00781   0.01761   0.00518 ] ...(size = 589824 end with -0.001983642578125, sum = -0.1798095703125)
onnx::MatMul_2182
[-0.00445   0.003239  0.003319  0.01406   0.01145  -0.004986  0.001602
  0.04227   0.01044   0.00606 ] ...(size = 589824 end with 0.044952392578125, sum = -6.0078125)
onnx::MatMul_2193
[-0.00193  -0.00426  -0.00792  -0.000591 -0.01514  -0.02072   0.01174
 -0.00788  -0.00402   0.02562 ] ...(size = 589824 end with 0.0117645263671875, sum = -5.0078125)
onnx::MatMul_2229
[ 0.005795  0.001066 -0.02344   0.002197  0.01576   0.001766  0.0092
 -0.009995  0.02136   0.011536] ...(size = 589824 end with -0.00312042236328125, sum = 0.6279296875)
onnx::MatMul_2230
[ 0.02025  0.02794 -0.01005  0.02783  0.01213  0.0454   0.01678 -0.0285
  0.01075 -0.00343] ...(size = 2359296 end with 0.0142669677734375, sum = 0.62158203125)
onnx::MatMul_2231
[-0.0104   -0.00168  -0.01152  -0.002565 -0.00446   0.01382  -0.010666
  0.001764 -0.02306  -0.01196 ] ...(size = 2359296 end with -0.006805419921875, sum = -0.55029296875)
onnx::MatMul_2232
[-0.01855   0.03049   0.002039  0.02998  -0.02187   0.01041   0.01619
 -0.00655   0.01488   0.05533 ] ...(size = 589824 end with -0.007511138916015625, sum = -5.46484375)
onnx::MatMul_2233
[ 0.004875  -0.02968    0.0001197  0.01307   -0.0173     0.00789
 -0.01083   -0.03087   -0.01736   -0.0127   ] ...(size = 589824 end with 0.0258331298828125, sum = 1.115234375)
onnx::MatMul_2244
[ 0.01884   -0.01976    0.02423    0.00841   -0.01572    0.00271
 -0.01478   -0.010574  -0.02931   -0.0007877] ...(size = 589824 end with 0.00225067138671875, sum = 3.19921875)
onnx::MatMul_2280
[-0.00721  -0.02043  -0.01199   0.000975  0.013214 -0.02335   0.01564
  0.002445  0.00595  -0.003471] ...(size = 589824 end with -0.03424072265625, sum = 1.146484375)
onnx::MatMul_2281
[ 0.01808   -0.0007424 -0.006176  -0.03903    0.03906    0.02333
  0.01202   -0.01139    0.03738   -0.02094  ] ...(size = 2359296 end with 0.031005859375, sum = -252.625)
onnx::MatMul_2282
[ 0.005646  0.002289 -0.00236   0.007763 -0.01387  -0.02081   0.01378
 -0.00606   0.010086  0.010414] ...(size = 2359296 end with 0.0170440673828125, sum = 7.80859375)
onnx::MatMul_2283
[-8.2932e-03  5.5511e-02  1.4305e-02 -2.1408e-02 -6.4201e-03  1.0468e-02
 -1.7223e-03  1.5373e-02 -3.1204e-02 -4.4107e-06] ...(size = 589824 end with 0.0033550262451171875, sum = 7.78515625)
onnx::MatMul_2284
[-0.02005  -0.00853  -0.02675  -0.011795  0.01432   0.001106  0.014915
  0.03105  -0.01811   0.01794 ] ...(size = 589824 end with 0.0107421875, sum = -4.1484375)
onnx::MatMul_2295
[-0.011505    0.0008516  -0.01646     0.01485    -0.01794     0.01845
  0.00849     0.00010765  0.00886     0.005245  ] ...(size = 589824 end with -0.019927978515625, sum = -1.8056640625)
onnx::MatMul_2331
[ 0.003263 -0.008804 -0.003181 -0.00891   0.01259   0.002356 -0.01371
 -0.003365  0.00951  -0.01747 ] ...(size = 589824 end with -0.0150909423828125, sum = 1.3056640625)
onnx::MatMul_2332
[-0.001751  -0.00605   -0.00408    0.00543   -0.01533   -0.0003202
 -0.014824   0.02592    0.02695   -0.0455   ] ...(size = 2359296 end with 0.0208587646484375, sum = -120.375)
onnx::MatMul_2333
[ 0.01189   0.006104  0.002804 -0.01335   0.02927   0.01814   0.00826
 -0.0348    0.006176  0.01877 ] ...(size = 2359296 end with 0.01261138916015625, sum = 5.34375)
onnx::MatMul_2334
[-0.003891 -0.01519   0.00417   0.01273   0.03757   0.04797   0.03845
  0.00961  -0.01294  -0.00433 ] ...(size = 589824 end with 0.0041656494140625, sum = 5.1640625)
onnx::MatMul_2335
[ 0.00685   0.01715  -0.0218    0.001363 -0.003378  0.0024   -0.01477
 -0.02156  -0.000622 -0.00629 ] ...(size = 589824 end with -0.0186767578125, sum = -1.4169921875)
onnx::MatMul_2346
[-0.003237  0.014534 -0.02437   0.02496  -0.02493   0.00447  -0.003372
  0.00782  -0.01978   0.004475] ...(size = 589824 end with 0.0122833251953125, sum = -7.90234375)
onnx::MatMul_2382
[ 0.005783  -0.0001541 -0.01271    0.02156    0.00626   -0.003357
  0.00775    0.01645   -0.012215  -0.004543 ] ...(size = 589824 end with 0.01523590087890625, sum = 1.271484375)
onnx::MatMul_2383
[-0.0219    0.003435  0.01863  -0.01768  -0.02881   0.006935  0.004383
  0.00908  -0.02228   0.00483 ] ...(size = 2359296 end with 0.000339508056640625, sum = 355.0)
onnx::MatMul_2384
[-0.003952   0.01021   -0.02469   -0.00868    0.0001849 -0.003702
  0.00973    0.0211    -0.011     -0.01659  ] ...(size = 2359296 end with -0.000164031982421875, sum = 0.1785888671875)
onnx::MatMul_2385
[ 0.04202  -0.02606   0.0267   -0.01987  -0.013405 -0.01631  -0.0193
 -0.00225  -0.00978   0.007736] ...(size = 589824 end with 0.007129669189453125, sum = -7.3515625)
onnx::MatMul_2386
[-0.0356    -0.006866  -0.01393    0.02908    0.01945    0.01145
 -0.0008287 -0.0117     0.02354    0.02165  ] ...(size = 589824 end with -0.00566864013671875, sum = 0.1593017578125)
onnx::MatMul_2397
[ 0.01171   -0.03152    0.0001947  0.003027  -0.02301    0.01149
  0.02606   -0.00951   -0.02612    0.01329  ] ...(size = 589824 end with 0.004222869873046875, sum = -3.212890625)
onnx::MatMul_2433
[-0.005543  0.02098   0.01883  -0.008865 -0.009575  0.01138   0.00906
 -0.02402  -0.01108   0.02403 ] ...(size = 589824 end with 0.023529052734375, sum = -1.70703125)
onnx::MatMul_2434
[-0.004772  0.01137  -0.02321  -0.002926  0.007473 -0.000793 -0.01077
  0.001445  0.00117   0.014   ] ...(size = 2359296 end with -0.00902557373046875, sum = 232.25)
onnx::MatMul_2435
[-0.02026   0.00792   0.01859   0.001889 -0.010056 -0.03065   0.02354
  0.02942  -0.01688   0.01096 ] ...(size = 2359296 end with -0.018218994140625, sum = -2.029296875)
onnx::MatMul_2436
[-9.018e-03  7.347e-03  5.295e-03 -5.600e-03  5.222e-03 -8.430e-03
 -3.041e-02 -1.733e-02 -2.777e-03 -9.459e-05] ...(size = 589824 end with 0.0306854248046875, sum = 1.283203125)
onnx::MatMul_2437
[ 0.000921  0.00855   0.003023  0.001785 -0.0364    0.03116  -0.03024
 -0.007378 -0.012505  0.01146 ] ...(size = 589824 end with -0.0140838623046875, sum = -2.48828125)
onnx::MatMul_2448
[ 0.00879   0.00866   0.01319  -0.02159   0.006607  0.01714  -0.00924
 -0.03522  -0.001007  0.01005 ] ...(size = 589824 end with 0.00623321533203125, sum = 6.62890625)
onnx::MatMul_2484
[-0.0192   -0.03006   0.014175  0.01807  -0.01249  -0.03598   0.01455
 -0.01045  -0.01602  -0.01285 ] ...(size = 589824 end with -0.004970550537109375, sum = 1.17578125)
onnx::MatMul_2485
[ 0.02486  -0.03165  -0.035     0.01101   0.003822 -0.004963  0.02792
 -0.01111   0.02707  -0.00446 ] ...(size = 2359296 end with -0.01192474365234375, sum = 0.435791015625)
onnx::MatMul_2486
[ 0.01718   0.01645  -0.001115  0.002676 -0.00513  -0.01663   0.006615
 -0.00891  -0.02707   0.02263 ] ...(size = 2359296 end with -0.00800323486328125, sum = -0.9169921875)
onnx::MatMul_2487
[-0.02396   -0.000908  -0.02428   -0.0009747  0.005913   0.0002666
  0.005928   0.005726   0.014626   0.01095  ] ...(size = 589824 end with -0.0019588470458984375, sum = 5.80859375)
onnx::MatMul_2488
[ 0.04648  -0.008644  0.02113  -0.00874  -0.04742  -0.014244  0.01392
 -0.01823  -0.001894 -0.01016 ] ...(size = 589824 end with 0.0035381317138671875, sum = -5.87890625)
onnx::MatMul_2499
[-8.649e-05 -3.012e-02  5.875e-03  1.889e-02  9.521e-03  1.400e-02
  2.037e-02 -4.555e-03  1.758e-04 -3.538e-03] ...(size = 589824 end with -0.0119476318359375, sum = -0.89404296875)
onnx::MatMul_2535
[ 1.698e-02 -4.172e-06 -9.972e-03 -1.230e-03  3.625e-02 -6.180e-03
 -2.357e-02  1.955e-03 -2.777e-02 -4.585e-03] ...(size = 589824 end with -0.007411956787109375, sum = 2.12109375)
onnx::MatMul_2536
[-7.618e-03 -8.163e-03 -2.979e-03  1.869e-02 -2.214e-02  9.598e-03
 -4.963e-03  5.126e-05 -3.214e-02 -1.817e-02] ...(size = 2359296 end with 0.0296173095703125, sum = 553.5)
onnx::MatMul_2537
[-0.01223    0.011894   0.005848   0.0004575  0.02034    0.007046
  0.00856   -0.01508   -0.02802    0.003736 ] ...(size = 2359296 end with -0.0266265869140625, sum = -6.76953125)
onnx::MatMul_2538
[ 0.02184   -0.004017   0.02547   -0.007774  -0.015396   0.003746
  0.0007257 -0.03403   -0.0001535  0.0054   ] ...(size = 589824 end with 0.0186920166015625, sum = 0.654296875)
onnx::MatMul_2539
[ 0.01755   -0.04144   -0.0163     0.02483    0.001495   0.008194
  0.01717   -0.02687   -0.01999    0.0003123] ...(size = 589824 end with 0.01331329345703125, sum = -1.521484375)
onnx::MatMul_2550
[-0.01538   0.01712   0.00462  -0.00727   0.013985 -0.00855  -0.0094
 -0.03156  -0.01379   0.01115 ] ...(size = 589824 end with 0.0160064697265625, sum = 0.228759765625)
onnx::MatMul_2586
[ 0.01558  -0.00536  -0.02576  -0.002552 -0.02866  -0.007465  0.01855
 -0.002832  0.01683  -0.001639] ...(size = 589824 end with 0.0175628662109375, sum = -0.8994140625)
onnx::MatMul_2587
[ 0.0171   -0.0364   -0.01126  -0.002525 -0.003836  0.01247  -0.01738
  0.01239   0.002491 -0.002054] ...(size = 2359296 end with 0.005611419677734375, sum = 482.0)
onnx::MatMul_2588
[ 1.442e-02 -7.637e-03  1.245e-04  1.477e-02 -1.581e-02  8.947e-05
 -1.669e-02  1.213e-02 -9.804e-03 -8.774e-03] ...(size = 2359296 end with -0.00617218017578125, sum = -1.80859375)
onnx::MatMul_2589
[ 0.002958 -0.01762   0.00331  -0.02638  -0.02248   0.02591  -0.011375
  0.03925   0.02005   0.01474 ] ...(size = 589824 end with -0.0201568603515625, sum = -3.5546875)
onnx::MatMul_2590
[ 0.02725   0.03114  -0.012436 -0.003183  0.03014   0.0137    0.01788
 -0.005657 -0.003983 -0.02429 ] ...(size = 589824 end with 0.0112152099609375, sum = 3.572265625)
onnx::MatMul_2601
[ 0.01729   0.00575   0.006496 -0.00802   0.004047  0.02055   0.004612
  0.02652  -0.004757  0.01982 ] ...(size = 589824 end with 0.01165771484375, sum = 0.44287109375)
onnx::MatMul_2637
[-0.002792 -0.01645  -0.02357   0.02483  -0.05984  -0.042     0.02145
  0.02771  -0.00866  -0.02638 ] ...(size = 589824 end with 0.025421142578125, sum = -0.7041015625)
onnx::MatMul_2638
[-0.01929  -0.03008  -0.001552  0.01836   0.003761 -0.006695 -0.002556
 -0.00808   0.01426  -0.01207 ] ...(size = 2359296 end with 0.02191162109375, sum = 668.5)
onnx::MatMul_2639
[-0.01714  -0.02237   0.02863   0.04248  -0.002851 -0.02744   0.008644
  0.01659   0.01112   0.002785] ...(size = 2359296 end with 0.00290679931640625, sum = -1.6162109375)
onnx::MatMul_2640
[ 0.02982  -0.00957   0.00797  -0.00795  -0.00269  -0.02252  -0.00443
  0.012115  0.0058   -0.00328 ] ...(size = 589824 end with 0.004741668701171875, sum = -5.296875)
onnx::MatMul_2641
[-0.005154  0.005066 -0.007183  0.00336  -0.008484  0.01707  -0.01378
 -0.003906  0.01666  -0.00633 ] ...(size = 589824 end with 0.0135345458984375, sum = -0.345458984375)
onnx::MatMul_2652
[-0.004364   0.0009007 -0.001807  -0.0388    -0.002195   0.001913
  0.01436   -0.02345    0.02304    0.0001968] ...(size = 589824 end with -0.0181884765625, sum = -1.509765625)
onnx::MatMul_2688
[-0.002144 -0.003027  0.006733  0.005466  0.02087   0.003475  0.01567
  0.01826   0.005703  0.00757 ] ...(size = 589824 end with -0.0217742919921875, sum = -0.12225341796875)
onnx::MatMul_2689
[ 0.004383 -0.002218  0.00551   0.02098   0.0219    0.002392 -0.00809
  0.005737  0.01804   0.02327 ] ...(size = 2359296 end with -0.0033054351806640625, sum = 459.25)
onnx::MatMul_2690
[-0.01151   0.00921   0.003038 -0.00982  -0.01406  -0.0206    0.002092
  0.01645   0.002972 -0.02274 ] ...(size = 2359296 end with -0.0026378631591796875, sum = 44.71875)

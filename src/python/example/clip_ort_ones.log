ONNX model check passed!
Importing ONNX model into ONNX Runtime...
Execution Providers: ['CPUExecutionProvider']
last_hidden_state
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 59136 end with -1.849609375, sum = -6000.0)
pooler_output
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 768 end with 0.04644775390625, sum = -80.5625)
/text_model/Constant_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Constant_1_output_0
[-1 77] ...(size = 2 end with 77, sum = 76)
/text_model/Reshape_output_0
[1 1 1 1 1 1 1 1 1 1] ...(size = 77 end with 1, sum = 77)
/text_model/embeddings/token_embedding/Gather_output_0
[ 0.01521    0.02618   -0.01317   -0.0004854  0.00652   -0.01426
 -0.005135  -0.00672    0.02606   -0.009384 ] ...(size = 59136 end with 0.01210784912109375, sum = 2.34375)
/text_model/embeddings/position_embedding/Gather_output_0
[ 0.001584  0.002008  0.000208 -0.001874 -0.000706  0.002995  0.000633
 -0.002918  0.001847 -0.001681] ...(size = 59136 end with -0.0309600830078125, sum = -17.984375)
/text_model/embeddings/Add_output_0
[ 0.0168    0.0282   -0.01296  -0.00236   0.005814 -0.01126  -0.0045
 -0.00964   0.02791  -0.01106 ] ...(size = 59136 end with -0.01885986328125, sum = -15.6328125)
/text_model/Constant_2_output_0
[-65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with -65504.0, sum = -inf)
/text_model/Trilu_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/Constant_3_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Unsqueeze_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/Cast_output_0
[     0. -65504. -65504. -65504. -65504. -65504. -65504. -65504. -65504.
 -65504.] ...(size = 5929 end with 0.0, sum = -inf)
/text_model/encoder/layers.0/layer_norm1/ReduceMean_output_0
[6.1655e-04 1.9610e-04 2.3198e-04 2.9707e-04 2.8920e-04 2.1195e-04
 1.3888e-04 5.0128e-05 1.1295e-04 1.6117e-04] ...(size = 77 end with -0.00038886070251464844, sum = -0.020355224609375)
/text_model/encoder/layers.0/layer_norm1/Sub_output_0
[ 0.01617   0.02757  -0.01358  -0.002975  0.005196 -0.01188  -0.00512
 -0.010254  0.0273   -0.01168 ] ...(size = 59136 end with -0.018463134765625, sum = -0.0032711029052734375)
/text_model/encoder/layers.0/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.0/layer_norm1/Pow_output_0
[2.618e-04 7.606e-04 1.843e-04 8.881e-06 2.700e-05 1.411e-04 2.623e-05
 1.052e-04 7.448e-04 1.365e-04] ...(size = 59136 end with 0.0003409385681152344, sum = 19.09375)
/text_model/encoder/layers.0/layer_norm1/ReduceMean_1_output_0
[0.000844  0.0002816 0.0002925 0.0002906 0.0002887 0.0002892 0.000287
 0.0002885 0.0002885 0.0002882] ...(size = 77 end with 0.0007171630859375, sum = 0.0248565673828125)
/text_model/encoder/layers.0/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.0/layer_norm1/Add_output_0
[0.000854  0.0002916 0.0003026 0.0003006 0.0002987 0.0002992 0.000297
 0.0002985 0.0002985 0.0002983] ...(size = 77 end with 0.0007271766662597656, sum = 0.0256195068359375)
/text_model/encoder/layers.0/layer_norm1/Sqrt_output_0
[0.02922 0.01707 0.0174  0.01733 0.01729 0.01729 0.01724 0.01727 0.01727
 0.01727] ...(size = 77 end with 0.0269622802734375, sum = 1.3984375)
/text_model/encoder/layers.0/layer_norm1/Div_output_0
[ 0.5537   0.944   -0.4646  -0.10187  0.1779  -0.4065  -0.1752  -0.351
  0.934   -0.3997 ] ...(size = 59136 end with -0.6845703125, sum = -0.03509521484375)
/text_model/encoder/layers.0/layer_norm1/Mul_output_0
[ 1.019   1.558  -0.834  -0.1813  0.314  -0.7188 -0.326  -0.64    1.637
 -0.6943] ...(size = 59136 end with -1.20703125, sum = 194.5)
/text_model/encoder/layers.0/layer_norm1/Add_1_output_0
[ 0.9546  1.368  -0.9004 -0.0654  0.2947 -0.7954 -0.4182 -0.4897  1.482
 -0.6406] ...(size = 59136 end with -1.294921875, sum = 1419.0)
/text_model/encoder/layers.0/self_attn/q_proj/MatMul_output_0
[-0.5527   0.773   -0.02007 -0.02792 -1.338   -1.532   -0.786   -0.912
  0.2856   0.2742 ] ...(size = 59136 end with -3.646484375, sum = -3216.0)
/text_model/encoder/layers.0/self_attn/q_proj/Add_output_0
[-0.7935   0.922    0.4438   0.03995 -0.683   -1.292   -0.7295  -1.037
  0.2617   0.2966 ] ...(size = 59136 end with -3.654296875, sum = -1674.0)
/text_model/encoder/layers.0/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.0/self_attn/Mul_output_0
[-0.0992    0.11523   0.05548   0.004993 -0.0854   -0.1615   -0.0912
 -0.1296    0.0327    0.03708 ] ...(size = 59136 end with -0.456787109375, sum = -209.25)
/text_model/encoder/layers.0/self_attn/k_proj/MatMul_output_0
[ 0.4355   1.094    0.9854   0.3076  -4.188    0.8564   0.08685 -1.678
  0.04486  0.856  ] ...(size = 59136 end with -0.90185546875, sum = 1369.0)
/text_model/encoder/layers.0/self_attn/k_proj/Add_output_0
[ 0.4329   1.091    0.991    0.3083  -4.168    0.857    0.09503 -1.688
  0.05292  0.854  ] ...(size = 59136 end with -0.9150390625, sum = 1409.0)
/text_model/encoder/layers.0/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.0/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.0/self_attn/Reshape_output_0
[ 0.4329   1.091    0.991    0.3083  -4.168    0.857    0.09503 -1.688
  0.05292  0.854  ] ...(size = 59136 end with -0.9150390625, sum = 1409.0)
/text_model/encoder/layers.0/self_attn/Transpose_output_0
[ 0.4329   1.091    0.991    0.3083  -4.168    0.857    0.09503 -1.688
  0.05292  0.854  ] ...(size = 59136 end with -0.9150390625, sum = 1409.0)
/text_model/encoder/layers.0/self_attn/v_proj/MatMul_output_0
[ 0.1072   -0.0853   -0.004593  0.02249  -0.1064   -0.4502   -0.02066
  0.4434    0.586    -0.264   ] ...(size = 59136 end with -0.60107421875, sum = -2136.0)
/text_model/encoder/layers.0/self_attn/v_proj/Add_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.61572265625, sum = -2182.0)
/text_model/encoder/layers.0/self_attn/Reshape_1_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.61572265625, sum = -2182.0)
/text_model/encoder/layers.0/self_attn/Transpose_1_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.61572265625, sum = -2180.0)
/text_model/encoder/layers.0/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.0/self_attn/Reshape_2_output_0
[-0.0992    0.11523   0.05548   0.004993 -0.0854   -0.1615   -0.0912
 -0.1296    0.0327    0.03708 ] ...(size = 59136 end with -0.456787109375, sum = -209.25)
/text_model/encoder/layers.0/self_attn/Transpose_2_output_0
[-0.0992    0.11523   0.05548   0.004993 -0.0854   -0.1615   -0.0912
 -0.1296    0.0327    0.03708 ] ...(size = 59136 end with -0.456787109375, sum = -209.25)
/text_model/encoder/layers.0/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.0/self_attn/Reshape_3_output_0
[-0.0992    0.11523   0.05548   0.004993 -0.0854   -0.1615   -0.0912
 -0.1296    0.0327    0.03708 ] ...(size = 59136 end with -0.456787109375, sum = -209.25)
/text_model/encoder/layers.0/self_attn/Reshape_4_output_0
[ 0.4329   1.091    0.991    0.3083  -4.168    0.857    0.09503 -1.688
  0.05292  0.854  ] ...(size = 59136 end with -0.9150390625, sum = 1409.0)
/text_model/encoder/layers.0/self_attn/Reshape_5_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.61572265625, sum = -2180.0)
/text_model/encoder/layers.0/self_attn/Transpose_3_output_0
[ 0.4329    0.2766    0.2296    0.3386    0.5938    0.734     0.6133
  0.2542   -0.002626  0.05115 ] ...(size = 59136 end with -0.9150390625, sum = 1409.0)
/text_model/encoder/layers.0/self_attn/MatMul_output_0
[1.393   0.4895  0.525   0.642   0.6943  0.604   0.4268  0.253   0.1389
 0.08026] ...(size = 71148 end with 0.1790771484375, sum = inf)
/text_model/encoder/layers.0/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.0/self_attn/Reshape_6_output_0
[1.393   0.4895  0.525   0.642   0.6943  0.604   0.4268  0.253   0.1389
 0.08026] ...(size = 71148 end with 0.1790771484375, sum = inf)
/text_model/encoder/layers.0/self_attn/Add_output_0
[ 1.393e+00 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 0.1790771484375, sum = -inf)
/text_model/encoder/layers.0/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.0/self_attn/Reshape_7_output_0
[ 1.393e+00 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 0.1790771484375, sum = -inf)
/text_model/encoder/layers.0/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.02764892578125, sum = 924.0)
/text_model/encoder/layers.0/self_attn/MatMul_1_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.720703125, sum = -1880.0)
/text_model/encoder/layers.0/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.0/self_attn/Reshape_8_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.720703125, sum = -1880.0)
/text_model/encoder/layers.0/self_attn/Transpose_4_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.720703125, sum = -1879.0)
/text_model/encoder/layers.0/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.0/self_attn/Reshape_9_output_0
[ 0.1123   -0.0821    0.00956   0.014946 -0.09503  -0.4814    0.006195
  0.4314    0.576    -0.2472  ] ...(size = 59136 end with -0.720703125, sum = -1879.0)
/text_model/encoder/layers.0/self_attn/out_proj/MatMul_output_0
[ 0.2756   0.03317 -0.0537   0.196    0.0576   0.0194  -0.0696   0.2952
  0.11536  0.1703 ] ...(size = 59136 end with -0.1910400390625, sum = -16.015625)
/text_model/encoder/layers.0/self_attn/out_proj/Add_output_0
[ 2.0764e-01  1.7500e-04 -1.1894e-02  9.3933e-02  5.2094e-02  2.3682e-02
 -7.3425e-02  2.4683e-01  9.2590e-02  1.6821e-01] ...(size = 59136 end with -0.180908203125, sum = 22.671875)
/text_model/encoder/layers.0/Add_output_0
[ 0.2245   0.02837 -0.02486  0.09155  0.05792  0.01241 -0.07794  0.2372
  0.1205   0.1571 ] ...(size = 59136 end with -0.19970703125, sum = 7.04296875)
/text_model/encoder/layers.0/layer_norm2/ReduceMean_output_0
[0.002586 0.002728 0.00245  0.002403 0.002308 0.002136 0.001978 0.001805
 0.001789 0.001748] ...(size = 77 end with -0.0009703636169433594, sum = 0.00916290283203125)
/text_model/encoder/layers.0/layer_norm2/Sub_output_0
[ 0.2218   0.02579 -0.02745  0.089    0.05533  0.00982 -0.08057  0.2346
  0.1179   0.1545 ] ...(size = 59136 end with -0.19873046875, sum = 0.001979827880859375)
/text_model/encoder/layers.0/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.0/layer_norm2/Pow_output_0
[4.922e-02 6.647e-04 7.534e-04 7.919e-03 3.061e-03 9.650e-05 6.489e-03
 5.502e-02 1.390e-02 2.388e-02] ...(size = 59136 end with 0.03948974609375, sum = 1534.0)
/text_model/encoder/layers.0/layer_norm2/ReduceMean_1_output_0
[0.01637 0.02226 0.02325 0.02332 0.02324 0.02316 0.02313 0.0232  0.02332
 0.02348] ...(size = 77 end with 0.03155517578125, sum = 1.99609375)
/text_model/encoder/layers.0/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.0/layer_norm2/Add_output_0
[0.01639 0.02228 0.02327 0.02333 0.02325 0.02318 0.02313 0.02321 0.02333
 0.0235 ] ...(size = 77 end with 0.031585693359375, sum = 1.9970703125)
/text_model/encoder/layers.0/layer_norm2/Sqrt_output_0
[0.128  0.1493 0.1525 0.1527 0.1525 0.1522 0.1521 0.1523 0.1527 0.1533] ...(size = 77 end with 0.177734375, sum = 12.390625)
/text_model/encoder/layers.0/layer_norm2/Div_output_0
[ 1.733   0.2014 -0.2144  0.695   0.4321  0.0767 -0.629   1.832   0.921
  1.207 ] ...(size = 59136 end with -1.1181640625, sum = 0.0142364501953125)
/text_model/encoder/layers.0/layer_norm2/Mul_output_0
[ 2.682   0.3281 -0.3135  1.054   0.733   0.1178 -1.071   3.023   1.543
  1.864 ] ...(size = 59136 end with -1.8115234375, sum = 404.25)
/text_model/encoder/layers.0/layer_norm2/Add_1_output_0
[ 2.393    1.007   -0.5513   1.779    1.236    0.01531 -1.464    3.783
  1.825    2.14   ] ...(size = 59136 end with -1.826171875, sum = 2862.0)
/text_model/encoder/layers.0/mlp/fc1/MatMul_output_0
[-1.411  0.586 -0.762 -2.828 -1.609 -1.366 -1.231 -1.381 -1.973 -0.814] ...(size = 236544 end with -1.7646484375, sum = -inf)
/text_model/encoder/layers.0/mlp/fc1/Add_output_0
[-1.791   0.1794 -1.061  -3.246  -1.563  -1.464  -1.538  -1.656  -2.242
 -1.055 ] ...(size = 236544 end with -1.95703125, sum = -inf)
/text_model/encoder/layers.0/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.0/mlp/activation_fn/Mul_output_0
[-3.049   0.3054 -1.805  -5.523  -2.662  -2.492  -2.617  -2.82   -3.818
 -1.795 ] ...(size = 236544 end with -3.33203125, sum = -inf)
/text_model/encoder/layers.0/mlp/activation_fn/Sigmoid_output_0
[0.0453  0.5757  0.1414  0.00397 0.0653  0.0764  0.068   0.05627 0.0215
 0.1425 ] ...(size = 236544 end with 0.034515380859375, sum = 21984.0)
/text_model/encoder/layers.0/mlp/activation_fn/Mul_1_output_0
[-0.0811    0.10333  -0.1498   -0.012886 -0.1021   -0.1119   -0.10455
 -0.0932   -0.04825  -0.1503  ] ...(size = 236544 end with -0.0675048828125, sum = -13928.0)
/text_model/encoder/layers.0/mlp/fc2/MatMul_output_0
[-1.389   -0.8525   1.84     0.3936  -0.5405  -1.431   -0.891   -0.89
  1.203   -0.06274] ...(size = 59136 end with -0.137451171875, sum = -32.75)
/text_model/encoder/layers.0/mlp/fc2/Add_output_0
[-1.381  -0.8853  1.842   0.3906 -0.5586 -1.468  -0.8477 -0.899   1.21
 -0.0697] ...(size = 59136 end with -0.1514892578125, sum = 31.96875)
/text_model/encoder/layers.0/Add_1_output_0
[-1.156  -0.857   1.817   0.4822 -0.5005 -1.455  -0.9253 -0.6616  1.33
  0.0874] ...(size = 59136 end with -0.35107421875, sum = 38.96875)
/text_model/encoder/layers.1/layer_norm1/ReduceMean_output_0
[-0.004124  0.003668  0.002687  0.002611  0.00255   0.002426  0.002314
  0.002201  0.002218  0.002214] ...(size = 77 end with -0.0002949237823486328, sum = 0.050689697265625)
/text_model/encoder/layers.1/layer_norm1/Sub_output_0
[-1.152  -0.853   1.821   0.4863 -0.4963 -1.451  -0.9214 -0.6577  1.334
  0.0915] ...(size = 59136 end with -0.350830078125, sum = 0.01551055908203125)
/text_model/encoder/layers.1/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.1/layer_norm1/Pow_output_0
[1.327   0.727   3.318   0.2366  0.2465  2.105   0.849   0.4326  1.78
 0.00838] ...(size = 59136 end with 0.12310791015625, sum = inf)
/text_model/encoder/layers.1/layer_norm1/ReduceMean_1_output_0
[1.969e+02 3.525e-02 3.323e-02 3.262e-02 3.238e-02 3.229e-02 3.220e-02
 3.229e-02 3.232e-02 3.247e-02] ...(size = 77 end with 0.045257568359375, sum = 199.75)
/text_model/encoder/layers.1/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.1/layer_norm1/Add_output_0
[1.969e+02 3.525e-02 3.323e-02 3.262e-02 3.241e-02 3.229e-02 3.220e-02
 3.229e-02 3.235e-02 3.247e-02] ...(size = 77 end with 0.045257568359375, sum = 199.75)
/text_model/encoder/layers.1/layer_norm1/Sqrt_output_0
[14.03    0.1877  0.1823  0.1807  0.18    0.1797  0.1794  0.1797  0.1798
  0.1802] ...(size = 77 end with 0.2127685546875, sum = 28.671875)
/text_model/encoder/layers.1/layer_norm1/Div_output_0
[-0.0821  -0.06076  0.1298   0.03467 -0.03537 -0.1034  -0.0657  -0.04688
  0.0951   0.00652] ...(size = 59136 end with -1.6494140625, sum = 0.0297393798828125)
/text_model/encoder/layers.1/layer_norm1/Mul_output_0
[-0.0895   -0.0698    0.1464    0.03543  -0.04153  -0.1103   -0.0724
 -0.05246   0.10095   0.006756] ...(size = 59136 end with -1.935546875, sum = 869.0)
/text_model/encoder/layers.1/layer_norm1/Add_1_output_0
[ 0.04028  -0.0353   -0.03754   0.0476    0.012764 -0.03986  -0.003237
  0.01115   0.03696   0.02919 ] ...(size = 59136 end with -1.93359375, sum = 803.0)
/text_model/encoder/layers.1/self_attn/q_proj/MatMul_output_0
[-0.1919    -0.1109     0.0863     0.0014305  0.0821     0.083
  0.0182     0.003147   0.1854    -0.005608 ] ...(size = 59136 end with 3.322265625, sum = -2478.0)
/text_model/encoder/layers.1/self_attn/q_proj/Add_output_0
[ 0.1511   -0.1945    0.1287   -0.0913    0.2708    0.2098   -0.0832
 -0.002228 -0.3157    0.0803  ] ...(size = 59136 end with 3.771484375, sum = -2596.0)
/text_model/encoder/layers.1/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.1/self_attn/Mul_output_0
[ 0.01889   -0.0243     0.01608   -0.01141    0.03384    0.02623
 -0.0104    -0.0002785 -0.03946    0.01004  ] ...(size = 59136 end with 0.471435546875, sum = -324.5)
/text_model/encoder/layers.1/self_attn/k_proj/MatMul_output_0
[ 0.4968    0.0959    0.03069  -0.1194    0.06198   0.0951   -0.0192
  0.009865 -0.303     0.02081 ] ...(size = 59136 end with 0.9765625, sum = 1191.0)
/text_model/encoder/layers.1/self_attn/k_proj/Add_output_0
[ 0.4978   0.0914   0.0329  -0.1203   0.0639   0.1009  -0.02122  0.0079
 -0.302    0.01912] ...(size = 59136 end with 0.97998046875, sum = 1240.0)
/text_model/encoder/layers.1/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.1/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.1/self_attn/Reshape_output_0
[ 0.4978   0.0914   0.0329  -0.1203   0.0639   0.1009  -0.02122  0.0079
 -0.302    0.01912] ...(size = 59136 end with 0.97998046875, sum = 1240.0)
/text_model/encoder/layers.1/self_attn/Transpose_output_0
[ 0.4978   0.0914   0.0329  -0.1203   0.0639   0.1009  -0.02122  0.0079
 -0.302    0.01912] ...(size = 59136 end with 0.97998046875, sum = 1241.0)
/text_model/encoder/layers.1/self_attn/v_proj/MatMul_output_0
[ 0.05154   0.02292  -0.0328   -0.00916  -0.0352   -0.0539   -0.0296
  0.002323 -0.03111   0.0375  ] ...(size = 59136 end with -0.03668212890625, sum = -221.375)
/text_model/encoder/layers.1/self_attn/v_proj/Add_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.02215576171875, sum = -204.375)
/text_model/encoder/layers.1/self_attn/Reshape_1_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.02215576171875, sum = -204.375)
/text_model/encoder/layers.1/self_attn/Transpose_1_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.02215576171875, sum = -204.25)
/text_model/encoder/layers.1/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.1/self_attn/Reshape_2_output_0
[ 0.01889   -0.0243     0.01608   -0.01141    0.03384    0.02623
 -0.0104    -0.0002785 -0.03946    0.01004  ] ...(size = 59136 end with 0.471435546875, sum = -324.5)
/text_model/encoder/layers.1/self_attn/Transpose_2_output_0
[ 0.01889   -0.0243     0.01608   -0.01141    0.03384    0.02623
 -0.0104    -0.0002785 -0.03946    0.01004  ] ...(size = 59136 end with 0.471435546875, sum = -324.75)
/text_model/encoder/layers.1/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.1/self_attn/Reshape_3_output_0
[ 0.01889   -0.0243     0.01608   -0.01141    0.03384    0.02623
 -0.0104    -0.0002785 -0.03946    0.01004  ] ...(size = 59136 end with 0.471435546875, sum = -324.75)
/text_model/encoder/layers.1/self_attn/Reshape_4_output_0
[ 0.4978   0.0914   0.0329  -0.1203   0.0639   0.1009  -0.02122  0.0079
 -0.302    0.01912] ...(size = 59136 end with 0.97998046875, sum = 1241.0)
/text_model/encoder/layers.1/self_attn/Reshape_5_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.02215576171875, sum = -204.25)
/text_model/encoder/layers.1/self_attn/Transpose_3_output_0
[ 0.4978 -0.7646 -0.7993 -0.7344 -0.6694 -0.606  -0.5547 -0.498  -0.4358
 -0.3625] ...(size = 59136 end with 0.97998046875, sum = 1240.0)
/text_model/encoder/layers.1/self_attn/MatMul_output_0
[ 0.9395 -0.674  -0.656  -0.683  -0.674  -0.666  -0.654  -0.651  -0.652
 -0.6387] ...(size = 71148 end with 1.2109375, sum = inf)
/text_model/encoder/layers.1/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.1/self_attn/Reshape_6_output_0
[ 0.9395 -0.674  -0.656  -0.683  -0.674  -0.666  -0.654  -0.651  -0.652
 -0.6387] ...(size = 71148 end with 1.2109375, sum = inf)
/text_model/encoder/layers.1/self_attn/Add_output_0
[ 9.395e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 1.2109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.1/self_attn/Reshape_7_output_0
[ 9.395e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 1.2109375, sum = -inf)
/text_model/encoder/layers.1/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.033172607421875, sum = 924.0)
/text_model/encoder/layers.1/self_attn/MatMul_1_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.01407623291015625, sum = -302.75)
/text_model/encoder/layers.1/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.1/self_attn/Reshape_8_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.01407623291015625, sum = -302.75)
/text_model/encoder/layers.1/self_attn/Transpose_4_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.01407623291015625, sum = -302.75)
/text_model/encoder/layers.1/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.1/self_attn/Reshape_9_output_0
[ 0.0407     0.01018   -0.02045    0.002079  -0.00841   -0.02094
 -0.00301    0.0001916 -0.00905    0.02486  ] ...(size = 59136 end with -0.01407623291015625, sum = -302.75)
/text_model/encoder/layers.1/self_attn/out_proj/MatMul_output_0
[-0.007763 -0.008865 -0.005005  0.01245  -0.01348   0.01103   0.002653
  0.02681  -0.013916  0.00889 ] ...(size = 59136 end with -0.019287109375, sum = -1.0859375)
/text_model/encoder/layers.1/self_attn/out_proj/Add_output_0
[ 0.0228     0.006157  -0.02614    0.02881   -0.01949   -0.0009294
  0.04065    0.0746    -0.02681    0.02061  ] ...(size = 59136 end with -0.023101806640625, sum = 26.53125)
/text_model/encoder/layers.1/Add_output_0
[-1.134   -0.8506   1.791    0.511   -0.52    -1.456   -0.885   -0.5874
  1.303    0.10803] ...(size = 59136 end with -0.374267578125, sum = 65.375)
/text_model/encoder/layers.1/layer_norm2/ReduceMean_output_0
[-0.003168  0.004578  0.00358   0.003515  0.003468  0.00333   0.0032
  0.003063  0.003056  0.003033] ...(size = 77 end with -0.00022113323211669922, sum = 0.08526611328125)
/text_model/encoder/layers.1/layer_norm2/Sub_output_0
[-1.13   -0.8477  1.794   0.514  -0.517  -1.453  -0.882  -0.584   1.307
  0.1112] ...(size = 59136 end with -0.3740234375, sum = -0.061279296875)
/text_model/encoder/layers.1/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.1/layer_norm2/Pow_output_0
[1.277   0.7183  3.22    0.2644  0.267   2.111   0.7773  0.341   1.707
 0.01236] ...(size = 59136 end with 0.139892578125, sum = inf)
/text_model/encoder/layers.1/layer_norm2/ReduceMean_1_output_0
[1.968e+02 3.842e-02 3.903e-02 3.909e-02 3.903e-02 3.888e-02 3.873e-02
 3.885e-02 3.885e-02 3.897e-02] ...(size = 77 end with 0.055938720703125, sum = 200.125)
/text_model/encoder/layers.1/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.1/layer_norm2/Add_output_0
[1.968e+02 3.842e-02 3.903e-02 3.909e-02 3.903e-02 3.888e-02 3.873e-02
 3.885e-02 3.888e-02 3.900e-02] ...(size = 77 end with 0.055938720703125, sum = 200.125)
/text_model/encoder/layers.1/layer_norm2/Sqrt_output_0
[14.02    0.196   0.1976  0.1978  0.1976  0.1973  0.1968  0.1971  0.1971
  0.1975] ...(size = 77 end with 0.236572265625, sum = 30.078125)
/text_model/encoder/layers.1/layer_norm2/Div_output_0
[-0.08057 -0.06042  0.1279   0.03665 -0.03683 -0.1036  -0.06287 -0.04163
  0.09314  0.00793] ...(size = 59136 end with -1.5810546875, sum = -0.0005807876586914062)
/text_model/encoder/layers.1/layer_norm2/Mul_output_0
[-0.1504  -0.1075   0.2319   0.06976 -0.0671  -0.1902  -0.1214  -0.0792
  0.187    0.01377] ...(size = 59136 end with -2.91015625, sum = 407.75)
/text_model/encoder/layers.1/layer_norm2/Add_1_output_0
[-0.05035  0.219    0.02153 -0.44    -0.10944 -0.4578   0.8203  -0.354
 -0.3398  -0.04172] ...(size = 59136 end with -2.908203125, sum = -831.5)
/text_model/encoder/layers.1/mlp/fc1/MatMul_output_0
[-2.016 -2.566 -1.284 -1.397 -3.465 -1.528 -2.06  -2.305 -1.379 -2.441] ...(size = 236544 end with -0.06744384765625, sum = -inf)
/text_model/encoder/layers.1/mlp/fc1/Add_output_0
[-2.299 -2.904 -1.235 -1.746 -3.701 -1.986 -2.486 -2.672 -1.72  -2.797] ...(size = 236544 end with -0.342529296875, sum = -inf)
/text_model/encoder/layers.1/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.1/mlp/activation_fn/Mul_output_0
[-3.914 -4.94  -2.104 -2.973 -6.3   -3.38  -4.234 -4.547 -2.926 -4.76 ] ...(size = 236544 end with -0.5830078125, sum = -inf)
/text_model/encoder/layers.1/mlp/activation_fn/Sigmoid_output_0
[0.01958  0.007088 0.1088   0.0487   0.001833 0.0329   0.01431  0.01049
 0.05084  0.00848 ] ...(size = 236544 end with 0.358154296875, sum = 39936.0)
/text_model/encoder/layers.1/mlp/activation_fn/Mul_1_output_0
[-0.045    -0.02058  -0.1344   -0.085    -0.006786 -0.0653   -0.03558
 -0.02803  -0.0874   -0.02371 ] ...(size = 236544 end with -0.12274169921875, sum = -15688.0)
/text_model/encoder/layers.1/mlp/fc2/MatMul_output_0
[ 0.03137 -0.0649   0.06192  0.02469 -0.1741  -0.10504  0.04614 -0.02312
  0.1462  -0.02   ] ...(size = 59136 end with -0.0740966796875, sum = -25.203125)
/text_model/encoder/layers.1/mlp/fc2/Add_output_0
[ 0.05777 -0.02608  0.02242  0.03943 -0.1647  -0.0946  -0.01559  0.01073
  0.2056  -0.03226] ...(size = 59136 end with -0.08990478515625, sum = -0.82861328125)
/text_model/encoder/layers.1/Add_1_output_0
[-1.076   -0.877    1.813    0.5503  -0.6846  -1.551   -0.9004  -0.5767
  1.509    0.07574] ...(size = 59136 end with -0.464111328125, sum = 64.625)
/text_model/encoder/layers.2/layer_norm1/ReduceMean_output_0
[-0.00525   0.00686   0.00379   0.003492  0.003405  0.003263  0.003168
  0.003046  0.003046  0.00304 ] ...(size = 77 end with -0.00033092498779296875, sum = 0.08416748046875)
/text_model/encoder/layers.2/layer_norm1/Sub_output_0
[-1.07   -0.8716  1.819   0.5557 -0.6797 -1.546  -0.895  -0.5713  1.514
  0.081 ] ...(size = 59136 end with -0.4638671875, sum = -0.0767822265625)
/text_model/encoder/layers.2/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.2/layer_norm1/Pow_output_0
[1.1455  0.76    3.309   0.3088  0.4617  2.389   0.8013  0.3264  2.293
 0.00656] ...(size = 59136 end with 0.215087890625, sum = inf)
/text_model/encoder/layers.2/layer_norm1/ReduceMean_1_output_0
[1.9800e+02 1.0675e-01 6.5247e-02 5.9357e-02 5.8380e-02 5.7312e-02
 5.7098e-02 5.6976e-02 5.6122e-02 5.6061e-02] ...(size = 77 end with 0.07391357421875, sum = 202.875)
/text_model/encoder/layers.2/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.2/layer_norm1/Add_output_0
[1.9800e+02 1.0675e-01 6.5247e-02 5.9387e-02 5.8380e-02 5.7312e-02
 5.7098e-02 5.6976e-02 5.6122e-02 5.6061e-02] ...(size = 77 end with 0.073974609375, sum = 202.875)
/text_model/encoder/layers.2/layer_norm1/Sqrt_output_0
[14.07    0.3267  0.2554  0.2437  0.2417  0.2394  0.239   0.2386  0.2369
  0.2368] ...(size = 77 end with 0.27197265625, sum = 33.15625)
/text_model/encoder/layers.2/layer_norm1/Div_output_0
[-0.07605  -0.06195   0.1293    0.0395   -0.04828  -0.10986  -0.0636
 -0.0406    0.1076    0.005756] ...(size = 59136 end with -1.7060546875, sum = 0.01554107666015625)
/text_model/encoder/layers.2/layer_norm1/Mul_output_0
[-0.09717  -0.0875    0.1711    0.04785  -0.069    -0.1349   -0.0809
 -0.04907   0.1321    0.006924] ...(size = 59136 end with -2.337890625, sum = 619.0)
/text_model/encoder/layers.2/layer_norm1/Add_1_output_0
[ 0.01531  -0.021     0.0187    0.04727  -0.0235   -0.04156   0.00847
  0.010574  0.03613   0.0435  ] ...(size = 59136 end with -2.341796875, sum = 544.5)
/text_model/encoder/layers.2/self_attn/q_proj/MatMul_output_0
[-0.02463 -0.01108 -0.06213 -0.02563  0.0639  -0.02856 -0.0479   0.05176
 -0.06445 -0.2145 ] ...(size = 59136 end with -0.491455078125, sum = -142.625)
/text_model/encoder/layers.2/self_attn/q_proj/Add_output_0
[-0.458    0.1543  -0.1141   0.1849   0.5977   0.2478  -0.01388  0.539
  0.02327  1.24   ] ...(size = 59136 end with -0.343994140625, sum = -117.8125)
/text_model/encoder/layers.2/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.2/self_attn/Mul_output_0
[-0.05725   0.01929  -0.01426   0.02312   0.0747    0.03098  -0.001735
  0.0674    0.002909  0.155   ] ...(size = 59136 end with -0.042999267578125, sum = -14.7265625)
/text_model/encoder/layers.2/self_attn/k_proj/MatMul_output_0
[-0.2118    0.1565    0.004898  0.11053   1.349     0.2369   -0.04095
  0.1581    0.05426   1.333   ] ...(size = 59136 end with 0.61328125, sum = -365.25)
/text_model/encoder/layers.2/self_attn/k_proj/Add_output_0
[-0.2158   0.157    0.00642  0.11084  1.356    0.2416  -0.0502   0.1604
  0.05698  1.346  ] ...(size = 59136 end with 0.615234375, sum = -361.25)
/text_model/encoder/layers.2/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.2/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.2/self_attn/Reshape_output_0
[-0.2158   0.157    0.00642  0.11084  1.356    0.2416  -0.0502   0.1604
  0.05698  1.346  ] ...(size = 59136 end with 0.615234375, sum = -361.25)
/text_model/encoder/layers.2/self_attn/Transpose_output_0
[-0.2158   0.157    0.00642  0.11084  1.356    0.2416  -0.0502   0.1604
  0.05698  1.346  ] ...(size = 59136 end with 0.615234375, sum = -361.0)
/text_model/encoder/layers.2/self_attn/v_proj/MatMul_output_0
[ 0.02834   0.00704  -0.004158  0.03387   0.0364   -0.007866  0.01105
  0.0808   -0.12427   0.0461  ] ...(size = 59136 end with 0.31494140625, sum = -2100.0)
/text_model/encoder/layers.2/self_attn/v_proj/Add_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.345458984375, sum = -2086.0)
/text_model/encoder/layers.2/self_attn/Reshape_1_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.345458984375, sum = -2086.0)
/text_model/encoder/layers.2/self_attn/Transpose_1_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.345458984375, sum = -2086.0)
/text_model/encoder/layers.2/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.2/self_attn/Reshape_2_output_0
[-0.05725   0.01929  -0.01426   0.02312   0.0747    0.03098  -0.001735
  0.0674    0.002909  0.155   ] ...(size = 59136 end with -0.042999267578125, sum = -14.7265625)
/text_model/encoder/layers.2/self_attn/Transpose_2_output_0
[-0.05725   0.01929  -0.01426   0.02312   0.0747    0.03098  -0.001735
  0.0674    0.002909  0.155   ] ...(size = 59136 end with -0.042999267578125, sum = -14.703125)
/text_model/encoder/layers.2/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.2/self_attn/Reshape_3_output_0
[-0.05725   0.01929  -0.01426   0.02312   0.0747    0.03098  -0.001735
  0.0674    0.002909  0.155   ] ...(size = 59136 end with -0.042999267578125, sum = -14.703125)
/text_model/encoder/layers.2/self_attn/Reshape_4_output_0
[-0.2158   0.157    0.00642  0.11084  1.356    0.2416  -0.0502   0.1604
  0.05698  1.346  ] ...(size = 59136 end with 0.615234375, sum = -361.0)
/text_model/encoder/layers.2/self_attn/Reshape_5_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.345458984375, sum = -2086.0)
/text_model/encoder/layers.2/self_attn/Transpose_3_output_0
[-0.2158  0.85    0.5537  0.5356  0.4954  0.4631  0.426   0.4106  0.3982
  0.3787] ...(size = 59136 end with 0.615234375, sum = -360.5)
/text_model/encoder/layers.2/self_attn/MatMul_output_0
[ 0.8403 -1.522  -1.434  -1.452  -1.441  -1.43   -1.42   -1.419  -1.432
 -1.425 ] ...(size = 71148 end with 0.414794921875, sum = -inf)
/text_model/encoder/layers.2/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.2/self_attn/Reshape_6_output_0
[ 0.8403 -1.522  -1.434  -1.452  -1.441  -1.43   -1.42   -1.419  -1.432
 -1.425 ] ...(size = 71148 end with 0.414794921875, sum = -inf)
/text_model/encoder/layers.2/self_attn/Add_output_0
[ 8.403e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 0.414794921875, sum = -inf)
/text_model/encoder/layers.2/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.2/self_attn/Reshape_7_output_0
[ 8.403e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with 0.414794921875, sum = -inf)
/text_model/encoder/layers.2/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.02630615234375, sum = 924.0)
/text_model/encoder/layers.2/self_attn/MatMul_1_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.42333984375, sum = -726.5)
/text_model/encoder/layers.2/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.2/self_attn/Reshape_8_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.42333984375, sum = -726.5)
/text_model/encoder/layers.2/self_attn/Transpose_4_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.42333984375, sum = -726.5)
/text_model/encoder/layers.2/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.2/self_attn/Reshape_9_output_0
[-0.001845 -0.006527  0.0103    0.006535  0.02103   0.0409    0.002808
  0.0689   -0.1459    0.0371  ] ...(size = 59136 end with 0.42333984375, sum = -726.5)
/text_model/encoder/layers.2/self_attn/out_proj/MatMul_output_0
[ 0.00289  -0.012085 -0.04428  -0.03546   0.002419 -0.03455   0.05405
 -0.010445 -0.0254    0.01028 ] ...(size = 59136 end with 0.005718231201171875, sum = -16.09375)
/text_model/encoder/layers.2/self_attn/out_proj/Add_output_0
[ 0.04938  0.02917 -0.10187 -0.03123 -0.01296 -0.04175  0.126   -0.00707
 -0.01338  0.00856] ...(size = 59136 end with 0.01366424560546875, sum = -3.515625)
/text_model/encoder/layers.2/Add_output_0
[-1.026  -0.8477  1.712   0.519  -0.6978 -1.593  -0.7744 -0.5835  1.495
  0.0843] ...(size = 59136 end with -0.450439453125, sum = 61.15625)
/text_model/encoder/layers.2/layer_norm2/ReduceMean_output_0
[-0.004795  0.007225  0.00407   0.00372   0.003595  0.003426  0.003305
  0.003164  0.003149  0.003128] ...(size = 77 end with -0.0005559921264648438, sum = 0.07958984375)
/text_model/encoder/layers.2/layer_norm2/Sub_output_0
[-1.021  -0.843   1.717   0.524  -0.693  -1.588  -0.7695 -0.5786  1.5
  0.0891] ...(size = 59136 end with -0.449951171875, sum = 0.02008056640625)
/text_model/encoder/layers.2/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.2/layer_norm2/Pow_output_0
[1.044   0.7104  2.947   0.2747  0.4802  2.521   0.5923  0.335   2.25
 0.00794] ...(size = 59136 end with 0.202392578125, sum = inf)
/text_model/encoder/layers.2/layer_norm2/ReduceMean_1_output_0
[1.9812e+02 1.1017e-01 6.9275e-02 6.4026e-02 6.3599e-02 6.2927e-02
 6.3049e-02 6.2988e-02 6.2286e-02 6.2317e-02] ...(size = 77 end with 0.08587646484375, sum = 203.625)
/text_model/encoder/layers.2/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.2/layer_norm2/Add_output_0
[1.9812e+02 1.1017e-01 6.9275e-02 6.4026e-02 6.3599e-02 6.2988e-02
 6.3049e-02 6.2988e-02 6.2286e-02 6.2347e-02] ...(size = 77 end with 0.08587646484375, sum = 203.625)
/text_model/encoder/layers.2/layer_norm2/Sqrt_output_0
[14.08    0.332   0.2632  0.2532  0.2522  0.251   0.251   0.251   0.2496
  0.2496] ...(size = 77 end with 0.29296875, sum = 34.46875)
/text_model/encoder/layers.2/layer_norm2/Div_output_0
[-0.0726   -0.05988   0.12195   0.03723  -0.04922  -0.1128   -0.0547
 -0.04114   0.10657   0.006332] ...(size = 59136 end with -1.53515625, sum = -0.032867431640625)
/text_model/encoder/layers.2/layer_norm2/Mul_output_0
[-0.147    -0.1219    0.2379    0.07336  -0.0964   -0.2168   -0.1131
 -0.0804    0.213     0.013115] ...(size = 59136 end with -3.07421875, sum = 339.5)
/text_model/encoder/layers.2/layer_norm2/Add_1_output_0
[ 0.06793  0.625   -0.1998  -0.1185  -0.29     0.1936   0.335   -0.1866
  0.0633  -0.3274 ] ...(size = 59136 end with -2.666015625, sum = 1086.0)
/text_model/encoder/layers.2/mlp/fc1/MatMul_output_0
[-2.637  -0.9873 -2.611  -3.71   -1.965  -1.136  -1.223  -2.65    0.9614
 -1.649 ] ...(size = 236544 end with -2.1171875, sum = -inf)
/text_model/encoder/layers.2/mlp/fc1/Add_output_0
[-2.807  -1.14   -2.799  -4.055  -2.262  -1.568  -1.498  -2.78    0.6147
 -1.559 ] ...(size = 236544 end with -2.462890625, sum = -inf)
/text_model/encoder/layers.2/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.2/mlp/activation_fn/Mul_output_0
[-4.777 -1.939 -4.766 -6.906 -3.85  -2.67  -2.55  -4.73   1.047 -2.652] ...(size = 236544 end with -4.19140625, sum = -inf)
/text_model/encoder/layers.2/mlp/activation_fn/Sigmoid_output_0
[0.008354 0.1256   0.00845  0.001001 0.02084  0.0648   0.07245  0.00875
 0.74     0.0658  ] ...(size = 236544 end with 0.0148773193359375, sum = 42944.0)
/text_model/encoder/layers.2/mlp/activation_fn/Mul_1_output_0
[-0.02345  -0.1432   -0.02367  -0.004063 -0.04715  -0.1016   -0.1085
 -0.0243    0.455    -0.10254 ] ...(size = 236544 end with -0.036651611328125, sum = -12448.0)
/text_model/encoder/layers.2/mlp/fc2/MatMul_output_0
[ 0.1188    0.006294 -0.1703    0.0524   -0.0728   -0.05988  -0.1458
 -0.03693   0.122     0.07056 ] ...(size = 59136 end with 0.228515625, sum = 32.59375)
/text_model/encoder/layers.2/mlp/fc2/Add_output_0
[ 0.1043   -0.013145 -0.2228    0.0214   -0.1241   -0.02383  -0.1508
 -0.00604   0.0612    0.06665 ] ...(size = 59136 end with 0.186767578125, sum = 55.25)
/text_model/encoder/layers.2/Add_1_output_0
[-0.922  -0.861   1.489   0.5405 -0.822  -1.616  -0.9253 -0.59    1.557
  0.151 ] ...(size = 59136 end with -0.263671875, sum = 116.375)
/text_model/encoder/layers.3/layer_norm1/ReduceMean_output_0
[-0.00467   0.008026  0.004845  0.004585  0.004505  0.004387  0.004307
  0.00418   0.004154  0.004135] ...(size = 77 end with 0.0001556873321533203, sum = 0.1514892578125)
/text_model/encoder/layers.3/layer_norm1/Sub_output_0
[-0.9175 -0.856   1.494   0.5454 -0.8174 -1.611  -0.9204 -0.585   1.562
  0.1556] ...(size = 59136 end with -0.263916015625, sum = -0.0400390625)
/text_model/encoder/layers.3/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.3/layer_norm1/Pow_output_0
[0.842   0.733   2.23    0.2974  0.668   2.598   0.847   0.3423  2.438
 0.02422] ...(size = 59136 end with 0.06964111328125, sum = inf)
/text_model/encoder/layers.3/layer_norm1/ReduceMean_1_output_0
[1.9850e+02 1.1676e-01 7.6416e-02 7.2083e-02 7.2266e-02 7.2205e-02
 7.2754e-02 7.2754e-02 7.1960e-02 7.2327e-02] ...(size = 77 end with 0.09423828125, sum = 204.875)
/text_model/encoder/layers.3/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.3/layer_norm1/Add_output_0
[1.9850e+02 1.1676e-01 7.6416e-02 7.2083e-02 7.2266e-02 7.2205e-02
 7.2754e-02 7.2754e-02 7.1960e-02 7.2327e-02] ...(size = 77 end with 0.09423828125, sum = 204.875)
/text_model/encoder/layers.3/layer_norm1/Sqrt_output_0
[14.086   0.3418  0.2764  0.2686  0.2688  0.2688  0.2698  0.2698  0.2683
  0.2688] ...(size = 77 end with 0.30712890625, sum = 36.0625)
/text_model/encoder/layers.3/layer_norm1/Div_output_0
[-0.0651  -0.06076  0.106    0.0387  -0.058   -0.1144  -0.06537 -0.04153
  0.11084  0.01105] ...(size = 59136 end with -0.85986328125, sum = -0.056640625)
/text_model/encoder/layers.3/layer_norm1/Mul_output_0
[-0.0838   -0.08453   0.1409    0.05322  -0.0801   -0.1523   -0.08435
 -0.05707   0.1472    0.014114] ...(size = 59136 end with -1.189453125, sum = 331.25)
/text_model/encoder/layers.3/layer_norm1/Add_1_output_0
[ 0.003525 -0.02333   0.02687   0.03003  -0.01388  -0.04742  -0.02243
  0.0099    0.0643    0.04364 ] ...(size = 59136 end with -1.189453125, sum = 338.75)
/text_model/encoder/layers.3/self_attn/q_proj/MatMul_output_0
[ 0.07     -0.003857  0.02272   0.04727   0.01169   0.0897   -0.0779
 -0.2167   -0.12305  -0.11914 ] ...(size = 59136 end with -0.70361328125, sum = 394.5)
/text_model/encoder/layers.3/self_attn/q_proj/Add_output_0
[ 0.2449 -0.0733 -0.2272 -0.2037  0.251  -0.1129 -0.0598 -0.0522  0.2852
  0.1909] ...(size = 59136 end with -0.1976318359375, sum = 770.0)
/text_model/encoder/layers.3/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.3/self_attn/Mul_output_0
[ 0.03061  -0.00916  -0.0284   -0.02547   0.03137  -0.014114 -0.007477
 -0.006523  0.03564   0.02386 ] ...(size = 59136 end with -0.0247039794921875, sum = 96.25)
/text_model/encoder/layers.3/self_attn/k_proj/MatMul_output_0
[ 1.5205  -0.02245 -0.147   -0.1037   0.1273  -0.11176 -0.2339  -0.07056
  0.3464   0.2062 ] ...(size = 59136 end with -0.39501953125, sum = 1285.0)
/text_model/encoder/layers.3/self_attn/k_proj/Add_output_0
[ 1.565   -0.0247  -0.1484  -0.10236  0.1254  -0.12177 -0.2385  -0.07513
  0.3555   0.2194 ] ...(size = 59136 end with -0.39111328125, sum = 1315.0)
/text_model/encoder/layers.3/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.3/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.3/self_attn/Reshape_output_0
[ 1.565   -0.0247  -0.1484  -0.10236  0.1254  -0.12177 -0.2385  -0.07513
  0.3555   0.2194 ] ...(size = 59136 end with -0.39111328125, sum = 1315.0)
/text_model/encoder/layers.3/self_attn/Transpose_output_0
[ 1.565   -0.0247  -0.1484  -0.10236  0.1254  -0.12177 -0.2385  -0.07513
  0.3555   0.2194 ] ...(size = 59136 end with -0.39111328125, sum = 1315.0)
/text_model/encoder/layers.3/self_attn/v_proj/MatMul_output_0
[ 0.0878    0.0887   -0.04364  -0.003702  0.0688    0.03934   0.0195
 -0.02806   0.07196  -0.00979 ] ...(size = 59136 end with 0.058929443359375, sum = 1254.0)
/text_model/encoder/layers.3/self_attn/v_proj/Add_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with 0.1243896484375, sum = 1220.0)
/text_model/encoder/layers.3/self_attn/Reshape_1_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with 0.1243896484375, sum = 1220.0)
/text_model/encoder/layers.3/self_attn/Transpose_1_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with 0.1243896484375, sum = 1220.0)
/text_model/encoder/layers.3/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.3/self_attn/Reshape_2_output_0
[ 0.03061  -0.00916  -0.0284   -0.02547   0.03137  -0.014114 -0.007477
 -0.006523  0.03564   0.02386 ] ...(size = 59136 end with -0.0247039794921875, sum = 96.25)
/text_model/encoder/layers.3/self_attn/Transpose_2_output_0
[ 0.03061  -0.00916  -0.0284   -0.02547   0.03137  -0.014114 -0.007477
 -0.006523  0.03564   0.02386 ] ...(size = 59136 end with -0.0247039794921875, sum = 96.25)
/text_model/encoder/layers.3/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.3/self_attn/Reshape_3_output_0
[ 0.03061  -0.00916  -0.0284   -0.02547   0.03137  -0.014114 -0.007477
 -0.006523  0.03564   0.02386 ] ...(size = 59136 end with -0.0247039794921875, sum = 96.25)
/text_model/encoder/layers.3/self_attn/Reshape_4_output_0
[ 1.565   -0.0247  -0.1484  -0.10236  0.1254  -0.12177 -0.2385  -0.07513
  0.3555   0.2194 ] ...(size = 59136 end with -0.39111328125, sum = 1315.0)
/text_model/encoder/layers.3/self_attn/Reshape_5_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with 0.1243896484375, sum = 1220.0)
/text_model/encoder/layers.3/self_attn/Transpose_3_output_0
[ 1.565 -0.929 -1.349 -1.548 -1.669 -1.75  -1.824 -1.892 -1.946 -1.985] ...(size = 59136 end with -0.39111328125, sum = 1315.0)
/text_model/encoder/layers.3/self_attn/MatMul_output_0
[ 0.601  -0.8984 -0.9277 -0.93   -0.9277 -0.9297 -0.9297 -0.9155 -0.909
 -0.896 ] ...(size = 71148 end with -3.3046875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.3/self_attn/Reshape_6_output_0
[ 0.601  -0.8984 -0.9277 -0.93   -0.9277 -0.9297 -0.9297 -0.9155 -0.909
 -0.896 ] ...(size = 71148 end with -3.3046875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Add_output_0
[ 6.01e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.3046875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.3/self_attn/Reshape_7_output_0
[ 6.01e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.3046875, sum = -inf)
/text_model/encoder/layers.3/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.003620147705078125, sum = 924.0)
/text_model/encoder/layers.3/self_attn/MatMul_1_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with -0.03265380859375, sum = 764.5)
/text_model/encoder/layers.3/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.3/self_attn/Reshape_8_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with -0.03265380859375, sum = 764.5)
/text_model/encoder/layers.3/self_attn/Transpose_4_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with -0.03265380859375, sum = 764.5)
/text_model/encoder/layers.3/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.3/self_attn/Reshape_9_output_0
[ 0.03183   0.03026   0.00435  -0.00916   0.05215   0.000764  0.00421
  0.004524  0.07025  -0.00563 ] ...(size = 59136 end with -0.03265380859375, sum = 764.5)
/text_model/encoder/layers.3/self_attn/out_proj/MatMul_output_0
[ 0.01714   -0.005966   0.002934  -0.01901    0.00801   -0.01646
  0.02226    0.003815  -0.0011425  0.04224  ] ...(size = 59136 end with -0.07196044921875, sum = 7.390625)
/text_model/encoder/layers.3/self_attn/out_proj/Add_output_0
[ 0.01252  -0.01668  -0.001312 -0.03067  -0.0643   -0.005062  0.0881
 -0.02777   0.02159   0.09393 ] ...(size = 59136 end with -0.0537109375, sum = 30.828125)
/text_model/encoder/layers.3/Add_output_0
[-0.9097 -0.8774  1.487   0.51   -0.886  -1.621  -0.837  -0.617   1.578
  0.2449] ...(size = 59136 end with -0.3173828125, sum = 147.25)
/text_model/encoder/layers.3/layer_norm2/ReduceMean_output_0
[-0.00419   0.008575  0.005474  0.005276  0.005222  0.005116  0.00503
  0.004898  0.004856  0.00482 ] ...(size = 77 end with 0.0007181167602539062, sum = 0.191650390625)
/text_model/encoder/layers.3/layer_norm2/Sub_output_0
[-0.9053 -0.8735  1.492   0.514  -0.882  -1.617  -0.833  -0.6133  1.582
  0.249 ] ...(size = 59136 end with -0.318115234375, sum = 0.141845703125)
/text_model/encoder/layers.3/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.3/layer_norm2/Pow_output_0
[0.82    0.7627  2.227   0.2644  0.778   2.615   0.694   0.376   2.504
 0.06204] ...(size = 59136 end with 0.10125732421875, sum = inf)
/text_model/encoder/layers.3/layer_norm2/ReduceMean_1_output_0
[1.986e+02 1.164e-01 7.556e-02 7.214e-02 7.349e-02 7.465e-02 7.629e-02
 7.721e-02 7.721e-02 7.825e-02] ...(size = 77 end with 0.10589599609375, sum = 205.875)
/text_model/encoder/layers.3/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.3/layer_norm2/Add_output_0
[1.986e+02 1.164e-01 7.556e-02 7.214e-02 7.349e-02 7.465e-02 7.629e-02
 7.721e-02 7.721e-02 7.825e-02] ...(size = 77 end with 0.10589599609375, sum = 205.875)
/text_model/encoder/layers.3/layer_norm2/Sqrt_output_0
[14.09    0.341   0.275   0.2686  0.271   0.2732  0.2761  0.2778  0.2778
  0.2798] ...(size = 77 end with 0.325439453125, sum = 37.53125)
/text_model/encoder/layers.3/layer_norm2/Div_output_0
[-0.0642  -0.06195  0.10583  0.03647 -0.06256 -0.11475 -0.05908 -0.04352
  0.11224  0.01767] ...(size = 59136 end with -0.97802734375, sum = 0.10467529296875)
/text_model/encoder/layers.3/layer_norm2/Mul_output_0
[-0.1305  -0.12225  0.2189   0.0763  -0.1307  -0.2478  -0.1296  -0.09106
  0.2451   0.03644] ...(size = 59136 end with -2.115234375, sum = -103.875)
/text_model/encoder/layers.3/layer_norm2/Add_1_output_0
[-0.294    0.268   -0.4382   0.154   -0.4954   0.556    0.5073  -0.1779
 -0.1367  -0.12494] ...(size = 59136 end with -1.6181640625, sum = 1707.0)
/text_model/encoder/layers.3/mlp/fc1/MatMul_output_0
[-1.53  -2.691 -1.134 -1.165 -1.821 -2.139 -2.014 -3.049 -1.702 -0.098] ...(size = 236544 end with -1.693359375, sum = -inf)
/text_model/encoder/layers.3/mlp/fc1/Add_output_0
[-1.863  -3.154  -1.286  -1.434  -2.195  -2.432  -2.334  -3.504  -2.053
 -0.3828] ...(size = 236544 end with -2.00390625, sum = -inf)
/text_model/encoder/layers.3/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.3/mlp/activation_fn/Mul_output_0
[-3.172  -5.367  -2.19   -2.44   -3.738  -4.14   -3.97   -5.965  -3.494
 -0.6514] ...(size = 236544 end with -3.41015625, sum = -inf)
/text_model/encoder/layers.3/mlp/activation_fn/Sigmoid_output_0
[0.04022  0.004642 0.1007   0.0802   0.02325  0.01567  0.0185   0.002563
 0.02945  0.3428  ] ...(size = 236544 end with 0.031982421875, sum = 26928.0)
/text_model/encoder/layers.3/mlp/activation_fn/Mul_1_output_0
[-0.07495 -0.01464 -0.1295  -0.1149  -0.05106 -0.03812 -0.04315 -0.00898
 -0.0605  -0.1311 ] ...(size = 236544 end with -0.0640869140625, sum = -13680.0)
/text_model/encoder/layers.3/mlp/fc2/MatMul_output_0
[ 0.04163 -0.1072   0.07684  0.01563  0.2155  -0.0515  -0.1891   0.02707
  0.1481   0.01475] ...(size = 59136 end with 0.0443115234375, sum = -28.640625)
/text_model/encoder/layers.3/mlp/fc2/Add_output_0
[ 2.756e-02 -5.075e-02  1.321e-02 -3.105e-05  1.454e-01 -3.093e-02
 -1.398e-01  2.316e-02  5.286e-02 -1.226e-02] ...(size = 59136 end with 0.07098388671875, sum = -22.59375)
/text_model/encoder/layers.3/Add_1_output_0
[-0.882  -0.928   1.501   0.51   -0.7407 -1.652  -0.977  -0.594   1.631
  0.2327] ...(size = 59136 end with -0.2464599609375, sum = 124.625)
/text_model/encoder/layers.4/layer_norm1/ReduceMean_output_0
[-0.004467  0.00855   0.004997  0.004795  0.004753  0.004696  0.004635
  0.004536  0.004536  0.004513] ...(size = 77 end with 2.0265579223632812e-05, sum = 0.1622314453125)
/text_model/encoder/layers.4/layer_norm1/Sub_output_0
[-0.8774 -0.924   1.506   0.5146 -0.7363 -1.647  -0.972  -0.59    1.636
  0.237 ] ...(size = 59136 end with -0.24658203125, sum = -0.0184478759765625)
/text_model/encoder/layers.4/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.4/layer_norm1/Pow_output_0
[0.77   0.8535 2.266  0.2646 0.542  2.715  0.9453 0.348  2.676  0.0562] ...(size = 59136 end with 0.060791015625, sum = inf)
/text_model/encoder/layers.4/layer_norm1/ReduceMean_1_output_0
[1.9862e+02 1.0986e-01 7.4463e-02 7.2388e-02 7.3547e-02 7.4463e-02
 7.5684e-02 7.6538e-02 7.6538e-02 7.7576e-02] ...(size = 77 end with 0.10467529296875, sum = 205.875)
/text_model/encoder/layers.4/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.4/layer_norm1/Add_output_0
[1.9862e+02 1.0986e-01 7.4463e-02 7.2388e-02 7.3547e-02 7.4463e-02
 7.5684e-02 7.6538e-02 7.6599e-02 7.7576e-02] ...(size = 77 end with 0.104736328125, sum = 205.875)
/text_model/encoder/layers.4/layer_norm1/Sqrt_output_0
[14.09    0.3315  0.273   0.269   0.2712  0.273   0.2751  0.2766  0.2766
  0.2786] ...(size = 77 end with 0.323486328125, sum = 37.40625)
/text_model/encoder/layers.4/layer_norm1/Div_output_0
[-0.06226 -0.06555  0.1068   0.0365  -0.05225 -0.11694 -0.069   -0.04184
  0.116    0.01683] ...(size = 59136 end with -0.76171875, sum = 0.08599853515625)
/text_model/encoder/layers.4/layer_norm1/Mul_output_0
[-0.0884  -0.102    0.1545   0.05176 -0.0735  -0.1683  -0.0957  -0.05737
  0.1642   0.0229 ] ...(size = 59136 end with -1.0673828125, sum = 60.65625)
/text_model/encoder/layers.4/layer_norm1/Add_1_output_0
[-0.01651  -0.003277  0.03143   0.02646  -0.03912  -0.0455   -0.02512
  0.01452   0.03885   0.03317 ] ...(size = 59136 end with -1.0673828125, sum = 188.0)
/text_model/encoder/layers.4/self_attn/q_proj/MatMul_output_0
[-0.655     0.00816  -0.057     0.0346    0.3853    0.11957  -0.00879
  0.1757   -0.162     0.003666] ...(size = 59136 end with -1.849609375, sum = 4062.0)
/text_model/encoder/layers.4/self_attn/q_proj/Add_output_0
[ 0.482    -0.11285   0.08545   0.0949    0.0949   -0.004784 -0.2057
 -0.1627    0.00416   0.1255  ] ...(size = 59136 end with -4.0546875, sum = 5176.0)
/text_model/encoder/layers.4/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.4/self_attn/Mul_output_0
[ 0.06024  -0.01411   0.01068   0.01186   0.01186  -0.000598 -0.02571
 -0.02034   0.00052   0.01569 ] ...(size = 59136 end with -0.5068359375, sum = 647.0)
/text_model/encoder/layers.4/self_attn/k_proj/MatMul_output_0
[ 1.452   -0.1469   0.1447   0.1475  -0.02422 -0.0743  -0.2316  -0.228
  0.06012  0.02113] ...(size = 59136 end with -0.36474609375, sum = -204.375)
/text_model/encoder/layers.4/self_attn/k_proj/Add_output_0
[ 1.444   -0.1475   0.1433   0.1471  -0.02791 -0.0762  -0.2336  -0.2229
  0.0546   0.0229 ] ...(size = 59136 end with -0.3876953125, sum = -188.0)
/text_model/encoder/layers.4/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.4/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.4/self_attn/Reshape_output_0
[ 1.444   -0.1475   0.1433   0.1471  -0.02791 -0.0762  -0.2336  -0.2229
  0.0546   0.0229 ] ...(size = 59136 end with -0.3876953125, sum = -188.0)
/text_model/encoder/layers.4/self_attn/Transpose_output_0
[ 1.444   -0.1475   0.1433   0.1471  -0.02791 -0.0762  -0.2336  -0.2229
  0.0546   0.0229 ] ...(size = 59136 end with -0.3876953125, sum = -187.375)
/text_model/encoder/layers.4/self_attn/v_proj/MatMul_output_0
[ 0.001801  -0.0005584  0.03696   -0.03476   -0.0186    -0.01971
 -0.01452   -0.01797   -0.04346   -0.03207  ] ...(size = 59136 end with 0.475830078125, sum = 103.25)
/text_model/encoder/layers.4/self_attn/v_proj/Add_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.458251953125, sum = 142.75)
/text_model/encoder/layers.4/self_attn/Reshape_1_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.458251953125, sum = 142.75)
/text_model/encoder/layers.4/self_attn/Transpose_1_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.458251953125, sum = 142.5)
/text_model/encoder/layers.4/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.4/self_attn/Reshape_2_output_0
[ 0.06024  -0.01411   0.01068   0.01186   0.01186  -0.000598 -0.02571
 -0.02034   0.00052   0.01569 ] ...(size = 59136 end with -0.5068359375, sum = 647.0)
/text_model/encoder/layers.4/self_attn/Transpose_2_output_0
[ 0.06024  -0.01411   0.01068   0.01186   0.01186  -0.000598 -0.02571
 -0.02034   0.00052   0.01569 ] ...(size = 59136 end with -0.5068359375, sum = 647.5)
/text_model/encoder/layers.4/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.4/self_attn/Reshape_3_output_0
[ 0.06024  -0.01411   0.01068   0.01186   0.01186  -0.000598 -0.02571
 -0.02034   0.00052   0.01569 ] ...(size = 59136 end with -0.5068359375, sum = 647.5)
/text_model/encoder/layers.4/self_attn/Reshape_4_output_0
[ 1.444   -0.1475   0.1433   0.1471  -0.02791 -0.0762  -0.2336  -0.2229
  0.0546   0.0229 ] ...(size = 59136 end with -0.3876953125, sum = -187.375)
/text_model/encoder/layers.4/self_attn/Reshape_5_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.458251953125, sum = 142.5)
/text_model/encoder/layers.4/self_attn/Transpose_3_output_0
[ 1.444 -2.14  -1.759 -1.7   -1.633 -1.543 -1.447 -1.365 -1.277 -1.195] ...(size = 59136 end with -0.3876953125, sum = -187.5)
/text_model/encoder/layers.4/self_attn/MatMul_output_0
[ 0.458  -0.3127 -0.248  -0.2532 -0.2944 -0.3264 -0.3584 -0.3794 -0.403
 -0.4248] ...(size = 71148 end with -2.318359375, sum = -inf)
/text_model/encoder/layers.4/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.4/self_attn/Reshape_6_output_0
[ 0.458  -0.3127 -0.248  -0.2532 -0.2944 -0.3264 -0.3584 -0.3794 -0.403
 -0.4248] ...(size = 71148 end with -2.318359375, sum = -inf)
/text_model/encoder/layers.4/self_attn/Add_output_0
[ 4.58e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.318359375, sum = -inf)
/text_model/encoder/layers.4/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.4/self_attn/Reshape_7_output_0
[ 4.58e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.318359375, sum = -inf)
/text_model/encoder/layers.4/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.00754547119140625, sum = 924.0)
/text_model/encoder/layers.4/self_attn/MatMul_1_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.09307861328125, sum = -452.75)
/text_model/encoder/layers.4/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.4/self_attn/Reshape_8_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.09307861328125, sum = -452.75)
/text_model/encoder/layers.4/self_attn/Transpose_4_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.09307861328125, sum = -452.5)
/text_model/encoder/layers.4/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.4/self_attn/Reshape_9_output_0
[-0.00315  -0.02174   0.05777  -0.00812  -0.03552  -0.03485   0.005085
 -0.00595  -0.01718  -0.01299 ] ...(size = 59136 end with 0.09307861328125, sum = -452.5)
/text_model/encoder/layers.4/self_attn/out_proj/MatMul_output_0
[ 0.03165   0.02881   0.01862  -0.00551   0.0384    0.002487  0.02383
  0.010155  0.00874   0.02098 ] ...(size = 59136 end with -0.04931640625, sum = -19.71875)
/text_model/encoder/layers.4/self_attn/out_proj/Add_output_0
[ 0.02715   0.0299   -0.014854 -0.01823  -0.02869   0.06964   0.0925
 -0.005257  0.04892   0.05426 ] ...(size = 59136 end with -0.01007080078125, sum = 23.25)
/text_model/encoder/layers.4/Add_output_0
[-0.855  -0.8984  1.486   0.4917 -0.7695 -1.583  -0.8843 -0.5996  1.68
  0.2869] ...(size = 59136 end with -0.256591796875, sum = 147.875)
/text_model/encoder/layers.4/layer_norm2/ReduceMean_output_0
[-0.003672  0.00931   0.00569   0.005436  0.005352  0.00526   0.005184
  0.005066  0.005054  0.00502 ] ...(size = 77 end with 0.0004048347473144531, sum = 0.1925048828125)
/text_model/encoder/layers.4/layer_norm2/Sub_output_0
[-0.851  -0.8945  1.489   0.4954 -0.7656 -1.579  -0.8804 -0.5957  1.684
  0.2905] ...(size = 59136 end with -0.257080078125, sum = -0.0267486572265625)
/text_model/encoder/layers.4/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.4/layer_norm2/Pow_output_0
[0.7246 0.8003 2.219  0.2455 0.5864 2.494  0.7754 0.355  2.834  0.0844] ...(size = 59136 end with 0.0660400390625, sum = inf)
/text_model/encoder/layers.4/layer_norm2/ReduceMean_1_output_0
[1.988e+02 1.131e-01 7.776e-02 7.635e-02 7.837e-02 8.020e-02 8.209e-02
 8.350e-02 8.392e-02 8.514e-02] ...(size = 77 end with 0.12109375, sum = 207.0)
/text_model/encoder/layers.4/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.4/layer_norm2/Add_output_0
[1.988e+02 1.131e-01 7.776e-02 7.642e-02 7.843e-02 8.026e-02 8.209e-02
 8.356e-02 8.392e-02 8.514e-02] ...(size = 77 end with 0.12109375, sum = 207.0)
/text_model/encoder/layers.4/layer_norm2/Sqrt_output_0
[14.1     0.3364  0.2788  0.2764  0.28    0.2832  0.2866  0.289   0.2898
  0.2917] ...(size = 77 end with 0.347900390625, sum = 39.09375)
/text_model/encoder/layers.4/layer_norm2/Div_output_0
[-0.06036 -0.0635   0.10565  0.03513 -0.05432 -0.112   -0.06247 -0.04227
  0.11945  0.02061] ...(size = 59136 end with -0.73828125, sum = 0.04376220703125)
/text_model/encoder/layers.4/layer_norm2/Mul_output_0
[-0.1298  -0.1317   0.2316   0.07184 -0.1107  -0.2402  -0.1417  -0.0897
  0.2563   0.04514] ...(size = 59136 end with -1.68359375, sum = -385.25)
/text_model/encoder/layers.4/layer_norm2/Add_1_output_0
[-0.5347  0.372  -0.3896  0.2622 -1.042   0.1965  0.486  -0.0976 -0.5996
 -0.2576] ...(size = 59136 end with -1.068359375, sum = 1112.0)
/text_model/encoder/layers.4/mlp/fc1/MatMul_output_0
[-1.313 -1.231 -1.622 -2.44  -1.924 -0.853 -2.291 -0.795 -2.016 -1.354] ...(size = 236544 end with -0.283447265625, sum = -inf)
/text_model/encoder/layers.4/mlp/fc1/Add_output_0
[-1.634  -1.202  -1.905  -2.77   -2.258  -0.9087 -2.543  -0.9224 -2.379
 -1.725 ] ...(size = 236544 end with -0.60400390625, sum = -inf)
/text_model/encoder/layers.4/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.4/mlp/activation_fn/Mul_output_0
[-2.781 -2.045 -3.242 -4.715 -3.844 -1.547 -4.33  -1.569 -4.047 -2.936] ...(size = 236544 end with -1.0283203125, sum = -inf)
/text_model/encoder/layers.4/mlp/activation_fn/Sigmoid_output_0
[0.05835  0.1145   0.0376   0.00889  0.02097  0.1755   0.013016 0.1722
 0.01717  0.05038 ] ...(size = 236544 end with 0.263427734375, sum = 24624.0)
/text_model/encoder/layers.4/mlp/activation_fn/Mul_1_output_0
[-0.09534 -0.1376  -0.07166 -0.02461 -0.04733 -0.1595  -0.0331  -0.1588
 -0.0408  -0.0869 ] ...(size = 236544 end with -0.1591796875, sum = -13672.0)
/text_model/encoder/layers.4/mlp/fc2/MatMul_output_0
[-0.066    0.00847  0.09094  0.01833  0.11096 -0.2211  -0.11096  0.1188
 -0.1484   0.0719 ] ...(size = 59136 end with -0.022369384765625, sum = -18.078125)
/text_model/encoder/layers.4/mlp/fc2/Add_output_0
[-0.01978  0.0669   0.03955  0.03647  0.09644 -0.1058  -0.03806  0.1038
 -0.09656  0.0485 ] ...(size = 59136 end with 0.018218994140625, sum = -0.74658203125)
/text_model/encoder/layers.4/Add_1_output_0
[-0.8745 -0.8315  1.525   0.5283 -0.673  -1.688  -0.9224 -0.4956  1.583
  0.3354] ...(size = 59136 end with -0.2384033203125, sum = 147.375)
/text_model/encoder/layers.5/layer_norm1/ReduceMean_output_0
[-0.00369   0.00873   0.005253  0.005108  0.005028  0.00496   0.004944
  0.004868  0.004894  0.004883] ...(size = 77 end with 0.0003960132598876953, sum = 0.1915283203125)
/text_model/encoder/layers.5/layer_norm1/Sub_output_0
[-0.871  -0.8276  1.529   0.5317 -0.6694 -1.685  -0.9185 -0.492   1.587
  0.339 ] ...(size = 59136 end with -0.23876953125, sum = 0.08489990234375)
/text_model/encoder/layers.5/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.5/layer_norm1/Pow_output_0
[0.7583 0.685  2.338  0.283  0.448  2.838  0.8438 0.2421 2.52   0.115 ] ...(size = 59136 end with 0.0570068359375, sum = inf)
/text_model/encoder/layers.5/layer_norm1/ReduceMean_1_output_0
[1.985e+02 1.093e-01 7.727e-02 7.770e-02 8.057e-02 8.258e-02 8.429e-02
 8.545e-02 8.575e-02 8.630e-02] ...(size = 77 end with 0.1168212890625, sum = 206.375)
/text_model/encoder/layers.5/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.5/layer_norm1/Add_output_0
[1.985e+02 1.094e-01 7.727e-02 7.770e-02 8.063e-02 8.264e-02 8.429e-02
 8.545e-02 8.575e-02 8.636e-02] ...(size = 77 end with 0.1168212890625, sum = 206.375)
/text_model/encoder/layers.5/layer_norm1/Sqrt_output_0
[14.086   0.3306  0.278   0.2788  0.284   0.2874  0.2903  0.2925  0.2927
  0.294 ] ...(size = 77 end with 0.341796875, sum = 38.40625)
/text_model/encoder/layers.5/layer_norm1/Div_output_0
[-0.06183 -0.05875  0.1085   0.03775 -0.04752 -0.11957 -0.0652  -0.0349
  0.1127   0.02406] ...(size = 59136 end with -0.6982421875, sum = -0.0479736328125)
/text_model/encoder/layers.5/layer_norm1/Mul_output_0
[-0.0889  -0.091    0.1567   0.05423 -0.0698  -0.1912  -0.0965  -0.05225
  0.1697   0.03418] ...(size = 59136 end with -1.001953125, sum = -196.5)
/text_model/encoder/layers.5/layer_norm1/Add_1_output_0
[ 0.00611 -0.02875  0.04587  0.03564  0.01087 -0.05508 -0.02744 -0.01529
  0.03403  0.03152] ...(size = 59136 end with -1.0361328125, sum = -64.3125)
/text_model/encoder/layers.5/self_attn/q_proj/MatMul_output_0
[ 0.1335   -0.2104    0.1581   -0.03833   0.011734  0.1603    0.4497
 -0.2386    0.2605   -0.01575 ] ...(size = 59136 end with -0.73486328125, sum = 2728.0)
/text_model/encoder/layers.5/self_attn/q_proj/Add_output_0
[-0.1875   0.02023  0.1106  -0.1166   0.195    0.01421 -0.1295  -0.1417
  0.262   -0.4988 ] ...(size = 59136 end with -0.89453125, sum = 3982.0)
/text_model/encoder/layers.5/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.5/self_attn/Mul_output_0
[-0.02344   0.00253   0.013824 -0.01457   0.02437   0.001777 -0.01619
 -0.01772   0.03275  -0.06235 ] ...(size = 59136 end with -0.11181640625, sum = 497.75)
/text_model/encoder/layers.5/self_attn/k_proj/MatMul_output_0
[-0.2311   0.1316  -0.0129  -0.03027  0.06885 -0.1272  -0.507    0.083
  0.02258 -0.3323 ] ...(size = 59136 end with 1.509765625, sum = -606.5)
/text_model/encoder/layers.5/self_attn/k_proj/Add_output_0
[-0.2346   0.1337  -0.01093 -0.03026  0.07117 -0.1285  -0.5093   0.0855
  0.02214 -0.3281 ] ...(size = 59136 end with 1.5068359375, sum = -611.0)
/text_model/encoder/layers.5/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.5/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.5/self_attn/Reshape_output_0
[-0.2346   0.1337  -0.01093 -0.03026  0.07117 -0.1285  -0.5093   0.0855
  0.02214 -0.3281 ] ...(size = 59136 end with 1.5068359375, sum = -611.0)
/text_model/encoder/layers.5/self_attn/Transpose_output_0
[-0.2346   0.1337  -0.01093 -0.03026  0.07117 -0.1285  -0.5093   0.0855
  0.02214 -0.3281 ] ...(size = 59136 end with 1.5068359375, sum = -610.5)
/text_model/encoder/layers.5/self_attn/v_proj/MatMul_output_0
[-0.00646   0.0787    0.003872 -0.03653  -0.09296  -0.00493  -0.03687
  0.0044    0.02246   0.03632 ] ...(size = 59136 end with 0.7236328125, sum = 1470.0)
/text_model/encoder/layers.5/self_attn/v_proj/Add_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.7099609375, sum = 1459.0)
/text_model/encoder/layers.5/self_attn/Reshape_1_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.7099609375, sum = 1459.0)
/text_model/encoder/layers.5/self_attn/Transpose_1_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.7099609375, sum = 1458.0)
/text_model/encoder/layers.5/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.5/self_attn/Reshape_2_output_0
[-0.02344   0.00253   0.013824 -0.01457   0.02437   0.001777 -0.01619
 -0.01772   0.03275  -0.06235 ] ...(size = 59136 end with -0.11181640625, sum = 497.75)
/text_model/encoder/layers.5/self_attn/Transpose_2_output_0
[-0.02344   0.00253   0.013824 -0.01457   0.02437   0.001777 -0.01619
 -0.01772   0.03275  -0.06235 ] ...(size = 59136 end with -0.11181640625, sum = 498.0)
/text_model/encoder/layers.5/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.5/self_attn/Reshape_3_output_0
[-0.02344   0.00253   0.013824 -0.01457   0.02437   0.001777 -0.01619
 -0.01772   0.03275  -0.06235 ] ...(size = 59136 end with -0.11181640625, sum = 498.0)
/text_model/encoder/layers.5/self_attn/Reshape_4_output_0
[-0.2346   0.1337  -0.01093 -0.03026  0.07117 -0.1285  -0.5093   0.0855
  0.02214 -0.3281 ] ...(size = 59136 end with 1.5068359375, sum = -610.5)
/text_model/encoder/layers.5/self_attn/Reshape_5_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.7099609375, sum = 1458.0)
/text_model/encoder/layers.5/self_attn/Transpose_3_output_0
[-0.2346  -0.1805   0.01918  0.2043   0.375    0.518    0.639    0.709
  0.7275   0.752  ] ...(size = 59136 end with 1.5068359375, sum = -611.0)
/text_model/encoder/layers.5/self_attn/MatMul_output_0
[ 0.6025 -0.1169 -0.2017 -0.3064 -0.3494 -0.366  -0.3813 -0.3843 -0.3862
 -0.3792] ...(size = 71148 end with -3.37890625, sum = -inf)
/text_model/encoder/layers.5/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.5/self_attn/Reshape_6_output_0
[ 0.6025 -0.1169 -0.2017 -0.3064 -0.3494 -0.366  -0.3813 -0.3843 -0.3862
 -0.3792] ...(size = 71148 end with -3.37890625, sum = -inf)
/text_model/encoder/layers.5/self_attn/Add_output_0
[ 6.025e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -3.37890625, sum = -inf)
/text_model/encoder/layers.5/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.5/self_attn/Reshape_7_output_0
[ 6.025e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -3.37890625, sum = -inf)
/text_model/encoder/layers.5/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0017862319946289062, sum = 924.0)
/text_model/encoder/layers.5/self_attn/MatMul_1_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.034149169921875, sum = -18.71875)
/text_model/encoder/layers.5/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.5/self_attn/Reshape_8_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.034149169921875, sum = -18.71875)
/text_model/encoder/layers.5/self_attn/Transpose_4_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.034149169921875, sum = -18.796875)
/text_model/encoder/layers.5/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.5/self_attn/Reshape_9_output_0
[ 0.004726  0.04108   0.01208  -0.01442  -0.0365   -0.01648  -0.01262
 -0.001421  0.01245   0.00953 ] ...(size = 59136 end with 0.034149169921875, sum = -18.796875)
/text_model/encoder/layers.5/self_attn/out_proj/MatMul_output_0
[ 7.910e-05  2.832e-02  2.068e-02 -7.217e-03 -1.958e-02 -5.243e-02
  1.423e-02  4.050e-02 -5.057e-02 -3.087e-02] ...(size = 59136 end with -0.11212158203125, sum = -9.5859375)
/text_model/encoder/layers.5/self_attn/out_proj/Add_output_0
[ 0.02904    0.0411     0.03008   -0.01167   -0.0489    -0.0651
 -0.0005965 -0.01851   -0.0732     0.01085  ] ...(size = 59136 end with -0.10345458984375, sum = 21.109375)
/text_model/encoder/layers.5/Add_output_0
[-0.8457 -0.7905  1.556   0.5166 -0.7217 -1.754  -0.923  -0.514   1.51
  0.3462] ...(size = 59136 end with -0.341796875, sum = 168.125)
/text_model/encoder/layers.5/layer_norm2/ReduceMean_output_0
[-0.003248  0.00915   0.005627  0.0054    0.005276  0.005188  0.005165
  0.005085  0.005123  0.00511 ] ...(size = 77 end with 0.0009250640869140625, sum = 0.218994140625)
/text_model/encoder/layers.5/layer_norm2/Sub_output_0
[-0.8423 -0.787   1.559   0.5195 -0.7188 -1.75   -0.9194 -0.5107  1.514
  0.3494] ...(size = 59136 end with -0.3427734375, sum = -0.0229644775390625)
/text_model/encoder/layers.5/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.5/layer_norm2/Pow_output_0
[0.7095  0.6196  2.43    0.2703  0.5166  3.064   0.8457  0.261   2.291
 0.12213] ...(size = 59136 end with 0.117431640625, sum = inf)
/text_model/encoder/layers.5/layer_norm2/ReduceMean_1_output_0
[1.9862e+02 1.0925e-01 7.7393e-02 7.8491e-02 8.1726e-02 8.3801e-02
 8.5388e-02 8.6548e-02 8.6792e-02 8.7341e-02] ...(size = 77 end with 0.119384765625, sum = 206.5)
/text_model/encoder/layers.5/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.5/layer_norm2/Add_output_0
[1.9862e+02 1.0925e-01 7.7454e-02 7.8491e-02 8.1726e-02 8.3801e-02
 8.5388e-02 8.6548e-02 8.6792e-02 8.7341e-02] ...(size = 77 end with 0.119384765625, sum = 206.5)
/text_model/encoder/layers.5/layer_norm2/Sqrt_output_0
[14.09    0.3306  0.2783  0.2803  0.286   0.2896  0.2922  0.2942  0.2947
  0.2954] ...(size = 77 end with 0.345458984375, sum = 38.5625)
/text_model/encoder/layers.5/layer_norm2/Div_output_0
[-0.05978 -0.05585  0.1106   0.0369  -0.051   -0.1242  -0.06525 -0.03625
  0.1074   0.0248 ] ...(size = 59136 end with -0.99169921875, sum = -0.042236328125)
/text_model/encoder/layers.5/layer_norm2/Mul_output_0
[-0.1273  -0.1172   0.2396   0.0768  -0.09155 -0.2683  -0.1437  -0.07587
  0.24     0.05347] ...(size = 59136 end with -2.279296875, sum = -520.0)
/text_model/encoder/layers.5/layer_norm2/Add_1_output_0
[-0.0723  0.2246 -0.3596  0.1343 -0.684   0.3528  0.579  -0.4595  0.7705
 -0.2915] ...(size = 59136 end with -1.634765625, sum = -1071.0)
/text_model/encoder/layers.5/mlp/fc1/MatMul_output_0
[-1.426  -1.536  -1.54   -2.219  -1.53   -1.486  -0.5234 -1.912  -0.7866
 -1.483 ] ...(size = 236544 end with -2.111328125, sum = -inf)
/text_model/encoder/layers.5/mlp/fc1/Add_output_0
[-1.8   -1.945 -1.857 -2.482 -1.79  -1.858 -0.334 -2.277 -0.884 -1.775] ...(size = 236544 end with -2.421875, sum = -inf)
/text_model/encoder/layers.5/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.5/mlp/activation_fn/Mul_output_0
[-3.064  -3.312  -3.16   -4.227  -3.047  -3.164  -0.5684 -3.875  -1.505
 -3.021 ] ...(size = 236544 end with -4.12109375, sum = -inf)
/text_model/encoder/layers.5/mlp/activation_fn/Sigmoid_output_0
[0.04465 0.0352  0.04065 0.0144  0.04535 0.04056 0.3616  0.02034 0.1818
 0.04648] ...(size = 236544 end with 0.0159454345703125, sum = 30272.0)
/text_model/encoder/layers.5/mlp/activation_fn/Mul_1_output_0
[-0.0803  -0.0684  -0.0755  -0.03574 -0.0812  -0.0754  -0.1207  -0.0463
 -0.1606  -0.08246] ...(size = 236544 end with -0.03863525390625, sum = -14352.0)
/text_model/encoder/layers.5/mlp/fc2/MatMul_output_0
[-0.0617   -0.2122    0.04312   0.013725 -0.0086   -0.1423    0.0447
  0.1172    0.1696   -0.04538 ] ...(size = 59136 end with 0.04315185546875, sum = 47.03125)
/text_model/encoder/layers.5/mlp/fc2/Add_output_0
[-0.007633 -0.082    -0.01485   0.02945   0.02411  -0.04678   0.0575
  0.04974   0.0442   -0.03925 ] ...(size = 59136 end with 0.1383056640625, sum = 57.15625)
/text_model/encoder/layers.5/Add_1_output_0
[-0.853  -0.8726  1.541   0.546  -0.6978 -1.801  -0.865  -0.4644  1.555
  0.307 ] ...(size = 59136 end with -0.203369140625, sum = 225.375)
/text_model/encoder/layers.6/layer_norm1/ReduceMean_output_0
[-0.003351  0.00908   0.00609   0.006134  0.006126  0.006096  0.00606
  0.005966  0.006004  0.00598 ] ...(size = 77 end with 0.00191497802734375, sum = 0.29345703125)
/text_model/encoder/layers.6/layer_norm1/Sub_output_0
[-0.8496 -0.869   1.544   0.5493 -0.6943 -1.797  -0.8623 -0.4612  1.558
  0.3103] ...(size = 59136 end with -0.205322265625, sum = 0.054229736328125)
/text_model/encoder/layers.6/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.6/layer_norm1/Pow_output_0
[0.722  0.755  2.385  0.3018 0.4822 3.229  0.743  0.2126 2.426  0.0963] ...(size = 59136 end with 0.04217529296875, sum = inf)
/text_model/encoder/layers.6/layer_norm1/ReduceMean_1_output_0
[1.984e+02 1.029e-01 7.825e-02 8.179e-02 8.679e-02 9.021e-02 9.235e-02
 9.363e-02 9.399e-02 9.460e-02] ...(size = 77 end with 0.11541748046875, sum = 206.5)
/text_model/encoder/layers.6/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.6/layer_norm1/Add_output_0
[1.9838e+02 1.0297e-01 7.8247e-02 8.1787e-02 8.6792e-02 9.0210e-02
 9.2346e-02 9.3628e-02 9.4055e-02 9.4604e-02] ...(size = 77 end with 0.11541748046875, sum = 206.5)
/text_model/encoder/layers.6/layer_norm1/Sqrt_output_0
[14.086   0.3208  0.2798  0.2861  0.2947  0.3003  0.304   0.306   0.3066
  0.3076] ...(size = 77 end with 0.33984375, sum = 38.875)
/text_model/encoder/layers.6/layer_norm1/Div_output_0
[-0.06033 -0.06168  0.1096   0.039   -0.0493  -0.1276  -0.0612  -0.03275
  0.1106   0.02203] ...(size = 59136 end with -0.6044921875, sum = -0.0074462890625)
/text_model/encoder/layers.6/layer_norm1/Mul_output_0
[-0.09424 -0.10046  0.1658   0.06143 -0.07996 -0.2014  -0.0972  -0.05157
  0.1779   0.03522] ...(size = 59136 end with -0.95849609375, sum = -68.0)
/text_model/encoder/layers.6/layer_norm1/Add_1_output_0
[ 0.009796 -0.00344   0.00982   0.05316   0.02234  -0.06033   0.005787
  0.002695  0.01137   0.02644 ] ...(size = 59136 end with -0.951171875, sum = 148.25)
/text_model/encoder/layers.6/self_attn/q_proj/MatMul_output_0
[ 0.0354    0.014885  0.03033   0.268    -0.10046   0.03342  -0.2021
  0.04538  -0.0366    0.07904 ] ...(size = 59136 end with -0.8798828125, sum = 2362.0)
/text_model/encoder/layers.6/self_attn/q_proj/Add_output_0
[ 0.1554  -0.11414  0.228    0.0239  -0.04474 -0.1731  -0.075    0.2866
  0.0591   0.153  ] ...(size = 59136 end with -0.8115234375, sum = 3418.0)
/text_model/encoder/layers.6/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.6/self_attn/Mul_output_0
[ 0.01942  -0.01427   0.0285    0.002987 -0.005592 -0.02164  -0.00938
  0.03583   0.00739   0.01912 ] ...(size = 59136 end with -0.1014404296875, sum = 427.25)
/text_model/encoder/layers.6/self_attn/k_proj/MatMul_output_0
[ 0.07886  -0.06274   0.1444   -0.1653    0.0783   -0.05887  -0.0704
  0.1559   -0.005062  0.002054] ...(size = 59136 end with 1.333984375, sum = 125.375)
/text_model/encoder/layers.6/self_attn/k_proj/Add_output_0
[ 0.0852   -0.06003   0.1388   -0.159     0.07684  -0.05743  -0.07056
  0.1498   -0.001518 -0.002905] ...(size = 59136 end with 1.3388671875, sum = 98.75)
/text_model/encoder/layers.6/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.6/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.6/self_attn/Reshape_output_0
[ 0.0852   -0.06003   0.1388   -0.159     0.07684  -0.05743  -0.07056
  0.1498   -0.001518 -0.002905] ...(size = 59136 end with 1.3388671875, sum = 98.75)
/text_model/encoder/layers.6/self_attn/Transpose_output_0
[ 0.0852   -0.06003   0.1388   -0.159     0.07684  -0.05743  -0.07056
  0.1498   -0.001518 -0.002905] ...(size = 59136 end with 1.3388671875, sum = 98.8125)
/text_model/encoder/layers.6/self_attn/v_proj/MatMul_output_0
[-0.04456  -0.003822  0.00326  -0.05835  -0.04214   0.05185   0.07007
 -0.06287   0.00906   0.01646 ] ...(size = 59136 end with 0.20458984375, sum = 1079.0)
/text_model/encoder/layers.6/self_attn/v_proj/Add_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.1982421875, sum = 1198.0)
/text_model/encoder/layers.6/self_attn/Reshape_1_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.1982421875, sum = 1198.0)
/text_model/encoder/layers.6/self_attn/Transpose_1_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.1982421875, sum = 1198.0)
/text_model/encoder/layers.6/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.6/self_attn/Reshape_2_output_0
[ 0.01942  -0.01427   0.0285    0.002987 -0.005592 -0.02164  -0.00938
  0.03583   0.00739   0.01912 ] ...(size = 59136 end with -0.1014404296875, sum = 427.25)
/text_model/encoder/layers.6/self_attn/Transpose_2_output_0
[ 0.01942  -0.01427   0.0285    0.002987 -0.005592 -0.02164  -0.00938
  0.03583   0.00739   0.01912 ] ...(size = 59136 end with -0.1014404296875, sum = 427.5)
/text_model/encoder/layers.6/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.6/self_attn/Reshape_3_output_0
[ 0.01942  -0.01427   0.0285    0.002987 -0.005592 -0.02164  -0.00938
  0.03583   0.00739   0.01912 ] ...(size = 59136 end with -0.1014404296875, sum = 427.5)
/text_model/encoder/layers.6/self_attn/Reshape_4_output_0
[ 0.0852   -0.06003   0.1388   -0.159     0.07684  -0.05743  -0.07056
  0.1498   -0.001518 -0.002905] ...(size = 59136 end with 1.3388671875, sum = 98.8125)
/text_model/encoder/layers.6/self_attn/Reshape_5_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.1982421875, sum = 1198.0)
/text_model/encoder/layers.6/self_attn/Transpose_3_output_0
[0.0852 1.013  1.82   1.915  2.027  2.074  2.08   2.057  2.023  1.971 ] ...(size = 59136 end with 1.3388671875, sum = 98.375)
/text_model/encoder/layers.6/self_attn/MatMul_output_0
[ 0.4312 -0.6636 -0.5527 -0.6094 -0.6567 -0.6963 -0.719  -0.743  -0.7583
 -0.773 ] ...(size = 71148 end with -5.2890625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.6/self_attn/Reshape_6_output_0
[ 0.4312 -0.6636 -0.5527 -0.6094 -0.6567 -0.6963 -0.719  -0.743  -0.7583
 -0.773 ] ...(size = 71148 end with -5.2890625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Add_output_0
[ 4.312e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -5.2890625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.6/self_attn/Reshape_7_output_0
[ 4.312e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -5.2890625, sum = -inf)
/text_model/encoder/layers.6/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0008826255798339844, sum = 924.0)
/text_model/encoder/layers.6/self_attn/MatMul_1_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.027618408203125, sum = -85.6875)
/text_model/encoder/layers.6/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.6/self_attn/Reshape_8_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.027618408203125, sum = -85.6875)
/text_model/encoder/layers.6/self_attn/Transpose_4_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.027618408203125, sum = -85.625)
/text_model/encoder/layers.6/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.6/self_attn/Reshape_9_output_0
[-0.01743  -0.002594  0.007595 -0.01723  -0.02179   0.04486   0.05008
 -0.0358    0.01345   0.003794] ...(size = 59136 end with 0.027618408203125, sum = -85.625)
/text_model/encoder/layers.6/self_attn/out_proj/MatMul_output_0
[-0.02554  -0.002455  0.01564  -0.000639 -0.00429  -0.009926  0.02617
  0.02426   0.02943  -0.001283] ...(size = 59136 end with -0.018096923828125, sum = -7.171875)
/text_model/encoder/layers.6/self_attn/out_proj/Add_output_0
[-0.00469  -0.02309  -0.03467  -0.0165    0.01438  -0.01852   0.04312
 -0.01852  -0.001534  0.02762 ] ...(size = 59136 end with -0.048583984375, sum = 29.8125)
/text_model/encoder/layers.6/Add_output_0
[-0.858  -0.8955  1.506   0.5293 -0.6836 -1.819  -0.8223 -0.483   1.553
  0.3347] ...(size = 59136 end with -0.251953125, sum = 255.125)
/text_model/encoder/layers.6/layer_norm2/ReduceMean_output_0
[-0.002607  0.009796  0.006813  0.006844  0.006824  0.006786  0.006763
  0.00667   0.006718  0.006695] ...(size = 77 end with 0.00226593017578125, sum = 0.332275390625)
/text_model/encoder/layers.6/layer_norm2/Sub_output_0
[-0.8555 -0.8926  1.509   0.532  -0.6807 -1.816  -0.82   -0.4805  1.556
  0.3372] ...(size = 59136 end with -0.254150390625, sum = -0.0887451171875)
/text_model/encoder/layers.6/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.6/layer_norm2/Pow_output_0
[0.7314 0.797  2.275  0.2832 0.4634 3.299  0.672  0.2307 2.42   0.1137] ...(size = 59136 end with 0.06463623046875, sum = inf)
/text_model/encoder/layers.6/layer_norm2/ReduceMean_1_output_0
[1.986e+02 1.055e-01 8.038e-02 8.447e-02 8.990e-02 9.381e-02 9.644e-02
 9.821e-02 9.906e-02 9.991e-02] ...(size = 77 end with 0.12457275390625, sum = 207.25)
/text_model/encoder/layers.6/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.6/layer_norm2/Add_output_0
[1.986e+02 1.056e-01 8.038e-02 8.447e-02 8.990e-02 9.381e-02 9.644e-02
 9.821e-02 9.906e-02 9.998e-02] ...(size = 77 end with 0.12457275390625, sum = 207.25)
/text_model/encoder/layers.6/layer_norm2/Sqrt_output_0
[14.09    0.325   0.2834  0.2908  0.2998  0.3064  0.3105  0.3135  0.3147
  0.3162] ...(size = 77 end with 0.35302734375, sum = 39.71875)
/text_model/encoder/layers.6/layer_norm2/Div_output_0
[-0.0607  -0.06335  0.10706  0.03775 -0.0483  -0.1289  -0.05817 -0.0341
  0.1104   0.02393] ...(size = 59136 end with -0.72021484375, sum = 0.02960205078125)
/text_model/encoder/layers.6/layer_norm2/Mul_output_0
[-0.1333  -0.1422   0.234    0.0801  -0.07916 -0.2817  -0.1259  -0.0778
  0.2443   0.05304] ...(size = 59136 end with -1.6923828125, sum = -625.0)
/text_model/encoder/layers.6/layer_norm2/Add_1_output_0
[-4.313e-04  9.067e-01 -2.059e-01 -2.708e-01 -2.365e-01 -1.770e-01
  2.203e-01 -4.385e-01 -2.869e-01 -6.201e-02] ...(size = 59136 end with -0.63134765625, sum = -563.5)
/text_model/encoder/layers.6/mlp/fc1/MatMul_output_0
[-0.3037 -1.797  -2.12   -1.3    -1.762  -1.808  -1.829  -1.733  -2.045
 -1.107 ] ...(size = 236544 end with -2.509765625, sum = -inf)
/text_model/encoder/layers.6/mlp/fc1/Add_output_0
[-0.599 -2.127 -2.467 -1.554 -2.1   -2.16  -2.184 -2.072 -2.346 -1.456] ...(size = 236544 end with -2.845703125, sum = -inf)
/text_model/encoder/layers.6/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.6/mlp/activation_fn/Mul_output_0
[-1.0205 -3.62   -4.2    -2.645  -3.572  -3.678  -3.715  -3.525  -3.992
 -2.479 ] ...(size = 236544 end with -4.84375, sum = -inf)
/text_model/encoder/layers.6/mlp/activation_fn/Sigmoid_output_0
[0.265   0.0261  0.01477 0.0663  0.02731 0.02464 0.02377 0.02858 0.01811
 0.07745] ...(size = 236544 end with 0.0078125, sum = 24656.0)
/text_model/encoder/layers.6/mlp/activation_fn/Mul_1_output_0
[-0.1588  -0.05548 -0.03644 -0.103   -0.05734 -0.05325 -0.05188 -0.0592
 -0.04248 -0.11273] ...(size = 236544 end with -0.0222320556640625, sum = -13960.0)
/text_model/encoder/layers.6/mlp/fc2/MatMul_output_0
[-0.0774    0.1029    0.1974   -0.0278   -0.0981   -0.2107   -0.0809
  0.07336   0.002804 -0.02419 ] ...(size = 59136 end with 0.1971435546875, sum = 48.21875)
/text_model/encoder/layers.6/mlp/fc2/Add_output_0
[-0.0009675  0.1423     0.06012    0.03033   -0.05847   -0.1366
 -0.02374    0.06964   -0.00335   -0.01209  ] ...(size = 59136 end with 0.21533203125, sum = 69.5)
/text_model/encoder/layers.6/Add_1_output_0
[-0.859  -0.753   1.566   0.5596 -0.7417 -1.955  -0.846  -0.4133  1.55
  0.3225] ...(size = 59136 end with -0.03668212890625, sum = 324.75)
/text_model/encoder/layers.7/layer_norm1/ReduceMean_output_0
[-0.002127  0.01039   0.007557  0.007835  0.00797   0.00801   0.00803
  0.00791   0.007935  0.007904] ...(size = 77 end with 0.003505706787109375, sum = 0.4228515625)
/text_model/encoder/layers.7/layer_norm1/Sub_output_0
[-0.857  -0.751   1.568   0.562  -0.7397 -1.953  -0.8438 -0.4111  1.552
  0.3247] ...(size = 59136 end with -0.0401611328125, sum = 0.051849365234375)
/text_model/encoder/layers.7/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.7/layer_norm1/Pow_output_0
[0.734  0.564  2.459  0.3157 0.5474 3.816  0.7124 0.1691 2.408  0.1054] ...(size = 59136 end with 0.0016145706176757812, sum = inf)
/text_model/encoder/layers.7/layer_norm1/ReduceMean_1_output_0
[1.984e+02 1.057e-01 8.063e-02 8.606e-02 9.137e-02 9.485e-02 9.674e-02
 9.821e-02 9.894e-02 9.961e-02] ...(size = 77 end with 0.1195068359375, sum = 206.875)
/text_model/encoder/layers.7/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.7/layer_norm1/Add_output_0
[1.984e+02 1.057e-01 8.063e-02 8.606e-02 9.137e-02 9.485e-02 9.674e-02
 9.827e-02 9.900e-02 9.961e-02] ...(size = 77 end with 0.1195068359375, sum = 206.875)
/text_model/encoder/layers.7/layer_norm1/Sqrt_output_0
[14.086   0.3252  0.284   0.2935  0.3022  0.3079  0.311   0.3135  0.3147
  0.3157] ...(size = 77 end with 0.345703125, sum = 39.4375)
/text_model/encoder/layers.7/layer_norm1/Div_output_0
[-0.06082 -0.0533   0.1113   0.0399  -0.05252 -0.1387  -0.0599  -0.02919
  0.11017  0.02306] ...(size = 59136 end with -0.1162109375, sum = 0.00086212158203125)
/text_model/encoder/layers.7/layer_norm1/Mul_output_0
[-0.09424 -0.0874   0.1781   0.0634  -0.08575 -0.2274  -0.09247 -0.04666
  0.1755   0.03745] ...(size = 59136 end with -0.191162109375, sum = -268.75)
/text_model/encoder/layers.7/layer_norm1/Add_1_output_0
[ 0.004974 -0.04358   0.000631  0.0954   -0.005917 -0.007065  0.000993
 -0.00971   0.06113   0.02507 ] ...(size = 59136 end with -0.1956787109375, sum = -41.1875)
/text_model/encoder/layers.7/self_attn/q_proj/MatMul_output_0
[-0.1251  -0.0678   0.1034   0.2     -0.1584  -0.591   -0.0714  -0.08606
 -0.155    0.173  ] ...(size = 59136 end with 0.7587890625, sum = 1097.0)
/text_model/encoder/layers.7/self_attn/q_proj/Add_output_0
[-0.3657   0.2299   0.4795   0.04813 -0.39     0.306    0.2118  -0.2566
  0.01917 -0.1705 ] ...(size = 59136 end with 0.7822265625, sum = 330.25)
/text_model/encoder/layers.7/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.7/self_attn/Mul_output_0
[-0.04572   0.02873   0.05994   0.006016 -0.04874   0.03824   0.02647
 -0.03207   0.002396 -0.02132 ] ...(size = 59136 end with 0.0977783203125, sum = 41.28125)
/text_model/encoder/layers.7/self_attn/k_proj/MatMul_output_0
[-0.1927   0.289    0.1956  -0.04587 -0.2517   0.9756   0.2202  -0.0924
  0.0766  -0.2324 ] ...(size = 59136 end with 0.5224609375, sum = -747.0)
/text_model/encoder/layers.7/self_attn/k_proj/Add_output_0
[-0.202    0.3015   0.1934  -0.03995 -0.2534   1.016    0.2375  -0.0917
  0.0929  -0.2362 ] ...(size = 59136 end with 0.51708984375, sum = -709.5)
/text_model/encoder/layers.7/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.7/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.7/self_attn/Reshape_output_0
[-0.202    0.3015   0.1934  -0.03995 -0.2534   1.016    0.2375  -0.0917
  0.0929  -0.2362 ] ...(size = 59136 end with 0.51708984375, sum = -709.5)
/text_model/encoder/layers.7/self_attn/Transpose_output_0
[-0.202    0.3015   0.1934  -0.03995 -0.2534   1.016    0.2375  -0.0917
  0.0929  -0.2362 ] ...(size = 59136 end with 0.51708984375, sum = -709.5)
/text_model/encoder/layers.7/self_attn/v_proj/MatMul_output_0
[ 0.0323   -0.006413 -0.05884   0.04074   0.09045   0.02344   0.10004
 -0.01319  -0.018    -0.07104 ] ...(size = 59136 end with 1.4111328125, sum = 1320.0)
/text_model/encoder/layers.7/self_attn/v_proj/Add_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 1.435546875, sum = 1426.0)
/text_model/encoder/layers.7/self_attn/Reshape_1_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 1.435546875, sum = 1426.0)
/text_model/encoder/layers.7/self_attn/Transpose_1_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 1.435546875, sum = 1425.0)
/text_model/encoder/layers.7/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.7/self_attn/Reshape_2_output_0
[-0.04572   0.02873   0.05994   0.006016 -0.04874   0.03824   0.02647
 -0.03207   0.002396 -0.02132 ] ...(size = 59136 end with 0.0977783203125, sum = 41.28125)
/text_model/encoder/layers.7/self_attn/Transpose_2_output_0
[-0.04572   0.02873   0.05994   0.006016 -0.04874   0.03824   0.02647
 -0.03207   0.002396 -0.02132 ] ...(size = 59136 end with 0.0977783203125, sum = 41.21875)
/text_model/encoder/layers.7/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.7/self_attn/Reshape_3_output_0
[-0.04572   0.02873   0.05994   0.006016 -0.04874   0.03824   0.02647
 -0.03207   0.002396 -0.02132 ] ...(size = 59136 end with 0.0977783203125, sum = 41.21875)
/text_model/encoder/layers.7/self_attn/Reshape_4_output_0
[-0.202    0.3015   0.1934  -0.03995 -0.2534   1.016    0.2375  -0.0917
  0.0929  -0.2362 ] ...(size = 59136 end with 0.51708984375, sum = -709.5)
/text_model/encoder/layers.7/self_attn/Reshape_5_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 1.435546875, sum = 1425.0)
/text_model/encoder/layers.7/self_attn/Transpose_3_output_0
[-0.202   0.1663  0.8228  1.301   1.323   1.218   1.094   1.039   0.9287
  0.8794] ...(size = 59136 end with 0.51708984375, sum = -709.5)
/text_model/encoder/layers.7/self_attn/MatMul_output_0
[ 0.527  -0.5483 -0.9263 -1.149  -1.247  -1.32   -1.3545 -1.395  -1.421
 -1.445 ] ...(size = 71148 end with -3.3515625, sum = -inf)
/text_model/encoder/layers.7/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.7/self_attn/Reshape_6_output_0
[ 0.527  -0.5483 -0.9263 -1.149  -1.247  -1.32   -1.3545 -1.395  -1.421
 -1.445 ] ...(size = 71148 end with -3.3515625, sum = -inf)
/text_model/encoder/layers.7/self_attn/Add_output_0
[ 5.27e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.3515625, sum = -inf)
/text_model/encoder/layers.7/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.7/self_attn/Reshape_7_output_0
[ 5.27e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -3.3515625, sum = -inf)
/text_model/encoder/layers.7/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.002300262451171875, sum = 924.0)
/text_model/encoder/layers.7/self_attn/MatMul_1_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 0.078369140625, sum = 369.75)
/text_model/encoder/layers.7/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.7/self_attn/Reshape_8_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 0.078369140625, sum = 369.75)
/text_model/encoder/layers.7/self_attn/Transpose_4_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 0.078369140625, sum = 369.75)
/text_model/encoder/layers.7/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.7/self_attn/Reshape_9_output_0
[-0.00567  -0.003378 -0.03065   0.006737  0.03824  -0.01188   0.00427
  0.00794   0.02866  -0.02338 ] ...(size = 59136 end with 0.078369140625, sum = 369.75)
/text_model/encoder/layers.7/self_attn/out_proj/MatMul_output_0
[-0.001789 -0.06012   0.03775  -0.00918  -0.002613 -0.01645  -0.01749
 -0.01161  -0.00902  -0.01298 ] ...(size = 59136 end with -0.05389404296875, sum = 1.32421875)
/text_model/encoder/layers.7/self_attn/out_proj/Add_output_0
[-0.003445 -0.1283    0.03146  -0.0103    0.01533  -0.0458    0.00843
 -0.02754   0.00894  -0.03247 ] ...(size = 59136 end with -0.09844970703125, sum = 41.65625)
/text_model/encoder/layers.7/Add_output_0
[-0.8623 -0.8813  1.598   0.5493 -0.7266 -2.002  -0.8374 -0.441   1.559
  0.29  ] ...(size = 59136 end with -0.1351318359375, sum = 366.0)
/text_model/encoder/layers.7/layer_norm2/ReduceMean_output_0
[-0.001568  0.01095   0.00811   0.00842   0.00858   0.008644  0.00868
  0.00857   0.0086    0.00856 ] ...(size = 77 end with 0.0042572021484375, sum = 0.47705078125)
/text_model/encoder/layers.7/layer_norm2/Sub_output_0
[-0.861  -0.88    1.6     0.5513 -0.725  -2.     -0.836  -0.4392  1.56
  0.2915] ...(size = 59136 end with -0.139404296875, sum = -0.06072998046875)
/text_model/encoder/layers.7/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.7/layer_norm2/Pow_output_0
[0.7407 0.774  2.559  0.3037 0.5254 4.     0.699  0.193  2.434  0.085 ] ...(size = 59136 end with 0.0194244384765625, sum = inf)
/text_model/encoder/layers.7/layer_norm2/ReduceMean_1_output_0
[1.986e+02 1.087e-01 8.301e-02 8.740e-02 9.192e-02 9.479e-02 9.631e-02
 9.760e-02 9.808e-02 9.851e-02] ...(size = 77 end with 0.11932373046875, sum = 207.0)
/text_model/encoder/layers.7/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.7/layer_norm2/Add_output_0
[1.986e+02 1.087e-01 8.301e-02 8.740e-02 9.192e-02 9.485e-02 9.631e-02
 9.760e-02 9.808e-02 9.857e-02] ...(size = 77 end with 0.11932373046875, sum = 207.0)
/text_model/encoder/layers.7/layer_norm2/Sqrt_output_0
[14.09    0.3296  0.288   0.2957  0.3032  0.3079  0.3103  0.3123  0.3132
  0.314 ] ...(size = 77 end with 0.345458984375, sum = 39.3125)
/text_model/encoder/layers.7/layer_norm2/Div_output_0
[-0.06107 -0.06244  0.11346  0.0391  -0.05145 -0.1418  -0.05933 -0.03117
  0.1107   0.02069] ...(size = 59136 end with -0.403564453125, sum = -0.061431884765625)
/text_model/encoder/layers.7/layer_norm2/Mul_output_0
[-0.1383  -0.1346   0.2578   0.08765 -0.089   -0.316   -0.1318  -0.06836
  0.254    0.0477 ] ...(size = 59136 end with -0.953125, sum = -579.5)
/text_model/encoder/layers.7/layer_norm2/Add_1_output_0
[ 0.02386 -0.00253 -0.6045   0.05408  0.0612  -0.2617   0.05502 -0.0204
  0.3674   0.03044] ...(size = 59136 end with -0.312744140625, sum = 244.375)
/text_model/encoder/layers.7/mlp/fc1/MatMul_output_0
[-1.316  -1.588  -0.8076 -0.602  -1.245  -1.327  -1.279  -1.159  -1.357
 -0.9595] ...(size = 236544 end with -1.0263671875, sum = -inf)
/text_model/encoder/layers.7/mlp/fc1/Add_output_0
[-1.67   -1.866  -1.194  -0.8286 -1.634  -1.7    -1.587  -1.548  -1.695
 -1.281 ] ...(size = 236544 end with -1.2529296875, sum = -inf)
/text_model/encoder/layers.7/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.7/mlp/activation_fn/Mul_output_0
[-2.844 -3.178 -2.033 -1.41  -2.781 -2.895 -2.701 -2.635 -2.887 -2.182] ...(size = 236544 end with -2.1328125, sum = -inf)
/text_model/encoder/layers.7/mlp/activation_fn/Sigmoid_output_0
[0.05505 0.04004 0.11584 0.1962  0.05838 0.05243 0.0629  0.06696 0.05286
 0.10144] ...(size = 236544 end with 0.10589599609375, sum = 19536.0)
/text_model/encoder/layers.7/mlp/activation_fn/Mul_1_output_0
[-0.0919  -0.0747  -0.1383  -0.1626  -0.09534 -0.0892  -0.09985 -0.1036
 -0.0896  -0.13   ] ...(size = 236544 end with -0.1326904296875, sum = -14568.0)
/text_model/encoder/layers.7/mlp/fc2/MatMul_output_0
[ 0.01817 -0.09076  0.1048  -0.07056  0.06192 -0.03958 -0.07806  0.09045
  0.03592  0.1399 ] ...(size = 59136 end with 0.0360107421875, sum = 17.765625)
/text_model/encoder/layers.7/mlp/fc2/Add_output_0
[ 0.0622  -0.04672  0.06445  0.00767  0.0651  -0.04648 -0.01458  0.09106
  0.05917  0.08966] ...(size = 59136 end with 0.0217132568359375, sum = 27.53125)
/text_model/encoder/layers.7/Add_1_output_0
[-0.8003 -0.928   1.662   0.557  -0.661  -2.047  -0.852  -0.3499  1.617
  0.3796] ...(size = 59136 end with -0.1134033203125, sum = 393.75)
/text_model/encoder/layers.8/layer_norm1/ReduceMean_output_0
[-0.001335  0.01097   0.00837   0.008865  0.00906   0.009125  0.009125
  0.00898   0.009     0.00894 ] ...(size = 77 end with 0.00481414794921875, sum = 0.5126953125)
/text_model/encoder/layers.8/layer_norm1/Sub_output_0
[-0.799  -0.927   1.663   0.5586 -0.66   -2.047  -0.851  -0.3484  1.619
  0.381 ] ...(size = 59136 end with -0.11822509765625, sum = 0.07806396484375)
/text_model/encoder/layers.8/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.8/layer_norm1/Pow_output_0
[0.638  0.859  2.768  0.312  0.4355 4.188  0.724  0.1214 2.621  0.1451] ...(size = 59136 end with 0.01397705078125, sum = inf)
/text_model/encoder/layers.8/layer_norm1/ReduceMean_1_output_0
[1.998e+02 1.021e-01 8.398e-02 8.728e-02 9.143e-02 9.393e-02 9.503e-02
 9.583e-02 9.576e-02 9.576e-02] ...(size = 77 end with 0.1142578125, sum = 207.875)
/text_model/encoder/layers.8/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.8/layer_norm1/Add_output_0
[1.998e+02 1.021e-01 8.398e-02 8.728e-02 9.143e-02 9.393e-02 9.503e-02
 9.583e-02 9.576e-02 9.576e-02] ...(size = 77 end with 0.1142578125, sum = 207.875)
/text_model/encoder/layers.8/layer_norm1/Sqrt_output_0
[14.13    0.3196  0.2898  0.2954  0.3025  0.3064  0.3083  0.3096  0.3096
  0.3096] ...(size = 77 end with 0.337890625, sum = 38.90625)
/text_model/encoder/layers.8/layer_norm1/Div_output_0
[-0.05652 -0.06555  0.11774  0.03952 -0.0467  -0.1448  -0.0602  -0.02466
  0.11456  0.02696] ...(size = 59136 end with -0.349853515625, sum = 0.027740478515625)
/text_model/encoder/layers.8/layer_norm1/Mul_output_0
[-0.1013  -0.11694  0.2096   0.06647 -0.07556 -0.2634  -0.11005 -0.0448
  0.2084   0.04715] ...(size = 59136 end with -0.60205078125, sum = -272.75)
/text_model/encoder/layers.8/layer_norm1/Add_1_output_0
[ 0.00815   0.003355 -0.01688   0.0801    0.001571 -0.0557    0.01724
  0.008644  0.02081   0.0434  ] ...(size = 59136 end with -0.59130859375, sum = -38.0625)
/text_model/encoder/layers.8/self_attn/q_proj/MatMul_output_0
[ 0.1276  -0.4712   0.1685   0.327   -0.2152  -0.01723 -0.04883 -0.11487
  0.2065  -0.1497 ] ...(size = 59136 end with 0.014495849609375, sum = -2052.0)
/text_model/encoder/layers.8/self_attn/q_proj/Add_output_0
[ 0.0937   0.124   -0.1785  -0.04874  0.0241   0.01248  0.144    0.1405
  0.3074   0.33   ] ...(size = 59136 end with -0.2393798828125, sum = -2636.0)
/text_model/encoder/layers.8/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.8/self_attn/Mul_output_0
[ 0.01171   0.0155   -0.02231  -0.006092  0.003012  0.00156   0.018
  0.01756   0.03842   0.04126 ] ...(size = 59136 end with -0.0299224853515625, sum = -329.5)
/text_model/encoder/layers.8/self_attn/k_proj/MatMul_output_0
[ 0.05194  0.5396  -0.1573  -0.2637   0.2947   0.0816   0.07263  0.3044
  0.05377  0.525  ] ...(size = 59136 end with -0.71435546875, sum = 2122.0)
/text_model/encoder/layers.8/self_attn/k_proj/Add_output_0
[ 0.02818  0.4993  -0.1348  -0.2341   0.2229   0.0779   0.0744   0.272
  0.0512   0.492  ] ...(size = 59136 end with -0.7099609375, sum = 2140.0)
/text_model/encoder/layers.8/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.8/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.8/self_attn/Reshape_output_0
[ 0.02818  0.4993  -0.1348  -0.2341   0.2229   0.0779   0.0744   0.272
  0.0512   0.492  ] ...(size = 59136 end with -0.7099609375, sum = 2140.0)
/text_model/encoder/layers.8/self_attn/Transpose_output_0
[ 0.02818  0.4993  -0.1348  -0.2341   0.2229   0.0779   0.0744   0.272
  0.0512   0.492  ] ...(size = 59136 end with -0.7099609375, sum = 2142.0)
/text_model/encoder/layers.8/self_attn/v_proj/MatMul_output_0
[-0.02612 -0.07947 -0.01395  0.0716  -0.04245 -0.0746  -0.01718 -0.01467
  0.0512   0.09357] ...(size = 59136 end with -0.203369140625, sum = 87.5)
/text_model/encoder/layers.8/self_attn/v_proj/Add_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.196044921875, sum = -18.640625)
/text_model/encoder/layers.8/self_attn/Reshape_1_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.196044921875, sum = -18.640625)
/text_model/encoder/layers.8/self_attn/Transpose_1_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.196044921875, sum = -18.5625)
/text_model/encoder/layers.8/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.8/self_attn/Reshape_2_output_0
[ 0.01171   0.0155   -0.02231  -0.006092  0.003012  0.00156   0.018
  0.01756   0.03842   0.04126 ] ...(size = 59136 end with -0.0299224853515625, sum = -329.5)
/text_model/encoder/layers.8/self_attn/Transpose_2_output_0
[ 0.01171   0.0155   -0.02231  -0.006092  0.003012  0.00156   0.018
  0.01756   0.03842   0.04126 ] ...(size = 59136 end with -0.0299224853515625, sum = -329.5)
/text_model/encoder/layers.8/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.8/self_attn/Reshape_3_output_0
[ 0.01171   0.0155   -0.02231  -0.006092  0.003012  0.00156   0.018
  0.01756   0.03842   0.04126 ] ...(size = 59136 end with -0.0299224853515625, sum = -329.5)
/text_model/encoder/layers.8/self_attn/Reshape_4_output_0
[ 0.02818  0.4993  -0.1348  -0.2341   0.2229   0.0779   0.0744   0.272
  0.0512   0.492  ] ...(size = 59136 end with -0.7099609375, sum = 2142.0)
/text_model/encoder/layers.8/self_attn/Reshape_5_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.196044921875, sum = -18.5625)
/text_model/encoder/layers.8/self_attn/Transpose_3_output_0
[0.02818 0.8477  0.6895  0.6865  0.4285  0.2734  0.1661  0.157   0.1222
 0.0822 ] ...(size = 59136 end with -0.7099609375, sum = 2142.0)
/text_model/encoder/layers.8/self_attn/MatMul_output_0
[ 0.4722 -1.049  -0.9067 -0.908  -0.9663 -1.03   -1.087  -1.144  -1.191
 -1.233 ] ...(size = 71148 end with -4.8671875, sum = -inf)
/text_model/encoder/layers.8/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.8/self_attn/Reshape_6_output_0
[ 0.4722 -1.049  -0.9067 -0.908  -0.9663 -1.03   -1.087  -1.144  -1.191
 -1.233 ] ...(size = 71148 end with -4.8671875, sum = -inf)
/text_model/encoder/layers.8/self_attn/Add_output_0
[ 4.722e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.8671875, sum = -inf)
/text_model/encoder/layers.8/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.8/self_attn/Reshape_7_output_0
[ 4.722e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -4.8671875, sum = -inf)
/text_model/encoder/layers.8/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0005121231079101562, sum = 924.0)
/text_model/encoder/layers.8/self_attn/MatMul_1_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.0050811767578125, sum = 763.5)
/text_model/encoder/layers.8/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.8/self_attn/Reshape_8_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.0050811767578125, sum = 763.5)
/text_model/encoder/layers.8/self_attn/Transpose_4_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.0050811767578125, sum = 763.5)
/text_model/encoder/layers.8/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.8/self_attn/Reshape_9_output_0
[-0.01297  -0.03476  -0.02086   0.045    -0.02664  -0.03815  -0.01044
  0.004856  0.03029   0.03372 ] ...(size = 59136 end with -0.0050811767578125, sum = 763.5)
/text_model/encoder/layers.8/self_attn/out_proj/MatMul_output_0
[-0.008995  0.002224 -0.00807  -0.002558 -0.0605   -0.004463 -0.02493
  0.014915  0.006474  0.01484 ] ...(size = 59136 end with -0.06365966796875, sum = -29.875)
/text_model/encoder/layers.8/self_attn/out_proj/Add_output_0
[-0.04175 -0.03503  0.06256 -0.05197 -0.1461  -0.1218  -0.0221   0.0502
  0.03397 -0.05908] ...(size = 59136 end with -0.09820556640625, sum = -24.578125)
/text_model/encoder/layers.8/Add_output_0
[-0.842  -0.9634  1.725   0.5054 -0.8076 -2.17   -0.8745 -0.2996  1.651
  0.3206] ...(size = 59136 end with -0.211669921875, sum = 369.25)
/text_model/encoder/layers.8/layer_norm2/ReduceMean_output_0
[-0.0009046  0.01128    0.008514   0.00895    0.00913    0.00921
  0.00925    0.00911    0.009155   0.0091   ] ...(size = 77 end with 0.003635406494140625, sum = 0.48095703125)
/text_model/encoder/layers.8/layer_norm2/Sub_output_0
[-0.841  -0.9624  1.726   0.5063 -0.8066 -2.168  -0.8735 -0.2986  1.652
  0.3215] ...(size = 59136 end with -0.21533203125, sum = -0.141845703125)
/text_model/encoder/layers.8/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.8/layer_norm2/Pow_output_0
[0.707   0.926   2.979   0.256   0.6504  4.703   0.7627  0.08923 2.73
 0.10333] ...(size = 59136 end with 0.046356201171875, sum = inf)
/text_model/encoder/layers.8/layer_norm2/ReduceMean_1_output_0
[1.9988e+02 1.0852e-01 8.9539e-02 9.3018e-02 9.7107e-02 9.9548e-02
 1.0071e-01 1.0175e-01 1.0193e-01 1.0205e-01] ...(size = 77 end with 0.1339111328125, sum = 208.875)
/text_model/encoder/layers.8/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.8/layer_norm2/Add_output_0
[1.9988e+02 1.0852e-01 8.9539e-02 9.3018e-02 9.7107e-02 9.9609e-02
 1.0071e-01 1.0175e-01 1.0193e-01 1.0205e-01] ...(size = 77 end with 0.1339111328125, sum = 208.875)
/text_model/encoder/layers.8/layer_norm2/Sqrt_output_0
[14.14    0.3293  0.2993  0.305   0.3115  0.3157  0.3174  0.319   0.3193
  0.3193] ...(size = 77 end with 0.365966796875, sum = 40.1875)
/text_model/encoder/layers.8/layer_norm2/Div_output_0
[-0.05948 -0.06805  0.1221   0.0358  -0.05704 -0.1534  -0.06177 -0.02112
  0.1169   0.02274] ...(size = 59136 end with -0.58837890625, sum = 0.0241851806640625)
/text_model/encoder/layers.8/layer_norm2/Mul_output_0
[-0.1409  -0.1519   0.266    0.08093 -0.1071  -0.3755  -0.1376  -0.04794
  0.2722   0.0558 ] ...(size = 59136 end with -1.392578125, sum = -435.0)
/text_model/encoder/layers.8/layer_norm2/Add_1_output_0
[-0.3606   0.1836  -0.2118   0.3105  -0.3643  -0.6533   0.1305   0.05618
 -0.11    -0.2281 ] ...(size = 59136 end with -1.12890625, sum = -1675.0)
/text_model/encoder/layers.8/mlp/fc1/MatMul_output_0
[-2.367  -0.713  -1.07   -1.127  -2.115  -0.9116 -0.677  -1.818  -1.442
 -1.028 ] ...(size = 236544 end with -1.5048828125, sum = -inf)
/text_model/encoder/layers.8/mlp/fc1/Add_output_0
[-2.613 -1.053 -1.456 -1.414 -2.408 -1.059 -0.737 -2.158 -1.762 -1.349] ...(size = 236544 end with -1.6474609375, sum = -inf)
/text_model/encoder/layers.8/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.8/mlp/activation_fn/Mul_output_0
[-4.45  -1.792 -2.479 -2.408 -4.098 -1.803 -1.254 -3.674 -3.    -2.297] ...(size = 236544 end with -2.8046875, sum = -inf)
/text_model/encoder/layers.8/mlp/activation_fn/Sigmoid_output_0
[0.011566 0.1428   0.0774   0.0826   0.01633  0.1416   0.2219   0.02478
 0.04745  0.09143 ] ...(size = 236544 end with 0.057098388671875, sum = 23392.0)
/text_model/encoder/layers.8/mlp/activation_fn/Mul_1_output_0
[-0.03021 -0.1504  -0.1127  -0.1168  -0.0393  -0.1499  -0.1636  -0.05347
 -0.0836  -0.12335] ...(size = 236544 end with -0.09405517578125, sum = -15512.0)
/text_model/encoder/layers.8/mlp/fc2/MatMul_output_0
[-0.0792   0.2642  -0.1702   0.1464  -0.02072  0.3403  -0.147   -0.2229
 -0.1969   0.2932 ] ...(size = 59136 end with 0.005126953125, sum = 50.875)
/text_model/encoder/layers.8/mlp/fc2/Add_output_0
[-0.05762  0.2251  -0.1231   0.1071  -0.06934  0.2915  -0.07794 -0.1703
 -0.1425   0.2607 ] ...(size = 59136 end with 0.004425048828125, sum = 71.4375)
/text_model/encoder/layers.8/Add_1_output_0
[-0.8994 -0.738   1.602   0.6123 -0.877  -1.878  -0.952  -0.4697  1.509
  0.5815] ...(size = 59136 end with -0.207275390625, sum = 440.75)
/text_model/encoder/layers.9/layer_norm1/ReduceMean_output_0
[0.0001799 0.011826  0.0097    0.01035   0.010506  0.01062   0.010666
 0.010574  0.01063   0.01062  ] ...(size = 77 end with 0.004970550537109375, sum = 0.57373046875)
/text_model/encoder/layers.9/layer_norm1/Sub_output_0
[-0.8994 -0.7383  1.602   0.6123 -0.877  -1.878  -0.9526 -0.47    1.509
  0.581 ] ...(size = 59136 end with -0.212158203125, sum = 0.0005502700805664062)
/text_model/encoder/layers.9/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.9/layer_norm1/Pow_output_0
[0.8096 0.545  2.564  0.3748 0.769  3.527  0.907  0.221  2.277  0.338 ] ...(size = 59136 end with 0.045013427734375, sum = inf)
/text_model/encoder/layers.9/layer_norm1/ReduceMean_1_output_0
[1.9988e+02 1.0608e-01 8.9844e-02 9.5886e-02 1.0156e-01 1.0504e-01
 1.0675e-01 1.0773e-01 1.0797e-01 1.0779e-01] ...(size = 77 end with 0.136962890625, sum = 209.0)
/text_model/encoder/layers.9/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.9/layer_norm1/Add_output_0
[1.9988e+02 1.0608e-01 8.9844e-02 9.5947e-02 1.0156e-01 1.0510e-01
 1.0675e-01 1.0773e-01 1.0797e-01 1.0779e-01] ...(size = 77 end with 0.136962890625, sum = 209.0)
/text_model/encoder/layers.9/layer_norm1/Sqrt_output_0
[14.14    0.3257  0.2998  0.3098  0.3186  0.3242  0.3267  0.3281  0.3286
  0.3284] ...(size = 77 end with 0.3701171875, sum = 40.46875)
/text_model/encoder/layers.9/layer_norm1/Div_output_0
[-0.06366 -0.05222  0.1133   0.0433  -0.06204 -0.1328  -0.0674  -0.03323
  0.10675  0.0411 ] ...(size = 59136 end with -0.5732421875, sum = 0.006145477294921875)
/text_model/encoder/layers.9/layer_norm1/Mul_output_0
[-0.1037  -0.09393  0.1886   0.07245 -0.1008  -0.2316  -0.1101  -0.053
  0.1903   0.0705 ] ...(size = 59136 end with -0.94384765625, sum = -60.34375)
/text_model/encoder/layers.9/layer_norm1/Add_1_output_0
[ 0.03105  -0.04443  -0.01062   0.0473    0.0829   -0.08545   0.03075
  0.015526  0.0309    0.00831 ] ...(size = 59136 end with -0.9580078125, sum = 277.5)
/text_model/encoder/layers.9/self_attn/q_proj/MatMul_output_0
[ 0.118   -0.3567  -0.11383 -0.1006   0.2003  -0.01717  0.22     0.1328
 -0.233    0.07764] ...(size = 59136 end with -0.43359375, sum = -529.0)
/text_model/encoder/layers.9/self_attn/q_proj/Add_output_0
[-0.2808  -0.10754  0.0754  -0.114    0.2957   0.04504  0.2695  -0.03714
 -0.1885  -0.2139 ] ...(size = 59136 end with 0.08056640625, sum = -1628.0)
/text_model/encoder/layers.9/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.9/self_attn/Mul_output_0
[-0.0351   -0.01344   0.00942  -0.01425   0.03696   0.00563   0.0337
 -0.004642 -0.02356  -0.02673 ] ...(size = 59136 end with 0.01007080078125, sum = -203.5)
/text_model/encoder/layers.9/self_attn/k_proj/MatMul_output_0
[-0.359     0.2365    0.3743   -0.004704  0.07214   0.1025    0.09515
 -0.2142   -0.04007  -0.2285  ] ...(size = 59136 end with 1.3525390625, sum = 1194.0)
/text_model/encoder/layers.9/self_attn/k_proj/Add_output_0
[-0.3162   0.2161   0.365   -0.01283  0.09595  0.0909   0.1081  -0.2012
 -0.06305 -0.2261 ] ...(size = 59136 end with 1.197265625, sum = 1270.0)
/text_model/encoder/layers.9/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.9/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.9/self_attn/Reshape_output_0
[-0.3162   0.2161   0.365   -0.01283  0.09595  0.0909   0.1081  -0.2012
 -0.06305 -0.2261 ] ...(size = 59136 end with 1.197265625, sum = 1270.0)
/text_model/encoder/layers.9/self_attn/Transpose_output_0
[-0.3162   0.2161   0.365   -0.01283  0.09595  0.0909   0.1081  -0.2012
 -0.06305 -0.2261 ] ...(size = 59136 end with 1.197265625, sum = 1270.0)
/text_model/encoder/layers.9/self_attn/v_proj/MatMul_output_0
[ 0.0431    0.06198  -0.007423 -0.02614  -0.03047   0.01324  -0.04364
 -0.02132  -0.09674  -0.275   ] ...(size = 59136 end with -0.061492919921875, sum = 855.5)
/text_model/encoder/layers.9/self_attn/v_proj/Add_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with -0.0684814453125, sum = 971.0)
/text_model/encoder/layers.9/self_attn/Reshape_1_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with -0.0684814453125, sum = 971.0)
/text_model/encoder/layers.9/self_attn/Transpose_1_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with -0.0684814453125, sum = 971.0)
/text_model/encoder/layers.9/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.9/self_attn/Reshape_2_output_0
[-0.0351   -0.01344   0.00942  -0.01425   0.03696   0.00563   0.0337
 -0.004642 -0.02356  -0.02673 ] ...(size = 59136 end with 0.01007080078125, sum = -203.5)
/text_model/encoder/layers.9/self_attn/Transpose_2_output_0
[-0.0351   -0.01344   0.00942  -0.01425   0.03696   0.00563   0.0337
 -0.004642 -0.02356  -0.02673 ] ...(size = 59136 end with 0.01007080078125, sum = -203.625)
/text_model/encoder/layers.9/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.9/self_attn/Reshape_3_output_0
[-0.0351   -0.01344   0.00942  -0.01425   0.03696   0.00563   0.0337
 -0.004642 -0.02356  -0.02673 ] ...(size = 59136 end with 0.01007080078125, sum = -203.625)
/text_model/encoder/layers.9/self_attn/Reshape_4_output_0
[-0.3162   0.2161   0.365   -0.01283  0.09595  0.0909   0.1081  -0.2012
 -0.06305 -0.2261 ] ...(size = 59136 end with 1.197265625, sum = 1270.0)
/text_model/encoder/layers.9/self_attn/Reshape_5_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with -0.0684814453125, sum = 971.0)
/text_model/encoder/layers.9/self_attn/Transpose_3_output_0
[-0.3162   0.4944   0.03177 -0.2213  -0.1554  -0.067    0.02907  0.05923
  0.03075 -0.01788] ...(size = 59136 end with 1.197265625, sum = 1270.0)
/text_model/encoder/layers.9/self_attn/MatMul_output_0
[ 0.344  -0.434  -0.3582 -0.3457 -0.3254 -0.326  -0.3447 -0.359  -0.3848
 -0.3884] ...(size = 71148 end with -2.234375, sum = -inf)
/text_model/encoder/layers.9/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.9/self_attn/Reshape_6_output_0
[ 0.344  -0.434  -0.3582 -0.3457 -0.3254 -0.326  -0.3447 -0.359  -0.3848
 -0.3884] ...(size = 71148 end with -2.234375, sum = -inf)
/text_model/encoder/layers.9/self_attn/Add_output_0
[ 3.44e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.234375, sum = -inf)
/text_model/encoder/layers.9/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.9/self_attn/Reshape_7_output_0
[ 3.44e-01 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04 -6.55e+04
 -6.55e+04 -6.55e+04 -6.55e+04] ...(size = 71148 end with -2.234375, sum = -inf)
/text_model/encoder/layers.9/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.01092529296875, sum = 924.0)
/text_model/encoder/layers.9/self_attn/MatMul_1_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with 0.0228271484375, sum = -252.875)
/text_model/encoder/layers.9/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.9/self_attn/Reshape_8_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with 0.0228271484375, sum = -252.875)
/text_model/encoder/layers.9/self_attn/Transpose_4_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with 0.0228271484375, sum = -253.125)
/text_model/encoder/layers.9/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.9/self_attn/Reshape_9_output_0
[ 0.00817   0.02098   0.02368  -0.004223 -0.00993   0.010475 -0.03995
 -0.0511   -0.0337   -0.2222  ] ...(size = 59136 end with 0.0228271484375, sum = -253.125)
/text_model/encoder/layers.9/self_attn/out_proj/MatMul_output_0
[-0.00902  -0.00873  -0.002483  0.01865  -0.01698  -0.009834 -0.01706
 -0.04565   0.01004   0.005505] ...(size = 59136 end with -0.0675048828125, sum = -66.9375)
/text_model/encoder/layers.9/self_attn/out_proj/Add_output_0
[-0.0797  -0.0545   0.0885  -0.0742  -0.1225  -0.11163 -0.04288 -0.0651
  0.10913 -0.0543 ] ...(size = 59136 end with -0.04364013671875, sum = -47.09375)
/text_model/encoder/layers.9/Add_output_0
[-0.979  -0.7925  1.69    0.538  -0.9995 -1.989  -0.995  -0.535   1.618
  0.5273] ...(size = 59136 end with -0.2509765625, sum = 393.5)
/text_model/encoder/layers.9/layer_norm2/ReduceMean_output_0
[-7.7367e-05  1.1589e-02  9.4223e-03  1.0086e-02  1.0254e-02  1.0361e-02
  1.0406e-02  1.0315e-02  1.0376e-02  1.0376e-02] ...(size = 77 end with 0.0031414031982421875, sum = 0.5126953125)
/text_model/encoder/layers.9/layer_norm2/Sub_output_0
[-0.979  -0.7925  1.69    0.538  -0.9995 -1.989  -0.995  -0.5347  1.618
  0.5273] ...(size = 59136 end with -0.25390625, sum = -0.149169921875)
/text_model/encoder/layers.9/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.9/layer_norm2/Pow_output_0
[0.9585 0.628  2.857  0.2896 0.9985 3.959  0.99   0.2861 2.62   0.278 ] ...(size = 59136 end with 0.06451416015625, sum = inf)
/text_model/encoder/layers.9/layer_norm2/ReduceMean_1_output_0
[2.0038e+02 1.1353e-01 9.5642e-02 1.0046e-01 1.0541e-01 1.0852e-01
 1.1005e-01 1.1096e-01 1.1121e-01 1.1121e-01] ...(size = 77 end with 0.1595458984375, sum = 210.5)
/text_model/encoder/layers.9/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.9/layer_norm2/Add_output_0
[2.0038e+02 1.1359e-01 9.5642e-02 1.0046e-01 1.0547e-01 1.0852e-01
 1.1005e-01 1.1096e-01 1.1121e-01 1.1121e-01] ...(size = 77 end with 0.1595458984375, sum = 210.5)
/text_model/encoder/layers.9/layer_norm2/Sqrt_output_0
[14.16    0.337   0.3093  0.317   0.3247  0.3293  0.3318  0.3333  0.3335
  0.3335] ...(size = 77 end with 0.3994140625, sum = 41.75)
/text_model/encoder/layers.9/layer_norm2/Div_output_0
[-0.06915 -0.056    0.11945  0.03802 -0.0706  -0.1406  -0.0703  -0.03778
  0.1143   0.03726] ...(size = 59136 end with -0.6357421875, sum = -0.004062652587890625)
/text_model/encoder/layers.9/layer_norm2/Mul_output_0
[-0.177   -0.1305   0.2832   0.0912  -0.1381  -0.3687  -0.1692  -0.09143
  0.2908   0.0854 ] ...(size = 59136 end with -1.5537109375, sum = -385.25)
/text_model/encoder/layers.9/layer_norm2/Add_1_output_0
[-0.1471  -0.432    0.4243  -0.2551  -0.389   -0.9316   0.05728  0.1545
  0.4553  -0.3352 ] ...(size = 59136 end with -1.4833984375, sum = -1045.0)
/text_model/encoder/layers.9/mlp/fc1/MatMul_output_0
[-2.008  -0.5635 -0.642  -1.252  -0.96   -1.581  -1.901  -1.064  -2.094
 -0.8145] ...(size = 236544 end with 0.2476806640625, sum = -inf)
/text_model/encoder/layers.9/mlp/fc1/Add_output_0
[-2.248  -0.9263 -0.7285 -1.499  -1.347  -1.83   -2.123  -1.374  -2.467
 -1.069 ] ...(size = 236544 end with 0.1270751953125, sum = -inf)
/text_model/encoder/layers.9/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.9/mlp/activation_fn/Mul_output_0
[-3.826 -1.576 -1.24  -2.553 -2.293 -3.115 -3.615 -2.338 -4.2   -1.819] ...(size = 236544 end with 0.21630859375, sum = -inf)
/text_model/encoder/layers.9/mlp/activation_fn/Sigmoid_output_0
[0.02133 0.1713  0.2245  0.0723  0.0918  0.0425  0.02621 0.08795 0.01478
 0.1395 ] ...(size = 236544 end with 0.5537109375, sum = 26816.0)
/text_model/encoder/layers.9/mlp/activation_fn/Mul_1_output_0
[-0.04797 -0.1587  -0.1635  -0.1084  -0.1236  -0.07776 -0.05566 -0.12085
 -0.03647 -0.1492 ] ...(size = 236544 end with 0.07037353515625, sum = -13416.0)
/text_model/encoder/layers.9/mlp/fc2/MatMul_output_0
[ 0.1284  0.1469 -0.0923  0.1937  0.0753  0.0619  0.3093 -0.0822 -0.1826
  0.1401] ...(size = 59136 end with -0.234130859375, sum = 199.875)
/text_model/encoder/layers.9/mlp/fc2/Add_output_0
[ 0.1444   0.157   -0.10095  0.1494   0.00467  0.07306  0.2732  -0.138
 -0.0929   0.06158] ...(size = 59136 end with -0.193603515625, sum = 205.75)
/text_model/encoder/layers.9/Add_1_output_0
[-0.835  -0.6353  1.589   0.6875 -0.9946 -1.917  -0.7217 -0.673   1.525
  0.589 ] ...(size = 59136 end with -0.4443359375, sum = 599.0)
/text_model/encoder/layers.10/layer_norm1/ReduceMean_output_0
[0.0006475 0.01448   0.01254   0.01358   0.01376   0.01385   0.013885
 0.01379   0.013916  0.01398  ] ...(size = 77 end with 0.006313323974609375, sum = 0.7802734375)
/text_model/encoder/layers.10/layer_norm1/Sub_output_0
[-0.8354 -0.636   1.589   0.687  -0.995  -1.917  -0.7227 -0.6733  1.524
  0.588 ] ...(size = 59136 end with -0.45068359375, sum = 0.1314697265625)
/text_model/encoder/layers.10/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.10/layer_norm1/Pow_output_0
[0.6978 0.4048 2.523  0.4717 0.9907 3.676  0.522  0.4536 2.324  0.346 ] ...(size = 59136 end with 0.203125, sum = inf)
/text_model/encoder/layers.10/layer_norm1/ReduceMean_1_output_0
[2.0088e+02 1.2598e-01 1.0522e-01 1.1584e-01 1.2219e-01 1.2695e-01
 1.3000e-01 1.3232e-01 1.3403e-01 1.3562e-01] ...(size = 77 end with 0.160888671875, sum = 212.125)
/text_model/encoder/layers.10/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.10/layer_norm1/Add_output_0
[2.0088e+02 1.2598e-01 1.0522e-01 1.1584e-01 1.2219e-01 1.2695e-01
 1.3000e-01 1.3232e-01 1.3403e-01 1.3562e-01] ...(size = 77 end with 0.1610107421875, sum = 212.125)
/text_model/encoder/layers.10/layer_norm1/Sqrt_output_0
[14.17    0.355   0.3245  0.3403  0.3496  0.3562  0.3606  0.3638  0.3662
  0.3682] ...(size = 77 end with 0.401123046875, sum = 43.40625)
/text_model/encoder/layers.10/layer_norm1/Div_output_0
[-0.05893 -0.0449   0.11206  0.04846 -0.07025 -0.1353  -0.05096 -0.04752
  0.1076   0.0415 ] ...(size = 59136 end with -1.123046875, sum = -0.046142578125)
/text_model/encoder/layers.10/layer_norm1/Mul_output_0
[-0.10974 -0.08093  0.1985   0.0863  -0.1082  -0.2382  -0.0899  -0.0791
  0.1837   0.07336] ...(size = 59136 end with -1.9599609375, sum = -748.0)
/text_model/encoder/layers.10/layer_norm1/Add_1_output_0
[ 0.04733  0.0243  -0.02007  0.04996  0.0738  -0.0657   0.04303 -0.00832
 -0.00889 -0.01878] ...(size = 59136 end with -1.9609375, sum = -358.25)
/text_model/encoder/layers.10/self_attn/q_proj/MatMul_output_0
[ 0.3672   0.1519  -0.268   -0.10345  0.138   -0.4363   0.263    0.245
  0.1598   0.266  ] ...(size = 59136 end with -0.1529541015625, sum = 1394.0)
/text_model/encoder/layers.10/self_attn/q_proj/Add_output_0
[ 0.2532   0.345   -0.1476   0.1362   0.08    -0.06836 -0.1266   0.2874
  0.144    0.1995 ] ...(size = 59136 end with -0.1336669921875, sum = 2154.0)
/text_model/encoder/layers.10/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.10/self_attn/Mul_output_0
[ 0.03165   0.04312  -0.01845   0.01703   0.01     -0.008545 -0.01582
  0.03592   0.018     0.02493 ] ...(size = 59136 end with -0.0167083740234375, sum = 269.25)
/text_model/encoder/layers.10/self_attn/k_proj/MatMul_output_0
[-0.1257  0.3645  0.1361  0.4285 -0.067   0.441  -0.6353 -0.0365 -0.089
 -0.213 ] ...(size = 59136 end with -0.049072265625, sum = 2384.0)
/text_model/encoder/layers.10/self_attn/k_proj/Add_output_0
[-0.1249   0.3665   0.1298   0.431   -0.06476  0.4404  -0.6284  -0.02753
 -0.0786  -0.2146 ] ...(size = 59136 end with 0.005084991455078125, sum = 2432.0)
/text_model/encoder/layers.10/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.10/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.10/self_attn/Reshape_output_0
[-0.1249   0.3665   0.1298   0.431   -0.06476  0.4404  -0.6284  -0.02753
 -0.0786  -0.2146 ] ...(size = 59136 end with 0.005084991455078125, sum = 2432.0)
/text_model/encoder/layers.10/self_attn/Transpose_output_0
[-0.1249   0.3665   0.1298   0.431   -0.06476  0.4404  -0.6284  -0.02753
 -0.0786  -0.2146 ] ...(size = 59136 end with 0.005084991455078125, sum = 2434.0)
/text_model/encoder/layers.10/self_attn/v_proj/MatMul_output_0
[ 0.0328   0.0408  -0.03162  0.0947   0.03247  0.03613 -0.0327   0.05133
 -0.038    0.0702 ] ...(size = 59136 end with 0.370361328125, sum = 354.75)
/text_model/encoder/layers.10/self_attn/v_proj/Add_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.4033203125, sum = 201.0)
/text_model/encoder/layers.10/self_attn/Reshape_1_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.4033203125, sum = 201.0)
/text_model/encoder/layers.10/self_attn/Transpose_1_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.4033203125, sum = 201.125)
/text_model/encoder/layers.10/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.10/self_attn/Reshape_2_output_0
[ 0.03165   0.04312  -0.01845   0.01703   0.01     -0.008545 -0.01582
  0.03592   0.018     0.02493 ] ...(size = 59136 end with -0.0167083740234375, sum = 269.25)
/text_model/encoder/layers.10/self_attn/Transpose_2_output_0
[ 0.03165   0.04312  -0.01845   0.01703   0.01     -0.008545 -0.01582
  0.03592   0.018     0.02493 ] ...(size = 59136 end with -0.0167083740234375, sum = 269.25)
/text_model/encoder/layers.10/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.10/self_attn/Reshape_3_output_0
[ 0.03165   0.04312  -0.01845   0.01703   0.01     -0.008545 -0.01582
  0.03592   0.018     0.02493 ] ...(size = 59136 end with -0.0167083740234375, sum = 269.25)
/text_model/encoder/layers.10/self_attn/Reshape_4_output_0
[-0.1249   0.3665   0.1298   0.431   -0.06476  0.4404  -0.6284  -0.02753
 -0.0786  -0.2146 ] ...(size = 59136 end with 0.005084991455078125, sum = 2434.0)
/text_model/encoder/layers.10/self_attn/Reshape_5_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.4033203125, sum = 201.125)
/text_model/encoder/layers.10/self_attn/Transpose_3_output_0
[-0.1249  -1.235   -0.799   -0.522   -0.4348  -0.3174  -0.1718  -0.1034
 -0.05618 -0.0647 ] ...(size = 59136 end with 0.005084991455078125, sum = 2432.0)
/text_model/encoder/layers.10/self_attn/MatMul_output_0
[ 0.11456  0.07434 -0.03586 -0.0123  -0.0166  -0.02924 -0.03574 -0.05246
 -0.06137 -0.07855] ...(size = 71148 end with -1.7255859375, sum = -inf)
/text_model/encoder/layers.10/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.10/self_attn/Reshape_6_output_0
[ 0.11456  0.07434 -0.03586 -0.0123  -0.0166  -0.02924 -0.03574 -0.05246
 -0.06137 -0.07855] ...(size = 71148 end with -1.7255859375, sum = -inf)
/text_model/encoder/layers.10/self_attn/Add_output_0
[ 1.1456e-01 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04
 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04] ...(size = 71148 end with -1.7255859375, sum = -inf)
/text_model/encoder/layers.10/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.10/self_attn/Reshape_7_output_0
[ 1.1456e-01 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04
 -6.5504e+04 -6.5504e+04 -6.5504e+04 -6.5504e+04] ...(size = 71148 end with -1.7255859375, sum = -inf)
/text_model/encoder/layers.10/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.002651214599609375, sum = 924.0)
/text_model/encoder/layers.10/self_attn/MatMul_1_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.01210784912109375, sum = 235.75)
/text_model/encoder/layers.10/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.10/self_attn/Reshape_8_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.01210784912109375, sum = 235.75)
/text_model/encoder/layers.10/self_attn/Transpose_4_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.01210784912109375, sum = 235.625)
/text_model/encoder/layers.10/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.10/self_attn/Reshape_9_output_0
[ 0.06247   0.06223  -0.05743   0.1143    0.0453   -0.01098  -0.00963
  0.014854 -0.05307   0.1875  ] ...(size = 59136 end with 0.01210784912109375, sum = 235.625)
/text_model/encoder/layers.10/self_attn/out_proj/MatMul_output_0
[-0.02332 -0.0453   0.00866  0.05304 -0.03247 -0.04007  0.047    0.02545
 -0.0654  -0.0294 ] ...(size = 59136 end with -0.1280517578125, sum = -184.75)
/text_model/encoder/layers.10/self_attn/out_proj/Add_output_0
[-0.1306    0.05914   0.0821   -0.014885 -0.1254   -0.1267   -0.07404
 -0.02814   0.11084  -0.0357  ] ...(size = 59136 end with -0.0460205078125, sum = -131.125)
/text_model/encoder/layers.10/Add_output_0
[-0.9653 -0.576   1.671   0.6724 -1.12   -2.043  -0.796  -0.701   1.636
  0.553 ] ...(size = 59136 end with -0.490478515625, sum = 468.0)
/text_model/encoder/layers.10/layer_norm2/ReduceMean_output_0
[0.000843 0.01453  0.012276 0.01328  0.01342  0.01344  0.01341  0.01327
 0.013336 0.01335 ] ...(size = 77 end with 0.0026798248291015625, sum = 0.60986328125)
/text_model/encoder/layers.10/layer_norm2/Sub_output_0
[-0.9663 -0.577   1.671   0.672  -1.121  -2.045  -0.797  -0.7017  1.636
  0.5522] ...(size = 59136 end with -0.4931640625, sum = -0.0882568359375)
/text_model/encoder/layers.10/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.10/layer_norm2/Pow_output_0
[0.9336 0.3333 2.791  0.4512 1.257  4.18   0.635  0.4927 2.674  0.305 ] ...(size = 59136 end with 0.2431640625, sum = inf)
/text_model/encoder/layers.10/layer_norm2/ReduceMean_1_output_0
[2.016e+02 1.449e-01 1.241e-01 1.327e-01 1.376e-01 1.416e-01 1.443e-01
 1.464e-01 1.477e-01 1.490e-01] ...(size = 77 end with 0.206787109375, sum = 214.75)
/text_model/encoder/layers.10/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.10/layer_norm2/Add_output_0
[2.016e+02 1.449e-01 1.241e-01 1.327e-01 1.376e-01 1.416e-01 1.443e-01
 1.464e-01 1.477e-01 1.490e-01] ...(size = 77 end with 0.206787109375, sum = 214.75)
/text_model/encoder/layers.10/layer_norm2/Sqrt_output_0
[14.195   0.3806  0.3523  0.3643  0.3708  0.3762  0.38    0.3826  0.3843
  0.3862] ...(size = 77 end with 0.454833984375, sum = 45.65625)
/text_model/encoder/layers.10/layer_norm2/Div_output_0
[-0.06805 -0.04065  0.1177   0.0473  -0.079   -0.144   -0.05612 -0.04944
  0.1152   0.0389 ] ...(size = 59136 end with -1.083984375, sum = -0.078857421875)
/text_model/encoder/layers.10/layer_norm2/Mul_output_0
[-0.1554  -0.0919   0.2676   0.10767 -0.1791  -0.3586  -0.1394  -0.1172
  0.291    0.087  ] ...(size = 59136 end with -2.58984375, sum = -369.75)
/text_model/encoder/layers.10/layer_norm2/Add_1_output_0
[-0.0688  -0.385    0.465   -0.01399 -0.568   -0.577   -0.264    0.0311
  0.3555   0.00916] ...(size = 59136 end with -2.46875, sum = -1771.0)
/text_model/encoder/layers.10/mlp/fc1/MatMul_output_0
[-1.392   0.47   -0.89   -1.885  -1.465  -2.566  -0.6104 -0.95   -0.182
 -0.9233] ...(size = 236544 end with -1.2197265625, sum = -inf)
/text_model/encoder/layers.10/mlp/fc1/Add_output_0
[-1.719   0.2319 -1.283  -2.275  -1.697  -2.879  -0.712  -1.1875 -0.4412
 -1.168 ] ...(size = 236544 end with -1.513671875, sum = -inf)
/text_model/encoder/layers.10/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.10/mlp/activation_fn/Mul_output_0
[-2.926   0.3948 -2.184  -3.873  -2.889  -4.902  -1.212  -2.021  -0.751
 -1.989 ] ...(size = 236544 end with -2.576171875, sum = -inf)
/text_model/encoder/layers.10/mlp/activation_fn/Sigmoid_output_0
[0.0509   0.5977   0.1012   0.02036  0.0527   0.007385 0.2294   0.11694
 0.3206   0.12036 ] ...(size = 236544 end with 0.0706787109375, sum = 29984.0)
/text_model/encoder/layers.10/mlp/activation_fn/Mul_1_output_0
[-0.08746  0.1385  -0.1299  -0.04633 -0.0894  -0.02127 -0.1633  -0.1389
 -0.1415  -0.1406 ] ...(size = 236544 end with -0.10699462890625, sum = -12384.0)
/text_model/encoder/layers.10/mlp/fc2/MatMul_output_0
[ 0.1935   -0.3176   -0.172     0.1416    0.2988   -0.0419   -0.1077
 -0.006504 -0.3706   -0.0951  ] ...(size = 59136 end with -0.5556640625, sum = 447.0)
/text_model/encoder/layers.10/mlp/fc2/Add_output_0
[ 0.157   -0.1549  -0.2323   0.1318   0.2546   0.0759  -0.01351 -0.1399
 -0.3345  -0.06604] ...(size = 59136 end with -0.494140625, sum = 397.75)
/text_model/encoder/layers.10/Add_1_output_0
[-0.8086 -0.7314  1.438   0.804  -0.865  -1.968  -0.8096 -0.841   1.302
  0.487 ] ...(size = 59136 end with -0.984375, sum = 866.0)
/text_model/encoder/layers.11/layer_norm1/ReduceMean_output_0
[-0.0005155  0.02043    0.01767    0.02187    0.02315    0.02354
  0.02332    0.02304    0.02289    0.0227   ] ...(size = 77 end with 0.00580596923828125, sum = 1.1279296875)
/text_model/encoder/layers.11/layer_norm1/Sub_output_0
[-0.8076 -0.731   1.439   0.8047 -0.8647 -1.967  -0.809  -0.8403  1.302
  0.4875] ...(size = 59136 end with -0.990234375, sum = -0.09954833984375)
/text_model/encoder/layers.11/layer_norm1/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.11/layer_norm1/Pow_output_0
[0.653  0.534  2.072  0.648  0.748  3.87   0.6543 0.7065 1.695  0.2377] ...(size = 59136 end with 0.98095703125, sum = inf)
/text_model/encoder/layers.11/layer_norm1/ReduceMean_1_output_0
[2.019e+02 1.566e-01 1.284e-01 1.505e-01 1.659e-01 1.754e-01 1.796e-01
 1.832e-01 1.863e-01 1.875e-01] ...(size = 77 end with 0.220947265625, sum = 216.25)
/text_model/encoder/layers.11/layer_norm1/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.11/layer_norm1/Add_output_0
[2.019e+02 1.566e-01 1.284e-01 1.505e-01 1.660e-01 1.754e-01 1.796e-01
 1.832e-01 1.863e-01 1.875e-01] ...(size = 77 end with 0.220947265625, sum = 216.25)
/text_model/encoder/layers.11/layer_norm1/Sqrt_output_0
[14.21    0.3958  0.3584  0.388   0.4075  0.419   0.4238  0.428   0.4316
  0.433 ] ...(size = 77 end with 0.469970703125, sum = 47.21875)
/text_model/encoder/layers.11/layer_norm1/Div_output_0
[-0.05685 -0.05145  0.1013   0.05664 -0.06088 -0.1384  -0.05695 -0.05914
  0.0917   0.0343 ] ...(size = 59136 end with -2.107421875, sum = 0.06866455078125)
/text_model/encoder/layers.11/layer_norm1/Mul_output_0
[-0.1072  -0.09436  0.1902   0.10657 -0.0948  -0.2607  -0.1077  -0.1071
  0.1821   0.0651 ] ...(size = 59136 end with -3.857421875, sum = -970.5)
/text_model/encoder/layers.11/layer_norm1/Add_1_output_0
[ 0.0426   -0.003567  0.0779    0.08246   0.11774  -0.03412   0.04953
  0.11115  -0.0637   -0.02324 ] ...(size = 59136 end with -3.779296875, sum = -596.5)
/text_model/encoder/layers.11/self_attn/q_proj/MatMul_output_0
[-0.5503  -0.637    0.0991   0.02211 -0.1251  -0.5005  -0.0321  -0.0887
  1.613   -0.1059 ] ...(size = 59136 end with -1.0791015625, sum = 52.71875)
/text_model/encoder/layers.11/self_attn/q_proj/Add_output_0
[-0.379   -0.3936   0.2993  -0.08704 -0.3125  -0.5107   0.02234 -0.1193
 -0.2258   0.0322 ] ...(size = 59136 end with -1.1103515625, sum = 986.5)
/text_model/encoder/layers.11/self_attn/Constant_output_0
[0.125] ...(size = 1 end with 0.125, sum = 0.125)
/text_model/encoder/layers.11/self_attn/Mul_output_0
[-0.04736  -0.0492    0.0374   -0.01088  -0.03906  -0.06384   0.002792
 -0.014915 -0.02823   0.004025] ...(size = 59136 end with -0.1387939453125, sum = 123.3125)
/text_model/encoder/layers.11/self_attn/k_proj/MatMul_output_0
[ 0.387    0.2084   0.2263  -0.1725  -0.523   -0.3076  -0.1853  -0.02875
 -0.9634   0.2976 ] ...(size = 59136 end with 0.56103515625, sum = -817.0)
/text_model/encoder/layers.11/self_attn/k_proj/Add_output_0
[ 0.3877   0.2058   0.231   -0.1692  -0.525   -0.3057  -0.1847  -0.02917
 -0.982    0.297  ] ...(size = 59136 end with 0.5615234375, sum = -810.0)
/text_model/encoder/layers.11/self_attn/Constant_1_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.11/self_attn/Constant_2_output_0
[ 1 -1 12 64] ...(size = 4 end with 64, sum = 76)
/text_model/encoder/layers.11/self_attn/Reshape_output_0
[ 0.3877   0.2058   0.231   -0.1692  -0.525   -0.3057  -0.1847  -0.02917
 -0.982    0.297  ] ...(size = 59136 end with 0.5615234375, sum = -810.0)
/text_model/encoder/layers.11/self_attn/Transpose_output_0
[ 0.3877   0.2058   0.231   -0.1692  -0.525   -0.3057  -0.1847  -0.02917
 -0.982    0.297  ] ...(size = 59136 end with 0.5615234375, sum = -811.0)
/text_model/encoder/layers.11/self_attn/v_proj/MatMul_output_0
[ 0.028    -0.008224 -0.2301   -0.0327   -0.08734  -0.3696   -0.1821
  0.3337   -0.1709   -0.132   ] ...(size = 59136 end with -1.1025390625, sum = -1188.0)
/text_model/encoder/layers.11/self_attn/v_proj/Add_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -1.17578125, sum = -1143.0)
/text_model/encoder/layers.11/self_attn/Reshape_1_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -1.17578125, sum = -1143.0)
/text_model/encoder/layers.11/self_attn/Transpose_1_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -1.17578125, sum = -1144.0)
/text_model/encoder/layers.11/self_attn/Constant_3_output_0
[ 1 77 12 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.11/self_attn/Reshape_2_output_0
[-0.04736  -0.0492    0.0374   -0.01088  -0.03906  -0.06384   0.002792
 -0.014915 -0.02823   0.004025] ...(size = 59136 end with -0.1387939453125, sum = 123.3125)
/text_model/encoder/layers.11/self_attn/Transpose_2_output_0
[-0.04736  -0.0492    0.0374   -0.01088  -0.03906  -0.06384   0.002792
 -0.014915 -0.02823   0.004025] ...(size = 59136 end with -0.1387939453125, sum = 123.375)
/text_model/encoder/layers.11/self_attn/Constant_4_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Constant_5_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Constant_6_output_0
[12 -1 64] ...(size = 3 end with 64, sum = 75)
/text_model/encoder/layers.11/self_attn/Reshape_3_output_0
[-0.04736  -0.0492    0.0374   -0.01088  -0.03906  -0.06384   0.002792
 -0.014915 -0.02823   0.004025] ...(size = 59136 end with -0.1387939453125, sum = 123.375)
/text_model/encoder/layers.11/self_attn/Reshape_4_output_0
[ 0.3877   0.2058   0.231   -0.1692  -0.525   -0.3057  -0.1847  -0.02917
 -0.982    0.297  ] ...(size = 59136 end with 0.5615234375, sum = -811.0)
/text_model/encoder/layers.11/self_attn/Reshape_5_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -1.17578125, sum = -1144.0)
/text_model/encoder/layers.11/self_attn/Transpose_3_output_0
[ 0.3877 -0.825  -1.486  -1.31   -1.114  -1.013  -0.96   -1.039  -1.109
 -1.179 ] ...(size = 59136 end with 0.5615234375, sum = -811.5)
/text_model/encoder/layers.11/self_attn/MatMul_output_0
[ 0.1444 -0.28   -0.4553 -0.326  -0.2488 -0.2036 -0.1582 -0.1475 -0.127
 -0.127 ] ...(size = 71148 end with -1.958984375, sum = -inf)
/text_model/encoder/layers.11/self_attn/Constant_7_output_0
[ 1 12 77 77] ...(size = 4 end with 77, sum = 167)
/text_model/encoder/layers.11/self_attn/Reshape_6_output_0
[ 0.1444 -0.28   -0.4553 -0.326  -0.2488 -0.2036 -0.1582 -0.1475 -0.127
 -0.127 ] ...(size = 71148 end with -1.958984375, sum = -inf)
/text_model/encoder/layers.11/self_attn/Add_output_0
[ 1.444e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -1.958984375, sum = -inf)
/text_model/encoder/layers.11/self_attn/Constant_8_output_0
[12 77 77] ...(size = 3 end with 77, sum = 166)
/text_model/encoder/layers.11/self_attn/Reshape_7_output_0
[ 1.444e-01 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04
 -6.550e+04 -6.550e+04 -6.550e+04 -6.550e+04] ...(size = 71148 end with -1.958984375, sum = -inf)
/text_model/encoder/layers.11/self_attn/Softmax_output_0
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...(size = 71148 end with 0.0107574462890625, sum = 924.0)
/text_model/encoder/layers.11/self_attn/MatMul_1_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -0.1241455078125, sum = -599.0)
/text_model/encoder/layers.11/self_attn/Constant_9_output_0
[ 1 12 77 64] ...(size = 4 end with 64, sum = 154)
/text_model/encoder/layers.11/self_attn/Reshape_8_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -0.1241455078125, sum = -599.0)
/text_model/encoder/layers.11/self_attn/Transpose_4_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -0.1241455078125, sum = -598.5)
/text_model/encoder/layers.11/self_attn/Constant_10_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/encoder/layers.11/self_attn/Reshape_9_output_0
[ 0.0777   0.03748 -0.1833  -0.01573 -0.08295 -0.2563  -0.1493   0.2883
 -0.09564 -0.1627 ] ...(size = 59136 end with -0.1241455078125, sum = -598.5)
/text_model/encoder/layers.11/self_attn/out_proj/MatMul_output_0
[ 0.118   -0.06995  0.0457   0.08136  0.03778 -0.1152  -0.01344  0.1244
 -0.0362   0.0989 ] ...(size = 59136 end with -0.2354736328125, sum = 39.625)
/text_model/encoder/layers.11/self_attn/out_proj/Add_output_0
[-0.2114    0.3157   -0.1132    0.001661 -0.0889   -0.277     0.09247
 -0.1718    0.194     0.1354  ] ...(size = 59136 end with 0.0230560302734375, sum = 80.5625)
/text_model/encoder/layers.11/Add_output_0
[-1.02   -0.4155  1.326   0.806  -0.9546 -2.244  -0.717  -1.013   1.496
  0.6226] ...(size = 59136 end with -0.96142578125, sum = 947.0)
/text_model/encoder/layers.11/layer_norm2/ReduceMean_output_0
[0.000829 0.02184  0.01884  0.0231   0.02446  0.0249   0.02469  0.02438
 0.02423  0.024   ] ...(size = 77 end with 0.007724761962890625, sum = 1.232421875)
/text_model/encoder/layers.11/layer_norm2/Sub_output_0
[-1.0205 -0.4163  1.325   0.805  -0.955  -2.246  -0.718  -1.014   1.495
  0.6216] ...(size = 59136 end with -0.96923828125, sum = 0.0278778076171875)
/text_model/encoder/layers.11/layer_norm2/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/encoder/layers.11/layer_norm2/Pow_output_0
[1.042  0.1733 1.755  0.6484 0.9126 5.043  0.515  1.027  2.234  0.3862] ...(size = 59136 end with 0.939453125, sum = inf)
/text_model/encoder/layers.11/layer_norm2/ReduceMean_1_output_0
[2.025e+02 2.170e-01 1.971e-01 2.644e-01 2.954e-01 3.069e-01 3.083e-01
 3.101e-01 3.147e-01 3.162e-01] ...(size = 77 end with 0.359130859375, sum = 228.875)
/text_model/encoder/layers.11/layer_norm2/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/encoder/layers.11/layer_norm2/Add_output_0
[2.025e+02 2.170e-01 1.973e-01 2.644e-01 2.954e-01 3.069e-01 3.083e-01
 3.101e-01 3.147e-01 3.162e-01] ...(size = 77 end with 0.359130859375, sum = 228.875)
/text_model/encoder/layers.11/layer_norm2/Sqrt_output_0
[14.23    0.4658  0.444   0.514   0.5435  0.554   0.555   0.5566  0.561
  0.5625] ...(size = 77 end with 0.59912109375, sum = 58.90625)
/text_model/encoder/layers.11/layer_norm2/Div_output_0
[-0.0717  -0.02927  0.09314  0.05658 -0.06714 -0.1578  -0.05045 -0.0712
  0.10504  0.04367] ...(size = 59136 end with -1.6171875, sum = 0.051971435546875)
/text_model/encoder/layers.11/layer_norm2/Mul_output_0
[-0.1251  -0.05243  0.1663   0.09656 -0.1494  -0.2793  -0.083   -0.12134
  0.1885   0.0749 ] ...(size = 59136 end with -2.814453125, sum = 623.0)
/text_model/encoder/layers.11/layer_norm2/Add_1_output_0
[-0.1407  -0.1442   0.0258   0.1256  -0.444   -0.0468   0.0635   0.01688
  0.04846 -0.03763] ...(size = 59136 end with -2.638671875, sum = 520.5)
/text_model/encoder/layers.11/mlp/fc1/MatMul_output_0
[ 0.1755 -0.409  -1.678  -2.457  -0.319  -1.529  -1.136  -2.219  -1.026
 -1.598 ] ...(size = 236544 end with -0.6181640625, sum = -inf)
/text_model/encoder/layers.11/mlp/fc1/Add_output_0
[ 0.04843 -0.558   -1.906   -2.838   -0.4255  -1.773   -1.312   -2.426
 -1.292   -1.6875 ] ...(size = 236544 end with -0.66064453125, sum = -inf)
/text_model/encoder/layers.11/mlp/activation_fn/Constant_output_0
[1.702] ...(size = 1 end with 1.7021484375, sum = 1.7021484375)
/text_model/encoder/layers.11/mlp/activation_fn/Mul_output_0
[ 0.0824 -0.95   -3.244  -4.832  -0.7246 -3.018  -2.232  -4.13   -2.2
 -2.873 ] ...(size = 236544 end with -1.125, sum = -inf)
/text_model/encoder/layers.11/mlp/activation_fn/Sigmoid_output_0
[0.5205  0.2788  0.0375  0.00792 0.3264  0.0466  0.0969  0.01584 0.0998
 0.05353] ...(size = 236544 end with 0.2451171875, sum = 47360.0)
/text_model/encoder/layers.11/mlp/activation_fn/Mul_1_output_0
[ 0.0252  -0.1556  -0.07153 -0.02246 -0.1389  -0.08264 -0.1271  -0.03842
 -0.1289  -0.09033] ...(size = 236544 end with -0.1619873046875, sum = -17120.0)
/text_model/encoder/layers.11/mlp/fc2/MatMul_output_0
[ 0.3977   -0.494     0.3098    0.000953  0.2448    0.05106  -0.2603
  0.08435  -0.07263  -0.03406 ] ...(size = 59136 end with -0.2447509765625, sum = -560.0)
/text_model/encoder/layers.11/mlp/fc2/Add_output_0
[ 0.6533 -0.756   0.545   0.1401  0.2434  0.096  -0.144   0.0963 -0.297
  0.0853] ...(size = 59136 end with -0.304931640625, sum = -639.5)
/text_model/encoder/layers.11/Add_1_output_0
[-0.3662 -1.172   1.87    0.9463 -0.711  -2.148  -0.861  -0.9165  1.198
  0.7075] ...(size = 59136 end with -1.2666015625, sum = 306.75)
/text_model/final_layer_norm/ReduceMean_output_0
[-0.006012  0.01502   0.01047   0.014275  0.01584   0.0162    0.01578
  0.01513   0.014565  0.01404 ] ...(size = 77 end with -0.0036144256591796875, sum = 0.400146484375)
/text_model/final_layer_norm/Sub_output_0
[-0.3604 -1.165   1.877   0.952  -0.705  -2.143  -0.855  -0.91    1.204
  0.714 ] ...(size = 59136 end with -1.2626953125, sum = -0.139892578125)
/text_model/final_layer_norm/Constant_output_0
[2.] ...(size = 1 end with 2.0, sum = 2.0)
/text_model/final_layer_norm/Pow_output_0
[0.1298 1.358  3.521  0.9067 0.497  4.59   0.731  0.8286 1.451  0.5093] ...(size = 59136 end with 1.5947265625, sum = inf)
/text_model/final_layer_norm/ReduceMean_1_output_0
[200.9      0.238    0.2568   0.3406   0.3682   0.3757   0.3757   0.3782
   0.3833   0.384 ] ...(size = 77 end with 0.4033203125, sum = 230.875)
/text_model/final_layer_norm/Constant_1_output_0
[1.e-05] ...(size = 1 end with 1.0013580322265625e-05, sum = 1.0013580322265625e-05)
/text_model/final_layer_norm/Add_output_0
[200.9      0.238    0.2568   0.3406   0.3682   0.3757   0.3757   0.3782
   0.3833   0.384 ] ...(size = 77 end with 0.4033203125, sum = 230.875)
/text_model/final_layer_norm/Sqrt_output_0
[14.17    0.488   0.507   0.5835  0.607   0.6133  0.613   0.6147  0.619
  0.6196] ...(size = 77 end with 0.63525390625, sum = 61.90625)
/text_model/final_layer_norm/Div_output_0
[-0.02542 -0.0822   0.1324   0.0672  -0.04974 -0.1512  -0.06033 -0.0642
  0.085    0.05035] ...(size = 59136 end with -1.98828125, sum = -0.045623779296875)
/text_model/final_layer_norm/Mul_output_0
[-0.02489 -0.0764   0.1392   0.06604 -0.0678  -0.1484  -0.05405 -0.0636
  0.08264  0.05133] ...(size = 59136 end with -1.9443359375, sum = 555.5)
last_hidden_state
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 59136 end with -1.849609375, sum = -6000.0)
/text_model/Cast_1_output_0
[1 1 1 1 1 1 1 1 1 1] ...(size = 77 end with 1, sum = 77)
/text_model/ArgMax_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Shape_output_0
[  1  77 768] ...(size = 3 end with 768, sum = 846)
/text_model/Constant_4_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Gather_output_0
[77] ...(size = 1 end with 77, sum = 77)
/text_model/Constant_5_output_0
[2] ...(size = 1 end with 2, sum = 2)
/text_model/Gather_1_output_0
[768] ...(size = 1 end with 768, sum = 768)
/text_model/Flatten_output_0
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 59136 end with -1.849609375, sum = -6000.0)
/text_model/Constant_6_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Mul_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Add_output_0
[0] ...(size = 1 end with 0, sum = 0)
/text_model/Gather_2_output_0
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 768 end with 0.04644775390625, sum = -80.5625)
/text_model/Shape_1_output_0
[1] ...(size = 1 end with 1, sum = 1)
/text_model/Constant_7_output_0
[-1] ...(size = 1 end with -1, sum = -1)
/text_model/Concat_output_0
[ -1 768] ...(size = 2 end with 768, sum = 767)
/text_model/Reshape_1_output_0
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 768 end with 0.04644775390625, sum = -80.5625)
/text_model/Concat_1_output_0
[  1 768] ...(size = 2 end with 768, sum = 769)
pooler_output
[-0.3347   0.01014 -0.03897 -0.1467  -0.0575  -0.3665  -0.02725 -0.1877
  0.196   -0.05737] ...(size = 768 end with 0.04644775390625, sum = -80.5625)
text_model.embeddings.token_embedding.weight
[-0.0012045  0.0368     0.02213   -0.004208  -0.013     -0.007435
 -0.009056  -0.01979    0.03262   -0.01813  ] ...(size = 37945344 end with 0.005207061767578125, sum = -644.0)
text_model.embeddings.position_embedding.weight
[ 0.001584  0.002008  0.000208 -0.001874 -0.000706  0.002995  0.000633
 -0.002918  0.001847 -0.001681] ...(size = 59136 end with -0.0309600830078125, sum = -17.984375)
text_model.encoder.layers.0.self_attn.k_proj.bias
[-0.00285   -0.003304   0.005978   0.000769   0.02065    0.0007424
  0.00816   -0.01054    0.00806   -0.001903 ] ...(size = 768 end with -0.0131072998046875, sum = 0.51806640625)
text_model.encoder.layers.0.self_attn.v_proj.bias
[ 0.005116  0.003235  0.01415  -0.007545  0.01133  -0.03128   0.02686
 -0.01204  -0.01013   0.01665 ] ...(size = 768 end with -0.0143890380859375, sum = -0.5986328125)
text_model.encoder.layers.0.self_attn.q_proj.bias
[-0.2406   0.149    0.4639   0.0679   0.6553   0.2399   0.05664 -0.1252
 -0.02408  0.02257] ...(size = 768 end with -0.0065765380859375, sum = 20.03125)
text_model.encoder.layers.0.self_attn.out_proj.bias
[-0.06805  -0.033     0.0418   -0.1022   -0.005493  0.004288 -0.003868
 -0.04837  -0.02275  -0.002125] ...(size = 768 end with 0.0101318359375, sum = 0.50244140625)
text_model.encoder.layers.0.layer_norm1.weight
[1.84  1.65  1.795 1.78  1.766 1.768 1.86  1.823 1.752 1.736] ...(size = 768 end with 1.7626953125, sum = 1333.0)
text_model.encoder.layers.0.layer_norm1.bias
[-0.06396 -0.1891  -0.0663   0.11584 -0.0194  -0.0768  -0.09247  0.1501
 -0.154    0.05362] ...(size = 768 end with -0.08819580078125, sum = 15.8984375)
text_model.encoder.layers.0.mlp.fc1.bias
[-0.38    -0.4065  -0.2979  -0.417    0.04556 -0.0985  -0.3064  -0.2754
 -0.2705  -0.2405 ] ...(size = 3072 end with -0.1925048828125, sum = -973.5)
text_model.encoder.layers.0.mlp.fc2.bias
[ 0.00779  -0.0326    0.002337 -0.002743 -0.01785  -0.03696   0.04355
 -0.008736  0.005966 -0.006954] ...(size = 768 end with -0.0139617919921875, sum = 0.83935546875)
text_model.encoder.layers.0.layer_norm2.weight
[1.547 1.629 1.462 1.516 1.696 1.535 1.703 1.649 1.676 1.545] ...(size = 768 end with 1.6201171875, sum = 1265.0)
text_model.encoder.layers.0.layer_norm2.bias
[-0.2883  0.6787 -0.2378  0.7256  0.5034 -0.1025 -0.3928  0.7607  0.2822
  0.2751] ...(size = 768 end with -0.014129638671875, sum = 31.953125)
text_model.encoder.layers.1.self_attn.k_proj.bias
[ 0.001078  -0.004513   0.002207  -0.0009294  0.001965   0.005806
 -0.002028  -0.001972   0.0009737 -0.001694 ] ...(size = 768 end with 0.00342559814453125, sum = 0.62548828125)
text_model.encoder.layers.1.self_attn.v_proj.bias
[-0.01084  -0.01274   0.01237   0.01124   0.02676   0.03296   0.0266
 -0.002132  0.02206  -0.012634] ...(size = 768 end with 0.01453399658203125, sum = 0.224609375)
text_model.encoder.layers.1.self_attn.q_proj.bias
[ 0.343    -0.08356   0.04236  -0.0927    0.1887    0.1268   -0.1014
 -0.005375 -0.501     0.08594 ] ...(size = 768 end with 0.44775390625, sum = -1.4951171875)
text_model.encoder.layers.1.self_attn.out_proj.bias
[ 0.03056   0.01502  -0.02113   0.01636  -0.00601  -0.01196   0.038
  0.0478   -0.01289   0.011734] ...(size = 768 end with -0.003826141357421875, sum = 0.358642578125)
text_model.encoder.layers.1.layer_norm1.weight
[1.09  1.149 1.128 1.022 1.174 1.066 1.103 1.119 1.062 1.036] ...(size = 768 end with 1.173828125, sum = 857.0)
text_model.encoder.layers.1.layer_norm1.bias
[ 0.1298   0.03455 -0.184    0.01218  0.0543   0.07043  0.06915  0.0636
 -0.06396  0.02243] ...(size = 768 end with 0.0024051666259765625, sum = -0.85400390625)
text_model.encoder.layers.1.mlp.fc1.bias
[-0.2842  -0.3364   0.04828 -0.3481  -0.2357  -0.4583  -0.425   -0.366
 -0.3408  -0.356  ] ...(size = 3072 end with -0.275146484375, sum = -912.5)
text_model.encoder.layers.1.mlp.fc2.bias
[ 0.02638   0.0388   -0.0395    0.014725  0.00939   0.010445 -0.06174
  0.03384   0.05927  -0.01226 ] ...(size = 768 end with -0.0158233642578125, sum = 0.31640625)
text_model.encoder.layers.1.layer_norm2.weight
[1.866 1.778 1.813 1.903 1.82  1.836 1.932 1.903 2.008 1.737] ...(size = 768 end with 1.8408203125, sum = 1450.0)
text_model.encoder.layers.1.layer_norm2.bias
[ 0.10004  0.3264  -0.2104  -0.51    -0.0424  -0.2676   0.942   -0.2747
 -0.527   -0.05548] ...(size = 768 end with 0.0030536651611328125, sum = -16.09375)
text_model.encoder.layers.2.self_attn.k_proj.bias
[-0.004074   0.0004334  0.001524   0.0003138  0.00771    0.004726
 -0.009254   0.002254   0.002716   0.01347  ] ...(size = 768 end with 0.001834869384765625, sum = 0.05169677734375)
text_model.encoder.layers.2.self_attn.v_proj.bias
[-0.03018  -0.013565  0.01446  -0.02733  -0.01538   0.04877  -0.00824
 -0.01189  -0.02164  -0.008995] ...(size = 768 end with 0.03057861328125, sum = 0.1776123046875)
text_model.encoder.layers.2.self_attn.q_proj.bias
[-0.4333   0.1654  -0.05194  0.2106   0.5337   0.2764   0.03403  0.487
  0.0877   1.455  ] ...(size = 768 end with 0.1474609375, sum = 0.31982421875)
text_model.encoder.layers.2.self_attn.out_proj.bias
[ 0.04648   0.04126  -0.0576    0.004215 -0.01538  -0.007195  0.07196
  0.003372  0.01203  -0.001722] ...(size = 768 end with 0.00794219970703125, sum = 0.1630859375)
text_model.encoder.layers.2.layer_norm1.weight
[1.277 1.413 1.324 1.212 1.429 1.229 1.271 1.209 1.228 1.203] ...(size = 768 end with 1.37109375, sum = 1018.5)
text_model.encoder.layers.2.layer_norm1.bias
[ 0.1125     0.0665    -0.1525    -0.0005875  0.0455     0.0934
  0.08936    0.05966   -0.09595    0.03656  ] ...(size = 768 end with -0.002166748046875, sum = -0.9755859375)
text_model.encoder.layers.2.mlp.fc1.bias
[-0.1687  -0.1522  -0.1874  -0.3452  -0.2966  -0.4329  -0.2751  -0.1289
 -0.3467   0.09045] ...(size = 3072 end with -0.34521484375, sum = -891.5)
text_model.encoder.layers.2.mlp.fc2.bias
[-0.01445  -0.01944  -0.05246  -0.03102  -0.0513    0.03604  -0.004982
  0.03088  -0.0608   -0.003902] ...(size = 768 end with -0.041748046875, sum = 0.2939453125)
text_model.encoder.layers.2.layer_norm2.weight
[2.025 2.035 1.951 1.97  1.958 1.922 2.068 1.955 1.998 2.072] ...(size = 768 end with 2.001953125, sum = 1540.0)
text_model.encoder.layers.2.layer_norm2.bias
[ 0.215   0.747  -0.4377 -0.1919 -0.1936  0.4104  0.448  -0.1062 -0.1497
 -0.3406] ...(size = 768 end with 0.408447265625, sum = 9.6796875)
text_model.encoder.layers.3.self_attn.k_proj.bias
[ 0.04437  -0.00226  -0.00145   0.001346 -0.001952 -0.01     -0.004665
 -0.00454   0.00898   0.01318 ] ...(size = 768 end with 0.00384521484375, sum = 0.3916015625)
text_model.encoder.layers.3.self_attn.v_proj.bias
[-0.056    -0.0584    0.04797  -0.00546  -0.0166   -0.03857  -0.01528
  0.0326   -0.001681  0.004154] ...(size = 768 end with 0.0654296875, sum = -0.433349609375)
text_model.encoder.layers.3.self_attn.q_proj.bias
[ 0.1748  -0.06946 -0.2499  -0.251    0.2393  -0.2026   0.0181   0.1644
  0.4082   0.31   ] ...(size = 768 end with 0.505859375, sum = 4.875)
text_model.encoder.layers.3.self_attn.out_proj.bias
[-0.00462  -0.01071  -0.004246 -0.01166  -0.07227   0.011406  0.0658
 -0.0316    0.02274   0.0517  ] ...(size = 768 end with 0.0182342529296875, sum = 0.304443359375)
text_model.encoder.layers.3.layer_norm1.weight
[1.287 1.391 1.328 1.375 1.381 1.331 1.291 1.374 1.328 1.277] ...(size = 768 end with 1.3837890625, sum = 1029.0)
text_model.encoder.layers.3.layer_norm1.bias
[ 0.08734  0.0612  -0.11395 -0.0232   0.0662   0.10486  0.06192  0.06696
 -0.08295  0.02953] ...(size = 768 end with 0.00017511844635009766, sum = 0.09710693359375)
text_model.encoder.layers.3.mlp.fc1.bias
[-0.3335 -0.4612 -0.1525 -0.2683 -0.3743 -0.2935 -0.32   -0.455  -0.351
 -0.2847] ...(size = 3072 end with -0.310302734375, sum = -874.5)
text_model.encoder.layers.3.mlp.fc2.bias
[-0.01406  0.0564  -0.06366 -0.01566 -0.0701   0.0206   0.04938 -0.00391
 -0.0952  -0.02701] ...(size = 768 end with 0.0266571044921875, sum = 0.07843017578125)
text_model.encoder.layers.3.layer_norm2.weight
[2.031 1.973 2.068 2.092 2.09  2.16  2.193 2.094 2.184 2.062] ...(size = 768 end with 2.162109375, sum = 1594.0)
text_model.encoder.layers.3.layer_norm2.bias
[-0.1635   0.3904  -0.657    0.07776 -0.3645   0.804    0.6367  -0.08673
 -0.3818  -0.1614 ] ...(size = 768 end with 0.496337890625, sum = 23.5)
text_model.encoder.layers.4.self_attn.k_proj.bias
[-0.008316  -0.0007076 -0.001325  -0.0004635 -0.003689  -0.001901
 -0.002121   0.00513   -0.00554    0.001782 ] ...(size = 768 end with -0.022796630859375, sum = 0.2208251953125)
text_model.encoder.layers.4.self_attn.v_proj.bias
[-0.00495  -0.02118   0.02083   0.02664  -0.01692  -0.015144  0.0196
  0.01202   0.02626   0.01907 ] ...(size = 768 end with -0.01751708984375, sum = 0.509765625)
text_model.encoder.layers.4.self_attn.q_proj.bias
[ 1.137   -0.12103  0.1425   0.06033 -0.2903  -0.1243  -0.1969  -0.3384
  0.1661   0.12177] ...(size = 768 end with -2.20703125, sum = 14.5390625)
text_model.encoder.layers.4.self_attn.out_proj.bias
[-0.004513  0.001089 -0.03348  -0.01272  -0.0671    0.06714   0.0687
 -0.01541   0.0402    0.03326 ] ...(size = 768 end with 0.03924560546875, sum = 0.55810546875)
text_model.encoder.layers.4.layer_norm1.weight
[1.42  1.556 1.446 1.418 1.406 1.439 1.387 1.371 1.415 1.361] ...(size = 768 end with 1.4013671875, sum = 1102.0)
text_model.encoder.layers.4.layer_norm1.bias
[ 0.0719   0.0987  -0.12305 -0.0253   0.03433  0.1228   0.07056  0.0719
 -0.1254   0.01027] ...(size = 768 end with -0.0001195073127746582, sum = 1.654296875)
text_model.encoder.layers.4.mlp.fc1.bias
[-0.3206   0.02988 -0.2832  -0.3298  -0.334   -0.05557 -0.2524  -0.1273
 -0.3623  -0.371  ] ...(size = 3072 end with -0.320556640625, sum = -884.5)
text_model.encoder.layers.4.mlp.fc2.bias
[ 0.0462   0.05844 -0.0514   0.01813 -0.0145   0.1153   0.0729  -0.01498
  0.05185 -0.0234 ] ...(size = 768 end with 0.04058837890625, sum = 0.22509765625)
text_model.encoder.layers.4.layer_norm2.weight
[2.148 2.076 2.191 2.045 2.04  2.145 2.27  2.123 2.146 2.19 ] ...(size = 768 end with 2.279296875, sum = 1632.0)
text_model.encoder.layers.4.layer_norm2.bias
[-0.4048  0.504  -0.621   0.1904 -0.931   0.4368  0.628  -0.0079 -0.856
 -0.3027] ...(size = 768 end with 0.615234375, sum = 19.453125)
text_model.encoder.layers.5.self_attn.k_proj.bias
[-3.517e-03  2.033e-03  1.968e-03  1.490e-05  2.279e-03 -1.303e-03
 -2.371e-03  2.520e-03 -4.497e-04  4.120e-03] ...(size = 768 end with -0.002262115478515625, sum = -0.0498046875)
text_model.encoder.layers.5.self_attn.v_proj.bias
[ 0.011185 -0.03763   0.0082    0.0221    0.05646  -0.01156   0.02426
 -0.005817 -0.01001  -0.02678 ] ...(size = 768 end with -0.01401519775390625, sum = -0.148681640625)
text_model.encoder.layers.5.self_attn.q_proj.bias
[-0.321     0.2307   -0.04752  -0.07825   0.1832   -0.1461   -0.579
  0.0969    0.001486 -0.4832  ] ...(size = 768 end with -0.15966796875, sum = 16.28125)
text_model.encoder.layers.5.self_attn.out_proj.bias
[ 0.02896   0.01279   0.00939  -0.00446  -0.02933  -0.012665 -0.014824
 -0.05902  -0.02261   0.04172 ] ...(size = 768 end with 0.00867462158203125, sum = 0.398681640625)
text_model.encoder.layers.5.layer_norm1.weight
[1.438  1.549  1.444  1.437  1.47   1.599  1.4795 1.496  1.506  1.42  ] ...(size = 768 end with 1.4345703125, sum = 1149.0)
text_model.encoder.layers.5.layer_norm1.bias
[ 0.09503  0.06226 -0.1109  -0.0186   0.0807   0.1361   0.06903  0.03696
 -0.1356  -0.00266] ...(size = 768 end with -0.0345458984375, sum = 1.716796875)
text_model.encoder.layers.5.mlp.fc1.bias
[-0.3743 -0.409  -0.3171 -0.2642 -0.2595 -0.3726  0.1897 -0.364  -0.0976
 -0.2915] ...(size = 3072 end with -0.310302734375, sum = -875.5)
text_model.encoder.layers.5.mlp.fc2.bias
[ 0.05408   0.1301   -0.05798   0.01572   0.0327    0.0955    0.012794
 -0.06744  -0.1254    0.00614 ] ...(size = 768 end with 0.09521484375, sum = 0.1318359375)
text_model.encoder.layers.5.layer_norm2.weight
[2.13  2.098 2.166 2.082 1.795 2.16  2.201 2.092 2.234 2.156] ...(size = 768 end with 2.298828125, sum = 1631.0)
text_model.encoder.layers.5.layer_norm2.bias
[ 0.05502  0.3418  -0.599    0.05743 -0.593    0.621    0.7227  -0.3835
  0.531   -0.345  ] ...(size = 768 end with 0.6455078125, sum = -7.16015625)
text_model.encoder.layers.6.self_attn.k_proj.bias
[ 0.006336   0.002693  -0.005703   0.006226  -0.001444   0.001412
 -0.0001743 -0.00612    0.003546  -0.00496  ] ...(size = 768 end with 0.00455474853515625, sum = -0.345947265625)
text_model.encoder.layers.6.self_attn.v_proj.bias
[ 0.02711   0.001228  0.004333  0.04114   0.02036  -0.006992 -0.02
  0.02708   0.004387 -0.012665] ...(size = 768 end with -0.006359100341796875, sum = 1.5576171875)
text_model.encoder.layers.6.self_attn.q_proj.bias
[ 0.11993 -0.129    0.1978  -0.2443   0.0557  -0.2065   0.1271   0.2412
  0.0957   0.07385] ...(size = 768 end with 0.06854248046875, sum = 13.765625)
text_model.encoder.layers.6.self_attn.out_proj.bias
[ 0.02086 -0.02063 -0.05032 -0.01585  0.01868 -0.0086   0.01694 -0.0428
 -0.03098  0.0289 ] ...(size = 768 end with -0.030487060546875, sum = 0.47998046875)
text_model.encoder.layers.6.layer_norm1.weight
[1.562 1.629 1.513 1.575 1.622 1.579 1.589 1.575 1.608 1.599] ...(size = 768 end with 1.5859375, sum = 1217.0)
text_model.encoder.layers.6.layer_norm1.bias
[ 0.104    0.09705 -0.156   -0.00828  0.1023   0.1411   0.103    0.05426
 -0.1665  -0.00877] ...(size = 768 end with 0.007232666015625, sum = 2.80859375)
text_model.encoder.layers.6.mlp.fc1.bias
[-0.2957 -0.3293 -0.348  -0.254  -0.3374 -0.353  -0.3538 -0.3384 -0.3015
 -0.348 ] ...(size = 3072 end with -0.335205078125, sum = -892.0)
text_model.encoder.layers.6.mlp.fc2.bias
[ 0.0764    0.03943  -0.1373    0.05814   0.03958   0.07416   0.0571
 -0.00368  -0.006153  0.01209 ] ...(size = 768 end with 0.0181732177734375, sum = 0.276123046875)
text_model.encoder.layers.6.layer_norm2.weight
[2.195 2.244 2.186 2.121 1.639 2.186 2.164 2.283 2.213 2.217] ...(size = 768 end with 2.349609375, sum = 1669.0)
text_model.encoder.layers.6.layer_norm2.bias
[ 0.1328   1.049   -0.44    -0.3508  -0.1573   0.1047   0.3462  -0.3606
 -0.5312  -0.11505] ...(size = 768 end with 1.0615234375, sum = 0.79833984375)
text_model.encoder.layers.7.self_attn.k_proj.bias
[-0.00931    0.01232   -0.002289   0.005943  -0.001903   0.03967
  0.01732    0.0007343  0.0163    -0.003777 ] ...(size = 768 end with -0.005168914794921875, sum = 0.49169921875)
text_model.encoder.layers.7.self_attn.v_proj.bias
[-0.03796   0.003035  0.0282   -0.034    -0.05225  -0.0353   -0.09576
  0.02113   0.04666   0.04767 ] ...(size = 768 end with 0.0243072509765625, sum = 1.3759765625)
text_model.encoder.layers.7.self_attn.q_proj.bias
[-0.2406  0.2976  0.3762 -0.1519 -0.2314  0.8965  0.2832 -0.1705  0.1742
 -0.3435] ...(size = 768 end with 0.023681640625, sum = -9.9609375)
text_model.encoder.layers.7.self_attn.out_proj.bias
[-0.001656  -0.0682    -0.006268  -0.0011215  0.01794   -0.02936
  0.02592   -0.01593    0.01796   -0.0195   ] ...(size = 768 end with -0.0445556640625, sum = 0.5234375)
text_model.encoder.layers.7.layer_norm1.weight
[1.549 1.64  1.6   1.589 1.633 1.64  1.543 1.599 1.594 1.624] ...(size = 768 end with 1.64453125, sum = 1225.0)
text_model.encoder.layers.7.layer_norm1.bias
[ 0.0992   0.04385 -0.1775   0.032    0.07983  0.2203   0.09344  0.03696
 -0.11444 -0.01236] ...(size = 768 end with -0.004535675048828125, sum = 2.95703125)
text_model.encoder.layers.7.mlp.fc1.bias
[-0.354  -0.2788 -0.3865 -0.2266 -0.3882 -0.3728 -0.3074 -0.3887 -0.3381
 -0.322 ] ...(size = 3072 end with -0.2264404296875, sum = -888.0)
text_model.encoder.layers.7.mlp.fc2.bias
[ 0.044     0.044    -0.04034   0.07825   0.003208 -0.006916  0.0635
  0.000622  0.02325  -0.05026 ] ...(size = 768 end with -0.0142974853515625, sum = 0.126708984375)
text_model.encoder.layers.7.layer_norm2.weight
[2.264  2.156  2.271  2.242  1.7295 2.227  2.223  2.193  2.293  2.305 ] ...(size = 768 end with 2.361328125, sum = 1722.0)
text_model.encoder.layers.7.layer_norm2.bias
[ 0.1621   0.1321  -0.8623  -0.0336   0.1501   0.05414  0.1869   0.04797
  0.1135  -0.01724] ...(size = 768 end with 0.64013671875, sum = 10.703125)
text_model.encoder.layers.8.self_attn.k_proj.bias
[-0.02374  -0.04013   0.0226    0.02937  -0.0718   -0.003748  0.001768
 -0.03247  -0.002567 -0.0328  ] ...(size = 768 end with 0.004638671875, sum = 0.22119140625)
text_model.encoder.layers.8.self_attn.v_proj.bias
[ 0.01316   0.0447   -0.006905 -0.0266    0.0158    0.03647   0.006744
  0.01953  -0.02092  -0.0598  ] ...(size = 768 end with 0.007251739501953125, sum = -1.376953125)
text_model.encoder.layers.8.self_attn.q_proj.bias
[-0.03387  0.595   -0.347   -0.3757   0.2393   0.02971  0.1929   0.2554
  0.1009   0.4797 ] ...(size = 768 end with -0.25390625, sum = -7.58984375)
text_model.encoder.layers.8.self_attn.out_proj.bias
[-0.03275  -0.03726   0.0706   -0.0494   -0.08563  -0.1174    0.002825
  0.03528   0.02748  -0.0739  ] ...(size = 768 end with -0.0345458984375, sum = 0.0689697265625)
text_model.encoder.layers.8.layer_norm1.weight
[1.793 1.783 1.78  1.682 1.618 1.818 1.828 1.816 1.819 1.749] ...(size = 768 end with 1.7216796875, sum = 1341.0)
text_model.encoder.layers.8.layer_norm1.bias
[ 0.1095    0.1203   -0.2264    0.01363   0.07715   0.2076    0.1273
  0.05344  -0.1876   -0.003767] ...(size = 768 end with 0.0107269287109375, sum = 3.05078125)
text_model.encoder.layers.8.mlp.fc1.bias
[-0.2454  -0.34    -0.386   -0.2878  -0.2932  -0.1472  -0.06012 -0.3394
 -0.3198  -0.3203 ] ...(size = 3072 end with -0.1424560546875, sum = -913.0)
text_model.encoder.layers.8.mlp.fc2.bias
[ 0.02159 -0.03897  0.04706 -0.03928 -0.04865 -0.04865  0.0691   0.05264
  0.05444 -0.03244] ...(size = 768 end with -0.0007009506225585938, sum = 0.267333984375)
text_model.encoder.layers.8.layer_norm2.weight
[2.37  2.23  2.18  2.262 1.878 2.447 2.227 2.27  2.328 2.453] ...(size = 768 end with 2.3671875, sum = 1770.0)
text_model.encoder.layers.8.layer_norm2.bias
[-0.2197  0.3354 -0.4778  0.2296 -0.257  -0.278   0.268   0.1041 -0.382
 -0.284 ] ...(size = 768 end with 0.263671875, sum = -16.09375)
text_model.encoder.layers.9.self_attn.k_proj.bias
[ 0.04285  -0.0204   -0.00933  -0.00813   0.0238   -0.01161   0.012924
  0.013016 -0.023     0.002428] ...(size = 768 end with -0.1544189453125, sum = 0.9970703125)
text_model.encoder.layers.9.self_attn.v_proj.bias
[-0.0349   -0.041     0.0311    0.02191   0.02054  -0.002764  0.00368
 -0.02979   0.06305   0.05273 ] ...(size = 768 end with -0.006984710693359375, sum = 1.494140625)
text_model.encoder.layers.9.self_attn.q_proj.bias
[-0.3987    0.2491    0.1892   -0.013466  0.09534   0.06223   0.04962
 -0.1699    0.04456  -0.2915  ] ...(size = 768 end with 0.51416015625, sum = -14.296875)
text_model.encoder.layers.9.self_attn.out_proj.bias
[-0.0707  -0.04578  0.091   -0.0929  -0.1055  -0.1018  -0.0258  -0.0195
  0.09906 -0.05978] ...(size = 768 end with 0.023834228515625, sum = 0.2578125)
text_model.encoder.layers.9.layer_norm1.weight
[1.63  1.799 1.665 1.674 1.625 1.743 1.635 1.595 1.783 1.715] ...(size = 768 end with 1.646484375, sum = 1312.0)
text_model.encoder.layers.9.layer_norm1.bias
[ 0.1348   0.0495  -0.1992  -0.02518  0.1837   0.1461   0.1409   0.06854
 -0.1594  -0.0622 ] ...(size = 768 end with -0.01383209228515625, sum = 4.38671875)
text_model.encoder.layers.9.mlp.fc1.bias
[-0.2388  -0.3625  -0.08655 -0.247   -0.3867  -0.2485  -0.2224  -0.3096
 -0.374   -0.2546 ] ...(size = 3072 end with -0.12060546875, sum = -903.5)
text_model.encoder.layers.9.mlp.fc2.bias
[ 0.01605  0.0102  -0.00866 -0.04434 -0.0706   0.01116 -0.03613 -0.0557
  0.0898  -0.07855] ...(size = 768 end with 0.040557861328125, sum = 0.07568359375)
text_model.encoder.layers.9.layer_norm2.weight
[2.559 2.33  2.371 2.398 1.955 2.623 2.406 2.42  2.543 2.293] ...(size = 768 end with 2.443359375, sum = 1856.0)
text_model.encoder.layers.9.layer_norm2.bias
[ 0.02994 -0.3015   0.1412  -0.3464  -0.251   -0.563    0.2264   0.246
  0.1647  -0.4207 ] ...(size = 768 end with 0.069580078125, sum = -8.5703125)
text_model.encoder.layers.10.self_attn.k_proj.bias
[ 0.000829   0.002005  -0.006413   0.002409   0.002234  -0.0005426
  0.007      0.00899    0.01036   -0.001621 ] ...(size = 768 end with 0.054168701171875, sum = 0.59228515625)
text_model.encoder.layers.10.self_attn.v_proj.bias
[ 0.02965  0.02142 -0.0258   0.01959  0.01284 -0.04712  0.02307 -0.03647
 -0.01506  0.1173 ] ...(size = 768 end with 0.032806396484375, sum = -1.9951171875)
text_model.encoder.layers.10.self_attn.q_proj.bias
[-0.11414  0.1932   0.1205   0.2396  -0.05798  0.368   -0.3896   0.04245
 -0.01573 -0.0666 ] ...(size = 768 end with 0.019317626953125, sum = 9.8828125)
text_model.encoder.layers.10.self_attn.out_proj.bias
[-0.10736   0.10443   0.0734   -0.06793  -0.0929   -0.0867   -0.12103
 -0.0536    0.1763   -0.006317] ...(size = 768 end with 0.08203125, sum = 0.6962890625)
text_model.encoder.layers.10.layer_norm1.weight
[1.862  1.803  1.7705 1.781  1.541  1.761  1.764  1.665  1.708  1.769 ] ...(size = 768 end with 1.744140625, sum = 1353.0)
text_model.encoder.layers.10.layer_norm1.bias
[ 0.1571   0.1052  -0.2185  -0.03635  0.182    0.1725   0.1329   0.0708
 -0.1926  -0.09216] ...(size = 768 end with -0.00167083740234375, sum = 5.05859375)
text_model.encoder.layers.10.mlp.fc1.bias
[-0.327  -0.238  -0.3926 -0.3909 -0.2324 -0.3132 -0.1016 -0.2375 -0.259
 -0.245 ] ...(size = 3072 end with -0.293212890625, sum = -860.5)
text_model.encoder.layers.10.mlp.fc2.bias
[-0.03647  0.1627  -0.06024 -0.00979 -0.0443   0.1178   0.09424 -0.1334
  0.03613  0.02902] ...(size = 768 end with 0.061553955078125, sum = -0.634765625)
text_model.encoder.layers.10.layer_norm2.weight
[2.283 2.262 2.273 2.275 2.268 2.49  2.484 2.371 2.527 2.236] ...(size = 768 end with 2.388671875, sum = 1806.0)
text_model.encoder.layers.10.layer_norm2.bias
[ 0.0866  -0.293    0.1976  -0.12164 -0.389   -0.2184  -0.1244   0.1483
  0.06433 -0.0778 ] ...(size = 768 end with 0.12176513671875, sum = -18.203125)
text_model.encoder.layers.11.self_attn.k_proj.bias
[ 0.000508  -0.00256    0.004627   0.00334   -0.00197    0.001952
  0.000587  -0.0004306 -0.01877   -0.0004332] ...(size = 768 end with 0.0004892349243164062, sum = 0.067626953125)
text_model.encoder.layers.11.self_attn.v_proj.bias
[ 0.04968   0.0457    0.0467    0.017     0.004368  0.1133    0.03278
 -0.0453    0.07526  -0.03075 ] ...(size = 768 end with -0.0736083984375, sum = 0.58349609375)
text_model.encoder.layers.11.self_attn.q_proj.bias
[ 0.1714    0.2435    0.2001   -0.10913  -0.1874   -0.010254  0.05444
 -0.03065  -1.839     0.1381  ] ...(size = 768 end with -0.031402587890625, sum = 12.1328125)
text_model.encoder.layers.11.self_attn.out_proj.bias
[-0.3293   0.3857  -0.1589  -0.0797  -0.1267  -0.162    0.1059  -0.2961
  0.2302   0.03647] ...(size = 768 end with 0.258544921875, sum = 0.53076171875)
text_model.encoder.layers.11.layer_norm1.weight
[1.885 1.835 1.877 1.881 1.557 1.884 1.892 1.811 1.987 1.898] ...(size = 768 end with 1.8310546875, sum = 1444.0)
text_model.encoder.layers.11.layer_norm1.bias
[ 0.1498   0.0908  -0.1123  -0.02408  0.2125   0.2267   0.1572   0.2183
 -0.2458  -0.0884 ] ...(size = 768 end with 0.0787353515625, sum = 4.86328125)
text_model.encoder.layers.11.mlp.fc1.bias
[-0.1271 -0.1493 -0.2289 -0.3806 -0.1064 -0.2434 -0.1759 -0.2068 -0.266
 -0.0898] ...(size = 3072 end with -0.042388916015625, sum = -803.0)
text_model.encoder.layers.11.mlp.fc2.bias
[ 0.2559   -0.262     0.2349    0.1392   -0.00136   0.04492   0.11615
  0.011955 -0.2246    0.1194  ] ...(size = 768 end with -0.06005859375, sum = -1.0361328125)
text_model.encoder.layers.11.layer_norm2.weight
[1.745  1.792  1.786  1.706  2.227  1.77   1.6455 1.703  1.794  1.714 ] ...(size = 768 end with 1.740234375, sum = 1348.0)
text_model.encoder.layers.11.layer_norm2.bias
[-0.01553 -0.09174 -0.1405   0.02913 -0.2947   0.2324   0.1465   0.1382
 -0.14    -0.1125 ] ...(size = 768 end with 0.175048828125, sum = -1.33203125)
text_model.final_layer_norm.weight
[0.979  0.929  1.051  0.9834 1.363  0.982  0.896  0.99   0.972  1.02  ] ...(size = 768 end with 0.97802734375, sum = 763.5)
text_model.final_layer_norm.bias
[-0.3098   0.08655 -0.1781  -0.2128   0.01031 -0.218    0.02681 -0.1241
  0.11346 -0.1087 ] ...(size = 768 end with 0.09539794921875, sum = -85.0625)
onnx::Gather_2078
[0 1 2 3 4 5 6 7 8 9] ...(size = 77 end with 76, sum = 2926)
onnx::MatMul_2079
[ 0.01387  -0.05862  -0.02113   0.001622 -0.01461   0.00587  -0.0089
  0.02641  -0.0192   -0.02936 ] ...(size = 589824 end with 0.04248046875, sum = 14.1796875)
onnx::MatMul_2080
[-0.004616 -0.02571  -0.01325   0.001405 -0.0126    0.02467   0.01444
 -0.0194    0.01913  -0.02888 ] ...(size = 589824 end with 0.0048828125, sum = -11.890625)
onnx::MatMul_2091
[ 0.00655   0.003769  0.008736 -0.02274  -0.003893  0.001189  0.005108
  0.01107  -0.01677   0.001584] ...(size = 589824 end with 0.0030460357666015625, sum = -4.00390625)
onnx::MatMul_2127
[ 0.003212  -0.00932    0.0005665 -0.02193   -0.007694   0.004013
 -0.010796  -0.003586  -0.005844  -0.00641  ] ...(size = 589824 end with 0.007434844970703125, sum = 0.69873046875)
onnx::MatMul_2128
[ 0.04016    0.03204   -0.007206   0.02037   -0.008064  -0.0002044
 -0.01064   -0.001217  -0.00568   -0.01247  ] ...(size = 2359296 end with -0.01172637939453125, sum = -656.5)
onnx::MatMul_2129
[-0.000947  0.00071   0.001316  0.003325 -0.003906 -0.02774   0.00888
  0.01229   0.0097    0.02342 ] ...(size = 2359296 end with -0.0009479522705078125, sum = 18.953125)
onnx::MatMul_2130
[ 0.003275   0.005028   0.0001836 -0.005215   0.02411   -0.0225
  0.0642     0.01918    0.0559    -0.02936  ] ...(size = 589824 end with 0.0004582405090332031, sum = -1.1611328125)
onnx::MatMul_2131
[-0.00819  -0.002577 -0.01907   0.04016   0.001599  0.00588  -0.04495
 -0.001029  0.01974   0.01011 ] ...(size = 589824 end with -0.0077667236328125, sum = -1.5390625)
onnx::MatMul_2142
[ 0.0353    0.02858   0.0019   -0.003832 -0.01359   0.01962  -0.01067
 -0.002241 -0.004936 -0.002628] ...(size = 589824 end with -0.00940704345703125, sum = -4.60546875)
onnx::MatMul_2178
[ 0.0056    0.02176   0.00069   0.02724   0.004948  0.0348    0.007084
 -0.02173  -0.01159   0.02597 ] ...(size = 589824 end with 0.01329803466796875, sum = -2.78125)
onnx::MatMul_2179
[ 0.0344   -0.01005  -0.0169   -0.013756  0.01323  -0.0191    0.003515
  0.0224    0.013916 -0.002207] ...(size = 2359296 end with -0.019561767578125, sum = 376.25)
onnx::MatMul_2180
[ 0.002384 -0.003323 -0.02031   0.007812 -0.01361  -0.00735   0.00153
  0.00908  -0.01359  -0.000916] ...(size = 2359296 end with -0.011077880859375, sum = 8.3125)
onnx::MatMul_2181
[-0.03342  -0.006687 -0.00802  -0.00522   0.006012  0.004177 -0.009254
  0.00781   0.01761   0.00518 ] ...(size = 589824 end with -0.001983642578125, sum = -0.1798095703125)
onnx::MatMul_2182
[-0.00445   0.003239  0.003319  0.01406   0.01145  -0.004986  0.001602
  0.04227   0.01044   0.00606 ] ...(size = 589824 end with 0.044952392578125, sum = -6.0078125)
onnx::MatMul_2193
[-0.00193  -0.00426  -0.00792  -0.000591 -0.01514  -0.02072   0.01174
 -0.00788  -0.00402   0.02562 ] ...(size = 589824 end with 0.0117645263671875, sum = -5.0078125)
onnx::MatMul_2229
[ 0.005795  0.001066 -0.02344   0.002197  0.01576   0.001766  0.0092
 -0.009995  0.02136   0.011536] ...(size = 589824 end with -0.00312042236328125, sum = 0.6279296875)
onnx::MatMul_2230
[ 0.02025  0.02794 -0.01005  0.02783  0.01213  0.0454   0.01678 -0.0285
  0.01075 -0.00343] ...(size = 2359296 end with 0.0142669677734375, sum = 0.62158203125)
onnx::MatMul_2231
[-0.0104   -0.00168  -0.01152  -0.002565 -0.00446   0.01382  -0.010666
  0.001764 -0.02306  -0.01196 ] ...(size = 2359296 end with -0.006805419921875, sum = -0.55029296875)
onnx::MatMul_2232
[-0.01855   0.03049   0.002039  0.02998  -0.02187   0.01041   0.01619
 -0.00655   0.01488   0.05533 ] ...(size = 589824 end with -0.007511138916015625, sum = -5.46484375)
onnx::MatMul_2233
[ 0.004875  -0.02968    0.0001197  0.01307   -0.0173     0.00789
 -0.01083   -0.03087   -0.01736   -0.0127   ] ...(size = 589824 end with 0.0258331298828125, sum = 1.115234375)
onnx::MatMul_2244
[ 0.01884   -0.01976    0.02423    0.00841   -0.01572    0.00271
 -0.01478   -0.010574  -0.02931   -0.0007877] ...(size = 589824 end with 0.00225067138671875, sum = 3.19921875)
onnx::MatMul_2280
[-0.00721  -0.02043  -0.01199   0.000975  0.013214 -0.02335   0.01564
  0.002445  0.00595  -0.003471] ...(size = 589824 end with -0.03424072265625, sum = 1.146484375)
onnx::MatMul_2281
[ 0.01808   -0.0007424 -0.006176  -0.03903    0.03906    0.02333
  0.01202   -0.01139    0.03738   -0.02094  ] ...(size = 2359296 end with 0.031005859375, sum = -252.625)
onnx::MatMul_2282
[ 0.005646  0.002289 -0.00236   0.007763 -0.01387  -0.02081   0.01378
 -0.00606   0.010086  0.010414] ...(size = 2359296 end with 0.0170440673828125, sum = 7.80859375)
onnx::MatMul_2283
[-8.2932e-03  5.5511e-02  1.4305e-02 -2.1408e-02 -6.4201e-03  1.0468e-02
 -1.7223e-03  1.5373e-02 -3.1204e-02 -4.4107e-06] ...(size = 589824 end with 0.0033550262451171875, sum = 7.78515625)
onnx::MatMul_2284
[-0.02005  -0.00853  -0.02675  -0.011795  0.01432   0.001106  0.014915
  0.03105  -0.01811   0.01794 ] ...(size = 589824 end with 0.0107421875, sum = -4.1484375)
onnx::MatMul_2295
[-0.011505    0.0008516  -0.01646     0.01485    -0.01794     0.01845
  0.00849     0.00010765  0.00886     0.005245  ] ...(size = 589824 end with -0.019927978515625, sum = -1.8056640625)
onnx::MatMul_2331
[ 0.003263 -0.008804 -0.003181 -0.00891   0.01259   0.002356 -0.01371
 -0.003365  0.00951  -0.01747 ] ...(size = 589824 end with -0.0150909423828125, sum = 1.3056640625)
onnx::MatMul_2332
[-0.001751  -0.00605   -0.00408    0.00543   -0.01533   -0.0003202
 -0.014824   0.02592    0.02695   -0.0455   ] ...(size = 2359296 end with 0.0208587646484375, sum = -120.375)
onnx::MatMul_2333
[ 0.01189   0.006104  0.002804 -0.01335   0.02927   0.01814   0.00826
 -0.0348    0.006176  0.01877 ] ...(size = 2359296 end with 0.01261138916015625, sum = 5.34375)
onnx::MatMul_2334
[-0.003891 -0.01519   0.00417   0.01273   0.03757   0.04797   0.03845
  0.00961  -0.01294  -0.00433 ] ...(size = 589824 end with 0.0041656494140625, sum = 5.1640625)
onnx::MatMul_2335
[ 0.00685   0.01715  -0.0218    0.001363 -0.003378  0.0024   -0.01477
 -0.02156  -0.000622 -0.00629 ] ...(size = 589824 end with -0.0186767578125, sum = -1.4169921875)
onnx::MatMul_2346
[-0.003237  0.014534 -0.02437   0.02496  -0.02493   0.00447  -0.003372
  0.00782  -0.01978   0.004475] ...(size = 589824 end with 0.0122833251953125, sum = -7.90234375)
onnx::MatMul_2382
[ 0.005783  -0.0001541 -0.01271    0.02156    0.00626   -0.003357
  0.00775    0.01645   -0.012215  -0.004543 ] ...(size = 589824 end with 0.01523590087890625, sum = 1.271484375)
onnx::MatMul_2383
[-0.0219    0.003435  0.01863  -0.01768  -0.02881   0.006935  0.004383
  0.00908  -0.02228   0.00483 ] ...(size = 2359296 end with 0.000339508056640625, sum = 355.0)
onnx::MatMul_2384
[-0.003952   0.01021   -0.02469   -0.00868    0.0001849 -0.003702
  0.00973    0.0211    -0.011     -0.01659  ] ...(size = 2359296 end with -0.000164031982421875, sum = 0.1785888671875)
onnx::MatMul_2385
[ 0.04202  -0.02606   0.0267   -0.01987  -0.013405 -0.01631  -0.0193
 -0.00225  -0.00978   0.007736] ...(size = 589824 end with 0.007129669189453125, sum = -7.3515625)
onnx::MatMul_2386
[-0.0356    -0.006866  -0.01393    0.02908    0.01945    0.01145
 -0.0008287 -0.0117     0.02354    0.02165  ] ...(size = 589824 end with -0.00566864013671875, sum = 0.1593017578125)
onnx::MatMul_2397
[ 0.01171   -0.03152    0.0001947  0.003027  -0.02301    0.01149
  0.02606   -0.00951   -0.02612    0.01329  ] ...(size = 589824 end with 0.004222869873046875, sum = -3.212890625)
onnx::MatMul_2433
[-0.005543  0.02098   0.01883  -0.008865 -0.009575  0.01138   0.00906
 -0.02402  -0.01108   0.02403 ] ...(size = 589824 end with 0.023529052734375, sum = -1.70703125)
onnx::MatMul_2434
[-0.004772  0.01137  -0.02321  -0.002926  0.007473 -0.000793 -0.01077
  0.001445  0.00117   0.014   ] ...(size = 2359296 end with -0.00902557373046875, sum = 232.25)
onnx::MatMul_2435
[-0.02026   0.00792   0.01859   0.001889 -0.010056 -0.03065   0.02354
  0.02942  -0.01688   0.01096 ] ...(size = 2359296 end with -0.018218994140625, sum = -2.029296875)
onnx::MatMul_2436
[-9.018e-03  7.347e-03  5.295e-03 -5.600e-03  5.222e-03 -8.430e-03
 -3.041e-02 -1.733e-02 -2.777e-03 -9.459e-05] ...(size = 589824 end with 0.0306854248046875, sum = 1.283203125)
onnx::MatMul_2437
[ 0.000921  0.00855   0.003023  0.001785 -0.0364    0.03116  -0.03024
 -0.007378 -0.012505  0.01146 ] ...(size = 589824 end with -0.0140838623046875, sum = -2.48828125)
onnx::MatMul_2448
[ 0.00879   0.00866   0.01319  -0.02159   0.006607  0.01714  -0.00924
 -0.03522  -0.001007  0.01005 ] ...(size = 589824 end with 0.00623321533203125, sum = 6.62890625)
onnx::MatMul_2484
[-0.0192   -0.03006   0.014175  0.01807  -0.01249  -0.03598   0.01455
 -0.01045  -0.01602  -0.01285 ] ...(size = 589824 end with -0.004970550537109375, sum = 1.17578125)
onnx::MatMul_2485
[ 0.02486  -0.03165  -0.035     0.01101   0.003822 -0.004963  0.02792
 -0.01111   0.02707  -0.00446 ] ...(size = 2359296 end with -0.01192474365234375, sum = 0.435791015625)
onnx::MatMul_2486
[ 0.01718   0.01645  -0.001115  0.002676 -0.00513  -0.01663   0.006615
 -0.00891  -0.02707   0.02263 ] ...(size = 2359296 end with -0.00800323486328125, sum = -0.9169921875)
onnx::MatMul_2487
[-0.02396   -0.000908  -0.02428   -0.0009747  0.005913   0.0002666
  0.005928   0.005726   0.014626   0.01095  ] ...(size = 589824 end with -0.0019588470458984375, sum = 5.80859375)
onnx::MatMul_2488
[ 0.04648  -0.008644  0.02113  -0.00874  -0.04742  -0.014244  0.01392
 -0.01823  -0.001894 -0.01016 ] ...(size = 589824 end with 0.0035381317138671875, sum = -5.87890625)
onnx::MatMul_2499
[-8.649e-05 -3.012e-02  5.875e-03  1.889e-02  9.521e-03  1.400e-02
  2.037e-02 -4.555e-03  1.758e-04 -3.538e-03] ...(size = 589824 end with -0.0119476318359375, sum = -0.89404296875)
onnx::MatMul_2535
[ 1.698e-02 -4.172e-06 -9.972e-03 -1.230e-03  3.625e-02 -6.180e-03
 -2.357e-02  1.955e-03 -2.777e-02 -4.585e-03] ...(size = 589824 end with -0.007411956787109375, sum = 2.12109375)
onnx::MatMul_2536
[-7.618e-03 -8.163e-03 -2.979e-03  1.869e-02 -2.214e-02  9.598e-03
 -4.963e-03  5.126e-05 -3.214e-02 -1.817e-02] ...(size = 2359296 end with 0.0296173095703125, sum = 553.5)
onnx::MatMul_2537
[-0.01223    0.011894   0.005848   0.0004575  0.02034    0.007046
  0.00856   -0.01508   -0.02802    0.003736 ] ...(size = 2359296 end with -0.0266265869140625, sum = -6.76953125)
onnx::MatMul_2538
[ 0.02184   -0.004017   0.02547   -0.007774  -0.015396   0.003746
  0.0007257 -0.03403   -0.0001535  0.0054   ] ...(size = 589824 end with 0.0186920166015625, sum = 0.654296875)
onnx::MatMul_2539
[ 0.01755   -0.04144   -0.0163     0.02483    0.001495   0.008194
  0.01717   -0.02687   -0.01999    0.0003123] ...(size = 589824 end with 0.01331329345703125, sum = -1.521484375)
onnx::MatMul_2550
[-0.01538   0.01712   0.00462  -0.00727   0.013985 -0.00855  -0.0094
 -0.03156  -0.01379   0.01115 ] ...(size = 589824 end with 0.0160064697265625, sum = 0.228759765625)
onnx::MatMul_2586
[ 0.01558  -0.00536  -0.02576  -0.002552 -0.02866  -0.007465  0.01855
 -0.002832  0.01683  -0.001639] ...(size = 589824 end with 0.0175628662109375, sum = -0.8994140625)
onnx::MatMul_2587
[ 0.0171   -0.0364   -0.01126  -0.002525 -0.003836  0.01247  -0.01738
  0.01239   0.002491 -0.002054] ...(size = 2359296 end with 0.005611419677734375, sum = 482.0)
onnx::MatMul_2588
[ 1.442e-02 -7.637e-03  1.245e-04  1.477e-02 -1.581e-02  8.947e-05
 -1.669e-02  1.213e-02 -9.804e-03 -8.774e-03] ...(size = 2359296 end with -0.00617218017578125, sum = -1.80859375)
onnx::MatMul_2589
[ 0.002958 -0.01762   0.00331  -0.02638  -0.02248   0.02591  -0.011375
  0.03925   0.02005   0.01474 ] ...(size = 589824 end with -0.0201568603515625, sum = -3.5546875)
onnx::MatMul_2590
[ 0.02725   0.03114  -0.012436 -0.003183  0.03014   0.0137    0.01788
 -0.005657 -0.003983 -0.02429 ] ...(size = 589824 end with 0.0112152099609375, sum = 3.572265625)
onnx::MatMul_2601
[ 0.01729   0.00575   0.006496 -0.00802   0.004047  0.02055   0.004612
  0.02652  -0.004757  0.01982 ] ...(size = 589824 end with 0.01165771484375, sum = 0.44287109375)
onnx::MatMul_2637
[-0.002792 -0.01645  -0.02357   0.02483  -0.05984  -0.042     0.02145
  0.02771  -0.00866  -0.02638 ] ...(size = 589824 end with 0.025421142578125, sum = -0.7041015625)
onnx::MatMul_2638
[-0.01929  -0.03008  -0.001552  0.01836   0.003761 -0.006695 -0.002556
 -0.00808   0.01426  -0.01207 ] ...(size = 2359296 end with 0.02191162109375, sum = 668.5)
onnx::MatMul_2639
[-0.01714  -0.02237   0.02863   0.04248  -0.002851 -0.02744   0.008644
  0.01659   0.01112   0.002785] ...(size = 2359296 end with 0.00290679931640625, sum = -1.6162109375)
onnx::MatMul_2640
[ 0.02982  -0.00957   0.00797  -0.00795  -0.00269  -0.02252  -0.00443
  0.012115  0.0058   -0.00328 ] ...(size = 589824 end with 0.004741668701171875, sum = -5.296875)
onnx::MatMul_2641
[-0.005154  0.005066 -0.007183  0.00336  -0.008484  0.01707  -0.01378
 -0.003906  0.01666  -0.00633 ] ...(size = 589824 end with 0.0135345458984375, sum = -0.345458984375)
onnx::MatMul_2652
[-0.004364   0.0009007 -0.001807  -0.0388    -0.002195   0.001913
  0.01436   -0.02345    0.02304    0.0001968] ...(size = 589824 end with -0.0181884765625, sum = -1.509765625)
onnx::MatMul_2688
[-0.002144 -0.003027  0.006733  0.005466  0.02087   0.003475  0.01567
  0.01826   0.005703  0.00757 ] ...(size = 589824 end with -0.0217742919921875, sum = -0.12225341796875)
onnx::MatMul_2689
[ 0.004383 -0.002218  0.00551   0.02098   0.0219    0.002392 -0.00809
  0.005737  0.01804   0.02327 ] ...(size = 2359296 end with -0.0033054351806640625, sum = 459.25)
onnx::MatMul_2690
[-0.01151   0.00921   0.003038 -0.00982  -0.01406  -0.0206    0.002092
  0.01645   0.002972 -0.02274 ] ...(size = 2359296 end with -0.0026378631591796875, sum = 44.71875)

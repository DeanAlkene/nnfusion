  >> Backend = c-cuda, Python PID = 28928, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[N, H, W, C]], axis=[iter_var(N, range(min=0, ext=32)), iter_var(C, range(min=0, ext=3)), iter_var(H, range(min=0, ext=229)), iter_var(W, range(min=0, ext=229))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
found 10 results in first round with threshold 0.1
[debug] config = {"0": "{\"tile\": [1, 3, 4, 80], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 3, 4, 80], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [3, 1], 'H': [4, 1], 'W': [40, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [1, 3, 1], 'H': [1, 4, 1], 'W': [2, 40, 1]}
[debug] thread per block 480

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 229, 229, 3] -> output0:float32[32, 3, 229, 229]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C, H, W] = input0[N, H, W, C]", input_dict={"input0": {"dtype": "float32", "shape": [32, 229, 229, 3]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 229, 229, 3] -> output0:float32[32, 3, 229, 229]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(480) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 5568
  // [thread_extent] threadIdx.x = 480
  if (((((((int)blockIdx.x) % 174) / 3) * 4) + ((((int)threadIdx.x) % 160) / 40)) < 229) {
    output0[((((((((((int)blockIdx.x) / 174) * 157323) + ((((int)threadIdx.x) / 160) * 52441)) + (((((int)blockIdx.x) % 174) / 3) * 916)) + (((((int)threadIdx.x) % 160) / 40) * 229)) + ((((int)blockIdx.x) % 3) * 80)) + (((int)threadIdx.x) % 40)))] = input0[((((((((((int)blockIdx.x) / 174) * 157323) + (((((int)blockIdx.x) % 174) / 3) * 2748)) + (((((int)threadIdx.x) % 160) / 40) * 687)) + ((((int)blockIdx.x) % 3) * 240)) + ((((int)threadIdx.x) % 40) * 3)) + (((int)threadIdx.x) / 160)))];
    if ((((((int)blockIdx.x) % 3) * 80) + (((int)threadIdx.x) % 40)) < 189) {
      output0[(((((((((((int)blockIdx.x) / 174) * 157323) + ((((int)threadIdx.x) / 160) * 52441)) + (((((int)blockIdx.x) % 174) / 3) * 916)) + (((((int)threadIdx.x) % 160) / 40) * 229)) + ((((int)blockIdx.x) % 3) * 80)) + (((int)threadIdx.x) % 40)) + 40))] = input0[(((((((((((int)blockIdx.x) / 174) * 157323) + (((((int)blockIdx.x) % 174) / 3) * 2748)) + (((((int)threadIdx.x) % 160) / 40) * 687)) + ((((int)blockIdx.x) % 3) * 240)) + ((((int)threadIdx.x) % 40) * 3)) + (((int)threadIdx.x) / 160)) + 120))];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 7224239824.0, "TPR": 5.29039e-05}

[Antares] Average time cost / run = 5.29039e-05 sec, 95.16 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 30021, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[(input0[N] + input1[N])], axis=[iter_var(N, range(min=0, ext=524288))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'N': [32, 2]}
[debug] adjusted tiling: {'N': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[524288], input1:float32[524288] -> output0:float32[524288]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] = input0[N] + input1[N]", input_dict={"input0": {"dtype": "float32", "shape": [1024 * 512]}, "input1": {"dtype": "float32", "shape": [1024 * 512]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[524288], input1:float32[524288] -> output0:float32[524288]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 8192
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = (input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] + input1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]);
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = (input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] + input1[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1504583185.0, "TPR": 1.48978e-05}

[Antares] Average time cost / run = 1.48978e-05 sec, 35.1923 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 30423, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[A, B, (C/64), floormod(C, 64)]], axis=[iter_var(A, range(min=0, ext=3)), iter_var(B, range(min=0, ext=3)), iter_var(C, range(min=0, ext=128))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 1, 64], \"step\": []}", "1": "{\"tile\": [1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 64], \"step\": []}", "1": "{\"tile\": [1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'A': [1, 1], 'B': [1, 1], 'C': [32, 2]}
[debug] adjusted tiling: {'A': [1, 1, 1], 'B': [1, 1, 1], 'C': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[3, 3, 2, 64] -> output0:float32[3, 3, 128]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[A, B, C] = input0[A, B, C / 64, C % 64] where C in 128", input_dict={"input0": {"dtype": "float32", "shape": [3, 3, 2, 64]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[3, 3, 2, 64] -> output0:float32[3, 3, 128]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 18
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))];
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1645879.0, "TPR": 5.0686e-06}

[Antares] Average time cost / run = 5.0686e-06 sec, 0.227282 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 31053, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else((0f < input0[N, C]), input0[N, C], 0f)], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(C, range(min=0, ext=512))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [32, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 512] -> output0:float32[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C] = input0[N, C].when([input0[N, C] > 0.0], 0.0)", input_dict={"input0": {"dtype": "float32", "shape": [1024, 512]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 512] -> output0:float32[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 8192
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = ((0.000000e+00f < input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]) ? input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] : 0.000000e+00f);
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = ((0.000000e+00f < input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]) ? input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] : 0.000000e+00f);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 752291664.0, "TPR": 1.47415e-05}

[Antares] Average time cost / run = 1.47415e-05 sec, 35.5654 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 31535, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else((0f < input0[N, C]), input0[N, C], 0f)], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(C, range(min=0, ext=512))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [32, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 512] -> output0:float32[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C] = input0[N, C].when([input0[N, C] > const(0.0).cast(input0[N, C].dtype())], const(0.0).cast(input0[N, C].dtype()))", input_dict={"input0": {"dtype": "float32", "shape": [1024, 512]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 512] -> output0:float32[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 8192
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = ((0.000000e+00f < input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]) ? input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] : 0.000000e+00f);
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = ((0.000000e+00f < input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]) ? input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] : 0.000000e+00f);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 752291664.0, "TPR": 1.47282e-05}

[Antares] Average time cost / run = 1.47282e-05 sec, 35.5976 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 32018, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[0, H, W, C0, C1, C2]], axis=[iter_var(H, range(min=0, ext=256)), iter_var(C0, range(min=0, ext=2)), iter_var(W, range(min=0, ext=256)), iter_var(C1, range(min=0, ext=2)), iter_var(C2, range(min=0, ext=4))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
found 10 results in first round with threshold 1.0
[debug] config = {"0": "{\"tile\": [1, 1, 2, 4, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 2, 4, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'H': [1, 1], 'C0': [1, 1], 'W': [2, 1], 'C1': [4, 1], 'C2': [4, 2]}
[debug] adjusted tiling: {'H': [1, 1, 1], 'C0': [1, 1, 1], 'W': [1, 2, 1], 'C1': [1, 4, 1], 'C2': [2, 4, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1, 256, 256, 2, 2, 4] -> output0:float32[256, 2, 256, 2, 4]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, H, C0, W, C1, C2] = input0[N, H, W, C0, C1, C2]", input_dict={"input0": {"dtype": "float32", "shape": [1, 256, 256, 2, 2, 4]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1, 256, 256, 2, 2, 4] -> output0:float32[1, 256, 2, 256, 2, 4]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 65536
  // [thread_extent] threadIdx.x = 32
  if ((((int)threadIdx.x) & 15) < 8) {
    output0[((((((int)blockIdx.x) * 16) + ((((int)threadIdx.x) >> 4) * 8)) + (((int)threadIdx.x) & 15)))] = input0[((((((((int)blockIdx.x) >> 8) * 4096) + ((((int)blockIdx.x) & 127) * 32)) + (((((int)blockIdx.x) & 255) >> 7) * 8)) + ((int)threadIdx.x)))];
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1504846349.0, "TPR": 0.000104713}

[Antares] Average time cost / run = 0.000104713 sec, 10.0138 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 1100, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else(((((0 <= (-1 + HO)) && ((-1 + HO) < 32)) && (0 <= (-1 + WO))) && ((-1 + WO) < 32)), input0[N, C, (-1 + HO), (-1 + WO)], 0f)], axis=[iter_var(N, range(min=0, ext=32)), iter_var(C, range(min=0, ext=3)), iter_var(HO, range(min=0, ext=34)), iter_var(WO, range(min=0, ext=34))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
found 10 results in first round with threshold 0.2
[debug] config = {"0": "{\"tile\": [1, 1, 8, 40], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 8, 40], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [1, 1], 'HO': [8, 1], 'WO': [20, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [1, 1, 1], 'HO': [1, 8, 1], 'WO': [2, 20, 1]}
[debug] thread per block 160

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 3, 32, 32] -> output0:float32[32, 3, 34, 34]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C, HO, WO] = input0[N, C, -1 + HO, -1 + WO].when([-1 + HO >= 0, -1 + HO < 32, -1 + WO >= 0, -1 + WO < 32], 0.0) where HO in 34, WO in 34", input_dict={"input0": {"dtype": "float32", "shape": [32, 3, 32, 32]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 3, 32, 32] -> output0:float32[32, 3, 34, 34]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(160) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 480
  // [thread_extent] threadIdx.x = 160
  if ((((((int)blockIdx.x) % 5) * 8) + (((int)threadIdx.x) / 20)) < 34) {
    output0[((((((((int)blockIdx.x) / 5) * 1156) + ((((int)blockIdx.x) % 5) * 272)) + ((((int)threadIdx.x) / 20) * 34)) + (((int)threadIdx.x) % 20)))] = ((((1 <= (((((int)blockIdx.x) % 5) * 8) + (((int)threadIdx.x) / 20))) && ((((((int)blockIdx.x) % 5) * 8) + (((int)threadIdx.x) / 20)) < 33)) && (1 <= (((int)threadIdx.x) % 20))) ? input0[(((((((((int)blockIdx.x) / 5) * 1024) + ((((int)blockIdx.x) % 5) * 256)) + ((((int)threadIdx.x) / 20) * 32)) + (((int)threadIdx.x) % 20)) - 33))] : 0.000000e+00f);
    if ((((int)threadIdx.x) % 20) < 14) {
      output0[(((((((((int)blockIdx.x) / 5) * 1156) + ((((int)blockIdx.x) % 5) * 272)) + ((((int)threadIdx.x) / 20) * 34)) + (((int)threadIdx.x) % 20)) + 20))] = ((((1 <= (((((int)blockIdx.x) % 5) * 8) + (((int)threadIdx.x) / 20))) && ((((((int)blockIdx.x) % 5) * 8) + (((int)threadIdx.x) / 20)) < 33)) && ((((int)threadIdx.x) % 20) < 13)) ? input0[(((((((((int)blockIdx.x) / 5) * 1024) + ((((int)blockIdx.x) % 5) * 256)) + ((((int)threadIdx.x) / 20) * 32)) + (((int)threadIdx.x) % 20)) - 13))] : 0.000000e+00f);
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 141040062.0, "TPR": 9.93416e-06}

[Antares] Average time cost / run = 9.93416e-06 sec, 11.1712 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 1952, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[floormod(ON, 2), floormod(OC, 16)]], axis=[iter_var(ON, range(min=0, ext=1024)), iter_var(OC, range(min=0, ext=4096))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'ON': [1, 1], 'OC': [32, 2]}
[debug] adjusted tiling: {'ON': [1, 1, 1], 'OC': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[2, 16] -> output0:float32[1024, 4096]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[ON, OC] = input0[ON % 2, OC % 16] where ON in 1024, OC in 4096", input_dict={"input0": {"dtype": "float32", "shape": [2, 16]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[2, 16] -> output0:float32[1024, 4096]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 65536
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = input0[(((((((int)blockIdx.x) & 127) >> 6) * 16) + (((int)threadIdx.x) & 15)))];
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = input0[(((((((int)blockIdx.x) & 127) >> 6) * 16) + (((int)threadIdx.x) & 15)))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 2837445275.0, "TPR": 0.000104679}

[Antares] Average time cost / run = 0.000104679 sec, 40.0682 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 2385, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[(1f/(1f + tir.call_pure_extern("exp", (0f - input0[N, M]))))], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(M, range(min=0, ext=512))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'M': [32, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'M': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 512] -> output0:float32[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, M] = 1.0 / (1.0 + (-input0[N, M]).call(`exp`))", { "input0": {"dtype": "float32", "shape": [1024, 512]} })


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 512] -> output0:float32[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 8192
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = (1.000000e+00f / (1.000000e+00f + exp((0.000000e+00f - input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]))));
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = (1.000000e+00f / (1.000000e+00f + exp((0.000000e+00f - input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]))));
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 21203200.978, "TPR": 1.50513e-05}

[Antares] Average time cost / run = 1.50513e-05 sec, 34.8334 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 2845, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else((input1[N] != 0f), (input0[N]/input1[N]), 0f)], axis=[iter_var(N, range(min=0, ext=32768))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'N': [32, 2]}
[debug] adjusted tiling: {'N': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32768], input1:float32[32768] -> output0:float32[32768]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] = (input0[N] / input1[N]).when([input1[N] != 0], 0.0)", input_dict={"input0": {"dtype": "float32", "shape": [32 * 1024]}, "input1": {"dtype": "float32", "shape": [32 * 1024]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32768], input1:float32[32768] -> output0:float32[32768]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 512
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = ((input1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] != 0.000000e+00f) ? (input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] / input1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]) : 0.000000e+00f);
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = ((input1[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] != 0.000000e+00f) ? (input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] / input1[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]) : 0.000000e+00f);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1232285.9285, "TPR": 7.62897e-06}

[Antares] Average time cost / run = 7.62897e-06 sec, 4.29521 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 3241, Task = lang.generic;
[debug] devname = V100
[debug] op info =  compute(output0, body=[int8((bool(input0[N, M]) && (int32(input1[N, M]) == 0)))], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(M, range(min=0, ext=512))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'M': [32, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'M': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:int8[1024, 512], input1:int8[1024, 512] -> output0:int8[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, M] = input0[N, M] & ~input1[N, M]", { "input0": {"dtype": "int8", "shape": [1024, 512]}, "input1": {"dtype": "int8", "shape": [1024, 512]} })


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:int8[1024, 512], input1:int8[1024, 512] -> output0:int8[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(char* __restrict__ input0, char* __restrict__ input1, char* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 8192
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = ((char)(((bool)input0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]) && (((int)input1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))]) == 0)));
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = ((char)(((bool)input0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]) && (((int)input1[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))]) == 0)));
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1.061189314e-40, "TPR": 1.484e-05}

[Antares] Average time cost / run = 1.484e-05 sec, 35.3294 gflops. (Checked: None)

  >> Backend = c-cuda, Python PID = 3340, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[float32(N)], axis=[iter_var(N, range(min=0, ext=1024))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'N': [32, 2]}
[debug] adjusted tiling: {'N': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS:  -> output0:float32[1024]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] = N.cast(`float32`) where N in 1024", {})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 --  -> output0:float32[1024]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 16
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = ((float)((((int)blockIdx.x) * 64) + ((int)threadIdx.x)));
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = ((float)(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32));
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 21258462.0, "TPR": 3.28892e-06}

[Antares] Average time cost / run = 3.28892e-06 sec, 0.311348 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 3803, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.call_pure_extern("tanh", float32(N))], axis=[iter_var(N, range(min=0, ext=1024))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'N': [32, 2]}
[debug] adjusted tiling: {'N': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS:  -> output0:float32[1024]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] = N.cast(`float32`).call(`tanh`) where N in 1024", {})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 --  -> output0:float32[1024]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 16
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = tanh(((float)((((int)blockIdx.x) * 64) + ((int)threadIdx.x))));
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = tanh(((float)(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32)));
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 41240.39149, "TPR": 3.40265e-06}

[Antares] Average time cost / run = 3.40265e-06 sec, 0.300942 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 4293, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[(input0[0] + input1[0])], axis=[iter_var(I0, range(min=0, ext=1))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 1 results in first round with threshold 0.0
found 1 results in first round with threshold 0.1
found 1 results in first round with threshold 0.2
found 1 results in first round with threshold 0.3
found 1 results in first round with threshold 0.4
found 1 results in first round with threshold 0.5
found 1 results in first round with threshold 0.6
found 1 results in first round with threshold 0.7
found 1 results in first round with threshold 0.8
found 1 results in first round with threshold 0.9
found 2 results in first round with threshold 1.0
found 2 results in first round with threshold 1.1
found 2 results in first round with threshold 1.2
found 2 results in first round with threshold 1.3
found 2 results in first round with threshold 1.4
found 2 results in first round with threshold 1.5
found 2 results in first round with threshold 1.6
found 2 results in first round with threshold 1.7
found 2 results in first round with threshold 1.8
found 2 results in first round with threshold 1.9
found 2 results in first round with threshold 2.0
found 2 results in first round with threshold 2.1
found 2 results in first round with threshold 2.2
found 2 results in first round with threshold 2.3
found 2 results in first round with threshold 2.4
found 2 results in first round with threshold 2.5
found 2 results in first round with threshold 2.6
found 2 results in first round with threshold 2.7
found 2 results in first round with threshold 2.8
found 2 results in first round with threshold 2.9
found 3 results in first round with threshold 3.0
found 3 results in first round with threshold 3.1
found 3 results in first round with threshold 3.2
found 3 results in first round with threshold 3.3
found 3 results in first round with threshold 3.4
found 3 results in first round with threshold 3.5
found 3 results in first round with threshold 3.6
found 3 results in first round with threshold 3.7
found 3 results in first round with threshold 3.8
found 3 results in first round with threshold 3.9
[debug] config = {"0": "{\"tile\": [1], \"step\": []}", "1": "{\"tile\": [1], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1], \"step\": []}", "1": "{\"tile\": [1], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'I0': [1, 1]}
[debug] adjusted tiling: {'I0': [1, 1, 1]}
[debug] thread per block 1

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1], input1:float32[1] -> output0:float32[1]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[] = input0[] + input1[]", input_dict={"input0": {"dtype": "float32", "shape": []}, "input1": {"dtype": "float32", "shape": []}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1], input1:float32[1] -> output0:float32[1]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(1) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 1
  output0[(0)] = (input0[(0)] + input1[(0)]);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 3.0, "TPR": 7.32738e-06}

[Antares] Average time cost / run = 7.32738e-06 sec, 0.000136474 gflops. (Checked: True)

Finish Elementwise\n
  >> Backend = c-cuda, Python PID = 4936, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[0, F, 2]], axis=[iter_var(F, range(min=0, ext=16))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 7 results in first round with threshold 0.0
found 7 results in first round with threshold 0.1
found 7 results in first round with threshold 0.2
found 7 results in first round with threshold 0.3
found 7 results in first round with threshold 0.4
found 10 results in first round with threshold 0.5
[debug] config = {"0": "{\"tile\": [8], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [8], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'F': [4, 2]}
[debug] adjusted tiling: {'F': [2, 4, 1]}
[debug] thread per block 4

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1, 16, 32] -> output0:float32[16]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F] = input0[N, F, 2]", input_dict={"input0": {"dtype": "float32", "shape": [1, 16, 32]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1, 16, 32] -> output0:float32[1, 16]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(4) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 2
  // [thread_extent] threadIdx.x = 4
  output0[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)))] = input0[((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 32)) + 2))];
  output0[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) + 4))] = input0[((((((int)blockIdx.x) * 256) + (((int)threadIdx.x) * 32)) + 130))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 4807.0, "TPR": 4.9533e-06}

[Antares] Average time cost / run = 4.9533e-06 sec, 0.00323017 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 5326, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[input1[F], C]], axis=[iter_var(F, range(min=0, ext=3072)), iter_var(C, range(min=0, ext=1024))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [8, 128], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [8, 128], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'F': [8, 1], 'C': [64, 2]}
[debug] adjusted tiling: {'F': [1, 8, 1], 'C': [2, 64, 1]}
[debug] thread per block 512

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[30528, 1024], input1:int32[3072] -> output0:float32[3072, 1024]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[F, C] = input0[input1[F], C]", input_dict={"input0": {"dtype": "float32", "shape": [30528, 1024]}, "input1": {"dtype": "int32", "shape": [3072]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[30528, 1024], input1:int32[3072] -> output0:float32[3072, 1024]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(512) void template_op_kernel0(float* __restrict__ input0, int* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 3072
  // [thread_extent] threadIdx.x = 512
  output0[((((((((int)blockIdx.x) >> 3) * 8192) + ((((int)threadIdx.x) >> 6) * 1024)) + ((((int)blockIdx.x) & 7) * 128)) + (((int)threadIdx.x) & 63)))] = input0[((((input1[((((((int)blockIdx.x) >> 3) * 8) + (((int)threadIdx.x) >> 6)))] * 1024) + ((((int)blockIdx.x) & 7) * 128)) + (((int)threadIdx.x) & 63)))];
  output0[(((((((((int)blockIdx.x) >> 3) * 8192) + ((((int)threadIdx.x) >> 6) * 1024)) + ((((int)blockIdx.x) & 7) * 128)) + (((int)threadIdx.x) & 63)) + 64))] = input0[(((((input1[((((((int)blockIdx.x) >> 3) * 8) + (((int)threadIdx.x) >> 6)))] * 1024) + ((((int)blockIdx.x) & 7) * 128)) + (((int)threadIdx.x) & 63)) + 64))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 4440436078.0, "TPR": 1.68464e-05}

[Antares] Average time cost / run = 1.68464e-05 sec, 186.73 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 5920, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[input1[N, F]]], axis=[iter_var(N, range(min=0, ext=4)), iter_var(F, range(min=0, ext=64))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 64], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'F': [32, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'F': [2, 32, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[65536], input1:int32[4, 64] -> output0:float32[4, 64]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F] = input0[input1[N, F]]", input_dict={"input0": {"dtype": "float32", "shape": [65536]}, "input1": {"dtype": "int32", "shape": [4, 64]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[65536], input1:int32[4, 64] -> output0:float32[4, 64]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, int* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 4
  // [thread_extent] threadIdx.x = 32
  output0[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))] = input0[(input1[(((((int)blockIdx.x) * 64) + ((int)threadIdx.x)))])];
  output0[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))] = input0[(input1[((((((int)blockIdx.x) * 64) + ((int)threadIdx.x)) + 32))])];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 10237.0, "TPR": 6.62498e-06}

[Antares] Average time cost / run = 6.62498e-06 sec, 0.0386416 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 6309, Task = lang.generic;
[debug] devname = V100
[debug] op info =  compute(___data, body=[tir.call_pure_extern("__builtin_set", data[indices[B, 0], indices[B, 1], indices[B, 2], indices[B, 3], M], updates[B, M])], axis=[iter_var(M, range(min=0, ext=8)), iter_var(B, range(min=0, ext=2))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
failed to find results with padding threshold 1.0
failed to find results with padding threshold 1.1
failed to find results with padding threshold 1.2
failed to find results with padding threshold 1.3
failed to find results with padding threshold 1.4
failed to find results with padding threshold 1.5
failed to find results with padding threshold 1.6
failed to find results with padding threshold 1.7
failed to find results with padding threshold 1.8
failed to find results with padding threshold 1.9
failed to find results with padding threshold 2.0
failed to find results with padding threshold 2.1
failed to find results with padding threshold 2.2
failed to find results with padding threshold 2.3
failed to find results with padding threshold 2.4
failed to find results with padding threshold 2.5
failed to find results with padding threshold 2.6
failed to find results with padding threshold 2.7
failed to find results with padding threshold 2.8
failed to find results with padding threshold 2.9
found 10 results in first round with threshold 3.0
[debug] config = {"0": "{\"tile\": [8, 8], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [8, 8], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'M': [8, 1], 'B': [4, 2]}
[debug] adjusted tiling: {'M': [1, 8, 1], 'B': [2, 4, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: indices:int32[2, 4], updates:float32[2, 8] -> data:float32[32, 32, 32, 32, 8]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - _B, _M = 2, 8; einstein_v2("data[indices[B, 0], indices[B, 1], indices[B, 2], indices[B, 3], M] =. updates[B, M]", input_dict={"data": {"dtype": "float32", "shape": [32, 32, 32, 32, _M]}, "indices": {"dtype": "int32", "shape": [_B, 4]}, "updates": {"dtype": "float32", "shape": [_B, _M]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- indices:int32[2, 4], updates:float32[2, 8] -> data:float32[32, 32, 32, 32, 8]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(int* __restrict__ indices, float* __restrict__ updates, float* __restrict__ data) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 32
  if ((((int)threadIdx.x) & 3) < 2) {
    ((data[((((((indices[(((((int)threadIdx.x) & 3) * 4))] * 262144) + (indices[((((((int)threadIdx.x) & 3) * 4) + 1))] * 8192)) + (indices[((((((int)threadIdx.x) & 3) * 4) + 2))] * 256)) + (indices[((((((int)threadIdx.x) & 3) * 4) + 3))] * 8)) + (((int)threadIdx.x) >> 2)))]) = (updates[((((((int)threadIdx.x) & 3) * 8) + (((int)threadIdx.x) >> 2)))]));
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 240.0, "TPR": 7.23318e-06}

[Antares] Average time cost / run = 7.23318e-06 sec, 0.00221203 gflops. (Checked: None)

  >> Backend = c-cuda, Python PID = 6696, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[N]], axis=[iter_var(N, range(min=0, ext=16)), iter_var(F, range(min=0, ext=32)), iter_var(HO, range(min=0, ext=2)), iter_var(WO, range(min=0, ext=2))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: True
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
failed to find results with padding threshold 1.0
failed to find results with padding threshold 1.1
failed to find results with padding threshold 1.2
failed to find results with padding threshold 1.3
failed to find results with padding threshold 1.4
failed to find results with padding threshold 1.5
failed to find results with padding threshold 1.6
failed to find results with padding threshold 1.7
failed to find results with padding threshold 1.8
failed to find results with padding threshold 1.9
failed to find results with padding threshold 2.0
failed to find results with padding threshold 2.1
failed to find results with padding threshold 2.2
failed to find results with padding threshold 2.3
failed to find results with padding threshold 2.4
failed to find results with padding threshold 2.5
failed to find results with padding threshold 2.6
failed to find results with padding threshold 2.7
failed to find results with padding threshold 2.8
failed to find results with padding threshold 2.9
found 10 results in first round with threshold 3.0
[debug] config = {"0": "{\"tile\": [8, 2, 8, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [8, 2, 8, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [8, 1], 'F': [2, 1], 'HO': [8, 1], 'WO': [4, 2]}
[debug] adjusted tiling: {'N': [1, 8, 1], 'F': [1, 2, 1], 'HO': [1, 8, 1], 'WO': [2, 4, 1]}
[debug] thread per block 512

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[16] -> output0:float32[16, 32, 2, 2]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F, HO, WO] = input0[N] where F in 32, HO in 2, WO in 2", input_dict={"input0": {"dtype": "float32", "shape": [16]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[16] -> output0:float32[16, 32, 2, 2]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(512) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 32
  // [thread_extent] threadIdx.x = 512
  if ((((int)threadIdx.x) & 31) < 8) {
    if ((((int)threadIdx.x) & 3) < 2) {
      output0[((((((((((int)blockIdx.x) >> 4) * 1024) + ((((int)threadIdx.x) >> 6) * 128)) + ((((int)blockIdx.x) & 15) * 8)) + (((((int)threadIdx.x) & 63) >> 5) * 4)) + (((((int)threadIdx.x) & 31) >> 2) * 2)) + (((int)threadIdx.x) & 3)))] = input0[((((((int)blockIdx.x) >> 4) * 8) + (((int)threadIdx.x) >> 6)))];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 710615.0, "TPR": 1.92941e-06}

[Antares] Average time cost / run = 1.92941e-06 sec, 1.06146 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 9263, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[0]], axis=[iter_var(N, range(min=0, ext=8)), iter_var(F, range(min=0, ext=32)), iter_var(HO, range(min=0, ext=2)), iter_var(WO, range(min=0, ext=2))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: True
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
failed to find results with padding threshold 1.0
failed to find results with padding threshold 1.1
failed to find results with padding threshold 1.2
failed to find results with padding threshold 1.3
failed to find results with padding threshold 1.4
failed to find results with padding threshold 1.5
failed to find results with padding threshold 1.6
failed to find results with padding threshold 1.7
failed to find results with padding threshold 1.8
failed to find results with padding threshold 1.9
failed to find results with padding threshold 2.0
failed to find results with padding threshold 2.1
failed to find results with padding threshold 2.2
failed to find results with padding threshold 2.3
failed to find results with padding threshold 2.4
failed to find results with padding threshold 2.5
failed to find results with padding threshold 2.6
failed to find results with padding threshold 2.7
failed to find results with padding threshold 2.8
failed to find results with padding threshold 2.9
found 10 results in first round with threshold 3.0
[debug] config = {"0": "{\"tile\": [1, 1, 8, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 8, 8], \"step\": []}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": []}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'F': [1, 1], 'HO': [8, 1], 'WO': [4, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'F': [1, 1, 1], 'HO': [1, 8, 1], 'WO': [2, 4, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1] -> output0:float32[8, 32, 2, 2]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F, HO, WO] = input0[0] where N in 8, F in 32, HO in 2, WO in 2", input_dict={"input0": {"dtype": "float32", "shape": [1]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1] -> output0:float32[8, 32, 2, 2]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 256
  // [thread_extent] threadIdx.x = 32
  if (((int)threadIdx.x) < 8) {
    if ((((int)threadIdx.x) & 3) < 2) {
      output0[((((((int)blockIdx.x) * 4) + ((((int)threadIdx.x) >> 2) * 2)) + (((int)threadIdx.x) & 3)))] = input0[(0)];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 41242.0, "TPR": 4.84921e-06}

[Antares] Average time cost / run = 4.84921e-06 sec, 0.211168 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 11101, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else((F < 128), input0[N, F], input1[N, (F - 128)])], axis=[iter_var(N, range(min=0, ext=4)), iter_var(F, range(min=0, ext=256))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 256], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 256], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [1, 1], 'F': [128, 2]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'F': [2, 128, 1]}
[debug] thread per block 128

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[4, 128], input1:float32[4, 128] -> output0:float32[4, 256]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F] = input0[N, F].when([F < 128], input1[N, F - 128]) where F in 256", input_dict={"input0": {"dtype": "float32", "shape": [4, 128]}, "input1": {"dtype": "float32", "shape": [4, 128]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[4, 128], input1:float32[4, 128] -> output0:float32[4, 256]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(128) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 4
  // [thread_extent] threadIdx.x = 128
  output0[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)))] = input0[(((((int)blockIdx.x) * 128) + ((int)threadIdx.x)))];
  output0[((((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) + 128))] = input1[(((((int)blockIdx.x) * 128) + ((int)threadIdx.x)))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1401246.0, "TPR": 7.1149e-06}

[Antares] Average time cost / run = 7.1149e-06 sec, 0.143923 gflops. (Checked: True)

Finish Data Movement\n
  >> Backend = c-cuda, Python PID = 11444, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[N, K]*input1[K, M])], init=[], axis=[iter_var(K, range(min=0, ext=4096))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=4096)), iter_var(M, range(min=0, ext=4096))], reduce_axis=[iter_var(K, range(min=0, ext=4096))], tag=, attrs={})
[debug] is IODependent: True
found 10 results with threshold 0.0
[debug] config = {"0": "{\"tile\": [128, 64], \"step\": [8]}", "1": "{\"tile\": [8, 4], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [128, 64], \"step\": [8]}", "1": "{\"tile\": [8, 4], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] code gen tiling: {'N': [16, 8], 'M': [16, 4], 'K': [8, 1]}
[debug] adjusted tiling: {'N': [8, 16, 1], 'M': [4, 16, 1], 'K': [8, 1]}
[debug] thread per block 256

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[4096, 4096], input1:float32[4096, 4096] -> output0:float32[4096, 4096]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - S = 4096; einstein_v2(input_dict={"input0": {"dtype": "float32", "shape": [S, S]}, "input1": {"dtype": "float32", "shape": [S, S]}}, exprss="output0[N, M] +=! input0[N, K] * input1[K, M]")


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[4096, 4096], input1:float32[4096, 4096] -> output0:float32[4096, 4096]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(256) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 2048
  // [thread_extent] threadIdx.x = 256
  float output0_local[32];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(8)] = 0.000000e+00f;
  output0_local[(12)] = 0.000000e+00f;
  output0_local[(16)] = 0.000000e+00f;
  output0_local[(20)] = 0.000000e+00f;
  output0_local[(24)] = 0.000000e+00f;
  output0_local[(28)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(9)] = 0.000000e+00f;
  output0_local[(13)] = 0.000000e+00f;
  output0_local[(17)] = 0.000000e+00f;
  output0_local[(21)] = 0.000000e+00f;
  output0_local[(25)] = 0.000000e+00f;
  output0_local[(29)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(10)] = 0.000000e+00f;
  output0_local[(14)] = 0.000000e+00f;
  output0_local[(18)] = 0.000000e+00f;
  output0_local[(22)] = 0.000000e+00f;
  output0_local[(26)] = 0.000000e+00f;
  output0_local[(30)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  output0_local[(11)] = 0.000000e+00f;
  output0_local[(15)] = 0.000000e+00f;
  output0_local[(19)] = 0.000000e+00f;
  output0_local[(23)] = 0.000000e+00f;
  output0_local[(27)] = 0.000000e+00f;
  output0_local[(31)] = 0.000000e+00f;
  for (int K_outer = 0; K_outer < 512; ++K_outer) {
    __shared__ float input0_shared[1024];
  // [thread_extent] threadIdx.x = 256
    __syncthreads();
    input0_shared[(((int)threadIdx.x))] = input0[((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 3) * 4096)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)))];
    input0_shared[((((int)threadIdx.x) + 256))] = input0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 3) * 4096)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 131072))];
    input0_shared[((((int)threadIdx.x) + 512))] = input0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 3) * 4096)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 262144))];
    input0_shared[((((int)threadIdx.x) + 768))] = input0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 3) * 4096)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 393216))];
    __shared__ float input1_shared[512];
  // [thread_extent] threadIdx.x = 256
    input1_shared[(((int)threadIdx.x))] = input1[(((((K_outer * 32768) + ((((int)threadIdx.x) >> 6) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 63)))];
    input1_shared[((((int)threadIdx.x) + 256))] = input1[((((((K_outer * 32768) + ((((int)threadIdx.x) >> 6) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 63)) + 16384))];
    __syncthreads();
    for (int K_inner_outer = 0; K_inner_outer < 8; ++K_inner_outer) {
      float input0_shared_local[8];
      input0_shared_local[(0)] = input0_shared[((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer))];
      input0_shared_local[(1)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 128))];
      input0_shared_local[(2)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 256))];
      input0_shared_local[(3)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 384))];
      input0_shared_local[(4)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 512))];
      input0_shared_local[(5)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 640))];
      input0_shared_local[(6)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 768))];
      input0_shared_local[(7)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 896))];
      float input1_shared_local[4];
      input1_shared_local[(0)] = input1_shared[(((K_inner_outer * 64) + (((int)threadIdx.x) & 15)))];
      input1_shared_local[(1)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 16))];
      input1_shared_local[(2)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 32))];
      input1_shared_local[(3)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 48))];
      output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
      output0_local[(4)] = (output0_local[(4)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
      output0_local[(8)] = (output0_local[(8)] + (input0_shared_local[(2)] * input1_shared_local[(0)]));
      output0_local[(12)] = (output0_local[(12)] + (input0_shared_local[(3)] * input1_shared_local[(0)]));
      output0_local[(16)] = (output0_local[(16)] + (input0_shared_local[(4)] * input1_shared_local[(0)]));
      output0_local[(20)] = (output0_local[(20)] + (input0_shared_local[(5)] * input1_shared_local[(0)]));
      output0_local[(24)] = (output0_local[(24)] + (input0_shared_local[(6)] * input1_shared_local[(0)]));
      output0_local[(28)] = (output0_local[(28)] + (input0_shared_local[(7)] * input1_shared_local[(0)]));
      output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(0)] * input1_shared_local[(1)]));
      output0_local[(5)] = (output0_local[(5)] + (input0_shared_local[(1)] * input1_shared_local[(1)]));
      output0_local[(9)] = (output0_local[(9)] + (input0_shared_local[(2)] * input1_shared_local[(1)]));
      output0_local[(13)] = (output0_local[(13)] + (input0_shared_local[(3)] * input1_shared_local[(1)]));
      output0_local[(17)] = (output0_local[(17)] + (input0_shared_local[(4)] * input1_shared_local[(1)]));
      output0_local[(21)] = (output0_local[(21)] + (input0_shared_local[(5)] * input1_shared_local[(1)]));
      output0_local[(25)] = (output0_local[(25)] + (input0_shared_local[(6)] * input1_shared_local[(1)]));
      output0_local[(29)] = (output0_local[(29)] + (input0_shared_local[(7)] * input1_shared_local[(1)]));
      output0_local[(2)] = (output0_local[(2)] + (input0_shared_local[(0)] * input1_shared_local[(2)]));
      output0_local[(6)] = (output0_local[(6)] + (input0_shared_local[(1)] * input1_shared_local[(2)]));
      output0_local[(10)] = (output0_local[(10)] + (input0_shared_local[(2)] * input1_shared_local[(2)]));
      output0_local[(14)] = (output0_local[(14)] + (input0_shared_local[(3)] * input1_shared_local[(2)]));
      output0_local[(18)] = (output0_local[(18)] + (input0_shared_local[(4)] * input1_shared_local[(2)]));
      output0_local[(22)] = (output0_local[(22)] + (input0_shared_local[(5)] * input1_shared_local[(2)]));
      output0_local[(26)] = (output0_local[(26)] + (input0_shared_local[(6)] * input1_shared_local[(2)]));
      output0_local[(30)] = (output0_local[(30)] + (input0_shared_local[(7)] * input1_shared_local[(2)]));
      output0_local[(3)] = (output0_local[(3)] + (input0_shared_local[(0)] * input1_shared_local[(3)]));
      output0_local[(7)] = (output0_local[(7)] + (input0_shared_local[(1)] * input1_shared_local[(3)]));
      output0_local[(11)] = (output0_local[(11)] + (input0_shared_local[(2)] * input1_shared_local[(3)]));
      output0_local[(15)] = (output0_local[(15)] + (input0_shared_local[(3)] * input1_shared_local[(3)]));
      output0_local[(19)] = (output0_local[(19)] + (input0_shared_local[(4)] * input1_shared_local[(3)]));
      output0_local[(23)] = (output0_local[(23)] + (input0_shared_local[(5)] * input1_shared_local[(3)]));
      output0_local[(27)] = (output0_local[(27)] + (input0_shared_local[(6)] * input1_shared_local[(3)]));
      output0_local[(31)] = (output0_local[(31)] + (input0_shared_local[(7)] * input1_shared_local[(3)]));
    }
  }
  output0[((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)))] = output0_local[(0)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 65536))] = output0_local[(4)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 131072))] = output0_local[(8)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 196608))] = output0_local[(12)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 262144))] = output0_local[(16)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 327680))] = output0_local[(20)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 393216))] = output0_local[(24)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 458752))] = output0_local[(28)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 16))] = output0_local[(1)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 65552))] = output0_local[(5)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 131088))] = output0_local[(9)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 196624))] = output0_local[(13)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 262160))] = output0_local[(17)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 327696))] = output0_local[(21)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 393232))] = output0_local[(25)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 458768))] = output0_local[(29)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 32))] = output0_local[(2)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 65568))] = output0_local[(6)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 131104))] = output0_local[(10)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 196640))] = output0_local[(14)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 262176))] = output0_local[(18)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 327712))] = output0_local[(22)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 393248))] = output0_local[(26)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 458784))] = output0_local[(30)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 48))] = output0_local[(3)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 65584))] = output0_local[(7)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 131120))] = output0_local[(11)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 196656))] = output0_local[(15)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 262192))] = output0_local[(19)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 327728))] = output0_local[(23)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 393264))] = output0_local[(27)];
  output0[(((((((((int)blockIdx.x) >> 6) * 524288) + ((((int)threadIdx.x) >> 4) * 4096)) + ((((int)blockIdx.x) & 63) * 64)) + (((int)threadIdx.x) & 15)) + 458800))] = output0_local[(31)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 3451430443900000.0, "TPR": 0.0121699}

[Antares] Average time cost / run = 0.0121699 sec, 11293.4 gflops. (Checked: True)

Traceback (most recent call last):
  File "./antares/antares_compiler.py", line 728, in <module>
    main_compute()
  File "./antares/antares_compiler.py", line 467, in main_compute
    assert digests is not None, "Failed to generate CPU result for correctness reference"
AssertionError: Failed to generate CPU result for correctness reference
  >> Backend = c-cuda, Python PID = 12227, Task = lang.generic;
  >> Computing CPU result for correctness reference..
  >> Backend = c-cuda, Python PID = 13781, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[((input0[N, K]*input1[K, M]) + (input2[M]/512f))], init=[], axis=[iter_var(K, range(min=0, ext=512))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(M, range(min=0, ext=512))], reduce_axis=[iter_var(K, range(min=0, ext=512))], tag=, attrs={})
[debug] is IODependent: True
found 10 results with threshold 0.0
[debug] config = {"0": "{\"tile\": [64, 32], \"step\": [8]}", "1": "{\"tile\": [4, 2], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [64, 32], \"step\": [8]}", "1": "{\"tile\": [4, 2], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] code gen tiling: {'N': [16, 4], 'M': [16, 2], 'K': [8, 1]}
[debug] adjusted tiling: {'N': [4, 16, 1], 'M': [2, 16, 1], 'K': [8, 1]}
[debug] thread per block 256

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 512], input1:float32[512, 512], input2:float32[512] -> output0:float32[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, M] +=! input0[N, K] * input1[K, M] + input2[M] / K.val()", { "input0": {"dtype": "float32", "shape": [1024, 512]}, "input1": {"dtype": "float32", "shape": [512, 512]}, "input2": {"dtype": "float32", "shape": [512]} })


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 512], input1:float32[512, 512], input2:float32[512] -> output0:float32[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(256) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ input2, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 256
  // [thread_extent] threadIdx.x = 256
  float output0_local[8];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  for (int K_outer = 0; K_outer < 64; ++K_outer) {
    __shared__ float input0_shared[512];
  // [thread_extent] threadIdx.x = 256
    __syncthreads();
    input0_shared[(((int)threadIdx.x))] = input0[((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)))];
    input0_shared[((((int)threadIdx.x) + 256))] = input0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 16384))];
    __shared__ float input1_shared[256];
  // [thread_extent] threadIdx.x = 256
    input1_shared[(((int)threadIdx.x))] = input1[(((((K_outer * 4096) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 31)))];
    __shared__ float input2_shared[32];
  // [thread_extent] threadIdx.x = 256
    if (((int)threadIdx.x) < 32) {
      input2_shared[(((int)threadIdx.x))] = input2[((((((int)blockIdx.x) & 15) * 32) + ((int)threadIdx.x)))];
    }
    __syncthreads();
    for (int K_inner_outer = 0; K_inner_outer < 8; ++K_inner_outer) {
      float input0_shared_local[4];
      input0_shared_local[(0)] = input0_shared[((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer))];
      input0_shared_local[(1)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 128))];
      input0_shared_local[(2)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 256))];
      input0_shared_local[(3)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 384))];
      float input1_shared_local[2];
      input1_shared_local[(0)] = input1_shared[(((K_inner_outer * 32) + (((int)threadIdx.x) & 15)))];
      input1_shared_local[(1)] = input1_shared[((((K_inner_outer * 32) + (((int)threadIdx.x) & 15)) + 16))];
      float input2_shared_local[2];
      input2_shared_local[(0)] = input2_shared[((((int)threadIdx.x) & 15))];
      input2_shared_local[(1)] = input2_shared[(((((int)threadIdx.x) & 15) + 16))];
      output0_local[(0)] = (output0_local[(0)] + ((input0_shared_local[(0)] * input1_shared_local[(0)]) + (input2_shared_local[(0)] * 1.953125e-03f)));
      output0_local[(2)] = (output0_local[(2)] + ((input0_shared_local[(1)] * input1_shared_local[(0)]) + (input2_shared_local[(0)] * 1.953125e-03f)));
      output0_local[(4)] = (output0_local[(4)] + ((input0_shared_local[(2)] * input1_shared_local[(0)]) + (input2_shared_local[(0)] * 1.953125e-03f)));
      output0_local[(6)] = (output0_local[(6)] + ((input0_shared_local[(3)] * input1_shared_local[(0)]) + (input2_shared_local[(0)] * 1.953125e-03f)));
      output0_local[(1)] = (output0_local[(1)] + ((input0_shared_local[(0)] * input1_shared_local[(1)]) + (input2_shared_local[(1)] * 1.953125e-03f)));
      output0_local[(3)] = (output0_local[(3)] + ((input0_shared_local[(1)] * input1_shared_local[(1)]) + (input2_shared_local[(1)] * 1.953125e-03f)));
      output0_local[(5)] = (output0_local[(5)] + ((input0_shared_local[(2)] * input1_shared_local[(1)]) + (input2_shared_local[(1)] * 1.953125e-03f)));
      output0_local[(7)] = (output0_local[(7)] + ((input0_shared_local[(3)] * input1_shared_local[(1)]) + (input2_shared_local[(1)] * 1.953125e-03f)));
    }
  }
  output0[((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)))] = output0_local[(0)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 8192))] = output0_local[(2)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 16384))] = output0_local[(4)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 24576))] = output0_local[(6)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 16))] = output0_local[(1)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 8208))] = output0_local[(3)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 16400))] = output0_local[(5)];
  output0[(((((((((int)blockIdx.x) >> 4) * 32768) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 15) * 32)) + (((int)threadIdx.x) & 15)) + 24592))] = output0_local[(7)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 13482776721000.0, "TPR": 0.000123355}

[Antares] Average time cost / run = 0.000123355 sec, 4352.24 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 14274, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[B, N, K]*input1[B, K, M])], init=[], axis=[iter_var(K, range(min=0, ext=512))], where=(bool)1, value_index=0)], axis=[iter_var(B, range(min=0, ext=3)), iter_var(N, range(min=0, ext=1024)), iter_var(M, range(min=0, ext=512))], reduce_axis=[iter_var(K, range(min=0, ext=512))], tag=, attrs={})
[debug] is IODependent: True
found 10 results with threshold 0.0
[debug] config = {"0": "{\"tile\": [1, 128, 64], \"step\": [8]}", "1": "{\"tile\": [1, 8, 4], \"step\": [1]}", "2": "{\"tile\": [1, 1, 1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 128, 64], \"step\": [8]}", "1": "{\"tile\": [1, 8, 4], \"step\": [1]}", "2": "{\"tile\": [1, 1, 1], \"step\": [1]}"}
[debug] code gen tiling: {'B': [1, 1], 'N': [16, 8], 'M': [16, 4], 'K': [8, 1]}
[debug] adjusted tiling: {'B': [1, 1, 1], 'N': [8, 16, 1], 'M': [4, 16, 1], 'K': [8, 1]}
[debug] thread per block 256

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[3, 1024, 512], input1:float32[3, 512, 512] -> output0:float32[3, 1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[B, N, M] +=! input0[B, N, K] * input1[B, K, M]", input_dict={"input0": {"dtype": "float32", "shape": [3, 1024, 512]}, "input1": {"dtype": "float32", "shape": [3, 512, 512]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[3, 1024, 512], input1:float32[3, 512, 512] -> output0:float32[3, 1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(256) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 192
  // [thread_extent] threadIdx.x = 256
  float output0_local[32];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(8)] = 0.000000e+00f;
  output0_local[(12)] = 0.000000e+00f;
  output0_local[(16)] = 0.000000e+00f;
  output0_local[(20)] = 0.000000e+00f;
  output0_local[(24)] = 0.000000e+00f;
  output0_local[(28)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(9)] = 0.000000e+00f;
  output0_local[(13)] = 0.000000e+00f;
  output0_local[(17)] = 0.000000e+00f;
  output0_local[(21)] = 0.000000e+00f;
  output0_local[(25)] = 0.000000e+00f;
  output0_local[(29)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(10)] = 0.000000e+00f;
  output0_local[(14)] = 0.000000e+00f;
  output0_local[(18)] = 0.000000e+00f;
  output0_local[(22)] = 0.000000e+00f;
  output0_local[(26)] = 0.000000e+00f;
  output0_local[(30)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  output0_local[(11)] = 0.000000e+00f;
  output0_local[(15)] = 0.000000e+00f;
  output0_local[(19)] = 0.000000e+00f;
  output0_local[(23)] = 0.000000e+00f;
  output0_local[(27)] = 0.000000e+00f;
  output0_local[(31)] = 0.000000e+00f;
  for (int K_outer = 0; K_outer < 64; ++K_outer) {
    __shared__ float input0_shared[1024];
  // [thread_extent] threadIdx.x = 256
    __syncthreads();
    input0_shared[(((int)threadIdx.x))] = input0[((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)))];
    input0_shared[((((int)threadIdx.x) + 256))] = input0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 16384))];
    input0_shared[((((int)threadIdx.x) + 512))] = input0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 32768))];
    input0_shared[((((int)threadIdx.x) + 768))] = input0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 3) * 512)) + (K_outer * 8)) + (((int)threadIdx.x) & 7)) + 49152))];
    __shared__ float input1_shared[512];
  // [thread_extent] threadIdx.x = 256
    input1_shared[(((int)threadIdx.x))] = input1[(((((((((int)blockIdx.x) >> 6) * 262144) + (K_outer * 4096)) + ((((int)threadIdx.x) >> 6) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 63)))];
    input1_shared[((((int)threadIdx.x) + 256))] = input1[((((((((((int)blockIdx.x) >> 6) * 262144) + (K_outer * 4096)) + ((((int)threadIdx.x) >> 6) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 63)) + 2048))];
    __syncthreads();
    for (int K_inner_outer = 0; K_inner_outer < 8; ++K_inner_outer) {
      float input0_shared_local[8];
      input0_shared_local[(0)] = input0_shared[((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer))];
      input0_shared_local[(1)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 128))];
      input0_shared_local[(2)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 256))];
      input0_shared_local[(3)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 384))];
      input0_shared_local[(4)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 512))];
      input0_shared_local[(5)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 640))];
      input0_shared_local[(6)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 768))];
      input0_shared_local[(7)] = input0_shared[(((((((int)threadIdx.x) >> 4) * 8) + K_inner_outer) + 896))];
      float input1_shared_local[4];
      input1_shared_local[(0)] = input1_shared[(((K_inner_outer * 64) + (((int)threadIdx.x) & 15)))];
      input1_shared_local[(1)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 16))];
      input1_shared_local[(2)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 32))];
      input1_shared_local[(3)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 15)) + 48))];
      output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
      output0_local[(4)] = (output0_local[(4)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
      output0_local[(8)] = (output0_local[(8)] + (input0_shared_local[(2)] * input1_shared_local[(0)]));
      output0_local[(12)] = (output0_local[(12)] + (input0_shared_local[(3)] * input1_shared_local[(0)]));
      output0_local[(16)] = (output0_local[(16)] + (input0_shared_local[(4)] * input1_shared_local[(0)]));
      output0_local[(20)] = (output0_local[(20)] + (input0_shared_local[(5)] * input1_shared_local[(0)]));
      output0_local[(24)] = (output0_local[(24)] + (input0_shared_local[(6)] * input1_shared_local[(0)]));
      output0_local[(28)] = (output0_local[(28)] + (input0_shared_local[(7)] * input1_shared_local[(0)]));
      output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(0)] * input1_shared_local[(1)]));
      output0_local[(5)] = (output0_local[(5)] + (input0_shared_local[(1)] * input1_shared_local[(1)]));
      output0_local[(9)] = (output0_local[(9)] + (input0_shared_local[(2)] * input1_shared_local[(1)]));
      output0_local[(13)] = (output0_local[(13)] + (input0_shared_local[(3)] * input1_shared_local[(1)]));
      output0_local[(17)] = (output0_local[(17)] + (input0_shared_local[(4)] * input1_shared_local[(1)]));
      output0_local[(21)] = (output0_local[(21)] + (input0_shared_local[(5)] * input1_shared_local[(1)]));
      output0_local[(25)] = (output0_local[(25)] + (input0_shared_local[(6)] * input1_shared_local[(1)]));
      output0_local[(29)] = (output0_local[(29)] + (input0_shared_local[(7)] * input1_shared_local[(1)]));
      output0_local[(2)] = (output0_local[(2)] + (input0_shared_local[(0)] * input1_shared_local[(2)]));
      output0_local[(6)] = (output0_local[(6)] + (input0_shared_local[(1)] * input1_shared_local[(2)]));
      output0_local[(10)] = (output0_local[(10)] + (input0_shared_local[(2)] * input1_shared_local[(2)]));
      output0_local[(14)] = (output0_local[(14)] + (input0_shared_local[(3)] * input1_shared_local[(2)]));
      output0_local[(18)] = (output0_local[(18)] + (input0_shared_local[(4)] * input1_shared_local[(2)]));
      output0_local[(22)] = (output0_local[(22)] + (input0_shared_local[(5)] * input1_shared_local[(2)]));
      output0_local[(26)] = (output0_local[(26)] + (input0_shared_local[(6)] * input1_shared_local[(2)]));
      output0_local[(30)] = (output0_local[(30)] + (input0_shared_local[(7)] * input1_shared_local[(2)]));
      output0_local[(3)] = (output0_local[(3)] + (input0_shared_local[(0)] * input1_shared_local[(3)]));
      output0_local[(7)] = (output0_local[(7)] + (input0_shared_local[(1)] * input1_shared_local[(3)]));
      output0_local[(11)] = (output0_local[(11)] + (input0_shared_local[(2)] * input1_shared_local[(3)]));
      output0_local[(15)] = (output0_local[(15)] + (input0_shared_local[(3)] * input1_shared_local[(3)]));
      output0_local[(19)] = (output0_local[(19)] + (input0_shared_local[(4)] * input1_shared_local[(3)]));
      output0_local[(23)] = (output0_local[(23)] + (input0_shared_local[(5)] * input1_shared_local[(3)]));
      output0_local[(27)] = (output0_local[(27)] + (input0_shared_local[(6)] * input1_shared_local[(3)]));
      output0_local[(31)] = (output0_local[(31)] + (input0_shared_local[(7)] * input1_shared_local[(3)]));
    }
  }
  output0[((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)))] = output0_local[(0)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 8192))] = output0_local[(4)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 16384))] = output0_local[(8)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 24576))] = output0_local[(12)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 32768))] = output0_local[(16)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 40960))] = output0_local[(20)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 49152))] = output0_local[(24)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 57344))] = output0_local[(28)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 16))] = output0_local[(1)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 8208))] = output0_local[(5)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 16400))] = output0_local[(9)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 24592))] = output0_local[(13)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 32784))] = output0_local[(17)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 40976))] = output0_local[(21)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 49168))] = output0_local[(25)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 57360))] = output0_local[(29)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 32))] = output0_local[(2)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 8224))] = output0_local[(6)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 16416))] = output0_local[(10)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 24608))] = output0_local[(14)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 32800))] = output0_local[(18)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 40992))] = output0_local[(22)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 49184))] = output0_local[(26)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 57376))] = output0_local[(30)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 48))] = output0_local[(3)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 8240))] = output0_local[(7)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 16432))] = output0_local[(11)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 24624))] = output0_local[(15)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 32816))] = output0_local[(19)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 41008))] = output0_local[(23)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 49200))] = output0_local[(27)];
  output0[(((((((((int)blockIdx.x) >> 3) * 65536) + ((((int)threadIdx.x) >> 4) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 15)) + 57392))] = output0_local[(31)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 40446179111000.0, "TPR": 0.000428087}

[Antares] Average time cost / run = 0.000428087 sec, 3762.35 gflops. (Checked: True)

Finish MatMul\n
  >> Backend = c-cuda, Python PID = 14662, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[max(x, y)], lhs=[x], rhs=[y], identity_element=[-3.40282e+38f]), source=[input0[N, C, ((HO*2) + KH), ((WO*2) + KW)]], init=[], axis=[iter_var(KW, range(min=0, ext=2)), iter_var(KH, range(min=0, ext=2))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=32)), iter_var(C, range(min=0, ext=3)), iter_var(HO, range(min=0, ext=6)), iter_var(WO, range(min=0, ext=6))], reduce_axis=[iter_var(KW, range(min=0, ext=2)), iter_var(KH, range(min=0, ext=2))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
found 10 results in first round with threshold 0.4
[debug] config = {"0": "{\"tile\": [1, 1, 8, 8], \"step\": [2, 2]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 8, 8], \"step\": [2, 2]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1]}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [1, 1], 'HO': [8, 1], 'WO': [4, 2], 'KW': [2, 1], 'KH': [2, 1]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [1, 1, 1], 'HO': [1, 8, 1], 'WO': [2, 4, 1], 'KW': [2, 1], 'KH': [2, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 3, 12, 12] -> output0:float32[32, 3, 6, 6]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C, HO, WO] >=! input0[N, C, HO * 2 + KH, WO * 2 + KW] where HO in 6, WO in 6, KW in 2, KH in 2", input_dict={"input0": {"dtype": "float32", "shape": [32, 3, 12, 12]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 3, 12, 12] -> output0:float32[32, 3, 6, 6]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 96
  // [thread_extent] threadIdx.x = 32
  float output0_local[2];
  output0_local[(0)] = -3.402823e+38f;
  output0_local[(1)] = -3.402823e+38f;
  __shared__ float input0_shared[144];
  // [thread_extent] threadIdx.x = 32
  input0_shared[(((int)threadIdx.x))] = input0[(((((int)blockIdx.x) * 144) + ((int)threadIdx.x)))];
  input0_shared[((((int)threadIdx.x) + 32))] = input0[((((((int)blockIdx.x) * 144) + ((int)threadIdx.x)) + 32))];
  input0_shared[((((int)threadIdx.x) + 64))] = input0[((((((int)blockIdx.x) * 144) + ((int)threadIdx.x)) + 64))];
  input0_shared[((((int)threadIdx.x) + 96))] = input0[((((((int)blockIdx.x) * 144) + ((int)threadIdx.x)) + 96))];
  if (((int)threadIdx.x) < 16) {
    input0_shared[((((int)threadIdx.x) + 128))] = input0[((((((int)blockIdx.x) * 144) + ((int)threadIdx.x)) + 128))];
  }
  __syncthreads();
  for (int KW_inner_outer = 0; KW_inner_outer < 2; ++KW_inner_outer) {
    for (int KH_inner_outer = 0; KH_inner_outer < 2; ++KH_inner_outer) {
      float input0_shared_local[2];
      if ((((((int)threadIdx.x) >> 2) * 2) + KH_inner_outer) < 12) {
        input0_shared_local[(0)] = input0_shared[((((((((int)threadIdx.x) >> 2) * 24) + (KH_inner_outer * 12)) + ((((int)threadIdx.x) & 3) * 2)) + KW_inner_outer))];
        if ((((((int)threadIdx.x) & 3) * 2) + KW_inner_outer) < 4) {
          input0_shared_local[(1)] = input0_shared[(((((((((int)threadIdx.x) >> 2) * 24) + (KH_inner_outer * 12)) + ((((int)threadIdx.x) & 3) * 2)) + KW_inner_outer) + 8))];
        }
      }
      if (((int)threadIdx.x) < 24) {
        output0_local[(0)] = max(output0_local[(0)], input0_shared_local[(0)]);
        if ((((int)threadIdx.x) & 3) < 2) {
          output0_local[(1)] = max(output0_local[(1)], input0_shared_local[(1)]);
        }
      }
    }
  }
  if (((int)threadIdx.x) < 24) {
    output0[((((((int)blockIdx.x) * 36) + ((((int)threadIdx.x) >> 2) * 6)) + (((int)threadIdx.x) & 3)))] = output0_local[(0)];
    if ((((int)threadIdx.x) & 3) < 2) {
      output0[(((((((int)blockIdx.x) * 36) + ((((int)threadIdx.x) >> 2) * 6)) + (((int)threadIdx.x) & 3)) + 4))] = output0_local[(1)];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 6465546.0, "TPR": 4.83844e-06}

[Antares] Average time cost / run = 4.83844e-06 sec, 5.71424 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 15329, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[NC, ((HO*3) + KH), ((WO*3) + KW)]/9f)], init=[], axis=[iter_var(KW, range(min=0, ext=3)), iter_var(KH, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(NC, range(min=0, ext=1024)), iter_var(HO, range(min=0, ext=85)), iter_var(WO, range(min=0, ext=85))], reduce_axis=[iter_var(KW, range(min=0, ext=3)), iter_var(KH, range(min=0, ext=3))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
found 10 results in first round with threshold 0.1
[debug] config = {"0": "{\"tile\": [1, 8, 88], \"step\": [3, 3]}", "1": "{\"tile\": [1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1], \"step\": [1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 8, 88], \"step\": [3, 3]}", "1": "{\"tile\": [1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1], \"step\": [1, 1]}"}
[debug] code gen tiling: {'NC': [1, 1], 'HO': [8, 1], 'WO': [44, 2], 'KW': [3, 1], 'KH': [3, 1]}
[debug] adjusted tiling: {'NC': [1, 1, 1], 'HO': [1, 8, 1], 'WO': [2, 44, 1], 'KW': [3, 1], 'KH': [3, 1]}
[debug] thread per block 352

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 255, 255] -> output0:float32[1024, 85, 85]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[NC, HO, WO] +=! input0[NC, HO * 3 + KH, WO * 3 + KW] / 9.0 where HO in 85, WO in 85, KW in 3, KH in 3", input_dict={"input0": {"dtype": "float32", "shape": [1024, 255, 255]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 255, 255] -> output0:float32[1024, 85, 85]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(352) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 11264
  // [thread_extent] threadIdx.x = 352
  float output0_local[2];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  __shared__ float input0_shared[6120];
  // [thread_extent] threadIdx.x = 352
  input0_shared[(((int)threadIdx.x))] = input0[(((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)))];
  input0_shared[((((int)threadIdx.x) + 352))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 352))];
  input0_shared[((((int)threadIdx.x) + 704))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 704))];
  input0_shared[((((int)threadIdx.x) + 1056))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 1056))];
  input0_shared[((((int)threadIdx.x) + 1408))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 1408))];
  input0_shared[((((int)threadIdx.x) + 1760))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 1760))];
  input0_shared[((((int)threadIdx.x) + 2112))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 2112))];
  input0_shared[((((int)threadIdx.x) + 2464))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 2464))];
  input0_shared[((((int)threadIdx.x) + 2816))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 2816))];
  input0_shared[((((int)threadIdx.x) + 3168))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 3168))];
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 3520) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 3520))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 3520))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 3872) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 3872))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 3872))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 4224) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 4224))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 4224))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 4576) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 4576))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 4576))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 4928) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 4928))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 4928))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 5280) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 5280))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 5280))];
  }
  if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 5632) / 255)) < 255) {
    input0_shared[((((int)threadIdx.x) + 5632))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 5632))];
  }
  if (((int)threadIdx.x) < 136) {
    if ((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) + 5984) / 255)) < 255) {
      input0_shared[((((int)threadIdx.x) + 5984))] = input0[((((((((int)blockIdx.x) / 11) * 65025) + ((((int)blockIdx.x) % 11) * 6120)) + ((int)threadIdx.x)) + 5984))];
    }
  }
  __syncthreads();
  for (int KW_inner_outer = 0; KW_inner_outer < 3; ++KW_inner_outer) {
    for (int KH_inner_outer = 0; KH_inner_outer < 3; ++KH_inner_outer) {
      float input0_shared_local[2];
      if (((((((int)blockIdx.x) % 11) * 24) + ((((int)threadIdx.x) / 44) * 3)) + KH_inner_outer) < 255) {
        input0_shared_local[(0)] = input0_shared[((((((((int)threadIdx.x) / 44) * 765) + (KH_inner_outer * 255)) + ((((int)threadIdx.x) % 44) * 3)) + KW_inner_outer))];
        if ((((((int)threadIdx.x) % 44) * 3) + KW_inner_outer) < 123) {
          input0_shared_local[(1)] = input0_shared[(((((((((int)threadIdx.x) / 44) * 765) + (KH_inner_outer * 255)) + ((((int)threadIdx.x) % 44) * 3)) + KW_inner_outer) + 132))];
        }
      }
      if ((((((int)blockIdx.x) % 11) * 8) + (((int)threadIdx.x) / 44)) < 85) {
        output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * 1.111111e-01f));
        if ((((int)threadIdx.x) % 44) < 41) {
          output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(1)] * 1.111111e-01f));
        }
      }
    }
  }
  if ((((((int)blockIdx.x) % 11) * 8) + (((int)threadIdx.x) / 44)) < 85) {
    output0[((((((((int)blockIdx.x) / 11) * 7225) + ((((int)blockIdx.x) % 11) * 680)) + ((((int)threadIdx.x) / 44) * 85)) + (((int)threadIdx.x) % 44)))] = output0_local[(0)];
    if ((((int)threadIdx.x) % 44) < 41) {
      output0[(((((((((int)blockIdx.x) / 11) * 7225) + ((((int)blockIdx.x) % 11) * 680)) + ((((int)threadIdx.x) / 44) * 85)) + (((int)threadIdx.x) % 44)) + 44))] = output0_local[(1)];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 10616673488.0, "TPR": 0.000371683}

[Antares] Average time cost / run = 0.000371683 sec, 358.292 gflops. (Checked: True)

Finish Pool\n
  >> Backend = c-cuda, Python PID = 15838, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[input0[N, C]], init=[], axis=[iter_var(C, range(min=0, ext=1024))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=32))], reduce_axis=[iter_var(C, range(min=0, ext=1024))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
found 3 results in first round with threshold 1.0
found 3 results in first round with threshold 1.1
found 3 results in first round with threshold 1.2
found 3 results in first round with threshold 1.3
found 3 results in first round with threshold 1.4
found 3 results in first round with threshold 1.5
found 3 results in first round with threshold 1.6
found 3 results in first round with threshold 1.7
found 3 results in first round with threshold 1.8
found 3 results in first round with threshold 1.9
found 3 results in first round with threshold 2.0
found 3 results in first round with threshold 2.1
found 3 results in first round with threshold 2.2
found 3 results in first round with threshold 2.3
found 3 results in first round with threshold 2.4
found 3 results in first round with threshold 2.5
found 3 results in first round with threshold 2.6
found 3 results in first round with threshold 2.7
found 3 results in first round with threshold 2.8
found 3 results in first round with threshold 2.9
found 7 results in first round with threshold 3.0
found 7 results in first round with threshold 3.1
found 7 results in first round with threshold 3.2
found 7 results in first round with threshold 3.3
found 7 results in first round with threshold 3.4
found 7 results in first round with threshold 3.5
found 7 results in first round with threshold 3.6
found 7 results in first round with threshold 3.7
found 7 results in first round with threshold 3.8
found 7 results in first round with threshold 3.9
[debug] config = {"0": "{\"tile\": [64], \"step\": [128]}", "1": "{\"tile\": [2], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": [128]}", "1": "{\"tile\": [2], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] code gen tiling: {'N': [32, 2], 'C': [128, 1]}
[debug] adjusted tiling: {'N': [2, 32, 1], 'C': [128, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 1024] -> output0:float32[32]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] +=! input0[N, C]", input_dict={"input0": {"dtype": "float32", "shape": [32, 1024]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 1024] -> output0:float32[32]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 32
  float output0_local[2];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  for (int C_outer = 0; C_outer < 8; ++C_outer) {
    __shared__ float input0_shared[4096];
  // [thread_extent] threadIdx.x = 32
    __syncthreads();
    input0_shared[(((int)threadIdx.x))] = input0[(((C_outer * 128) + ((int)threadIdx.x)))];
    input0_shared[((((int)threadIdx.x) + 32))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 32))];
    input0_shared[((((int)threadIdx.x) + 64))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 64))];
    input0_shared[((((int)threadIdx.x) + 96))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 96))];
    input0_shared[((((int)threadIdx.x) + 128))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 1024))];
    input0_shared[((((int)threadIdx.x) + 160))] = input0[((((((((int)threadIdx.x) + 160) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 192))] = input0[((((((((int)threadIdx.x) + 192) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 224))] = input0[((((((((int)threadIdx.x) + 224) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 256))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 2048))];
    input0_shared[((((int)threadIdx.x) + 288))] = input0[((((((((int)threadIdx.x) + 288) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 320))] = input0[((((((((int)threadIdx.x) + 320) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 352))] = input0[((((((((int)threadIdx.x) + 352) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 384))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 3072))];
    input0_shared[((((int)threadIdx.x) + 416))] = input0[((((((((int)threadIdx.x) + 416) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 448))] = input0[((((((((int)threadIdx.x) + 448) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 480))] = input0[((((((((int)threadIdx.x) + 480) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 512))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 4096))];
    input0_shared[((((int)threadIdx.x) + 544))] = input0[((((((((int)threadIdx.x) + 544) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 576))] = input0[((((((((int)threadIdx.x) + 576) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 608))] = input0[((((((((int)threadIdx.x) + 608) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 640))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 5120))];
    input0_shared[((((int)threadIdx.x) + 672))] = input0[((((((((int)threadIdx.x) + 672) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 704))] = input0[((((((((int)threadIdx.x) + 704) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 736))] = input0[((((((((int)threadIdx.x) + 736) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 768))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 6144))];
    input0_shared[((((int)threadIdx.x) + 800))] = input0[((((((((int)threadIdx.x) + 800) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 832))] = input0[((((((((int)threadIdx.x) + 832) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 864))] = input0[((((((((int)threadIdx.x) + 864) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 896))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 7168))];
    input0_shared[((((int)threadIdx.x) + 928))] = input0[((((((((int)threadIdx.x) + 928) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 960))] = input0[((((((((int)threadIdx.x) + 960) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 992))] = input0[((((((((int)threadIdx.x) + 992) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1024))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 8192))];
    input0_shared[((((int)threadIdx.x) + 1056))] = input0[((((((((int)threadIdx.x) + 1056) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1088))] = input0[((((((((int)threadIdx.x) + 1088) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1120))] = input0[((((((((int)threadIdx.x) + 1120) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1152))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 9216))];
    input0_shared[((((int)threadIdx.x) + 1184))] = input0[((((((((int)threadIdx.x) + 1184) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1216))] = input0[((((((((int)threadIdx.x) + 1216) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1248))] = input0[((((((((int)threadIdx.x) + 1248) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1280))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 10240))];
    input0_shared[((((int)threadIdx.x) + 1312))] = input0[((((((((int)threadIdx.x) + 1312) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1344))] = input0[((((((((int)threadIdx.x) + 1344) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1376))] = input0[((((((((int)threadIdx.x) + 1376) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1408))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 11264))];
    input0_shared[((((int)threadIdx.x) + 1440))] = input0[((((((((int)threadIdx.x) + 1440) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1472))] = input0[((((((((int)threadIdx.x) + 1472) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1504))] = input0[((((((((int)threadIdx.x) + 1504) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1536))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 12288))];
    input0_shared[((((int)threadIdx.x) + 1568))] = input0[((((((((int)threadIdx.x) + 1568) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1600))] = input0[((((((((int)threadIdx.x) + 1600) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1632))] = input0[((((((((int)threadIdx.x) + 1632) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1664))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 13312))];
    input0_shared[((((int)threadIdx.x) + 1696))] = input0[((((((((int)threadIdx.x) + 1696) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1728))] = input0[((((((((int)threadIdx.x) + 1728) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1760))] = input0[((((((((int)threadIdx.x) + 1760) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1792))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 14336))];
    input0_shared[((((int)threadIdx.x) + 1824))] = input0[((((((((int)threadIdx.x) + 1824) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1856))] = input0[((((((((int)threadIdx.x) + 1856) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1888))] = input0[((((((((int)threadIdx.x) + 1888) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1920))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 15360))];
    input0_shared[((((int)threadIdx.x) + 1952))] = input0[((((((((int)threadIdx.x) + 1952) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1984))] = input0[((((((((int)threadIdx.x) + 1984) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2016))] = input0[((((((((int)threadIdx.x) + 2016) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2048))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 16384))];
    input0_shared[((((int)threadIdx.x) + 2080))] = input0[((((((((int)threadIdx.x) + 2080) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2112))] = input0[((((((((int)threadIdx.x) + 2112) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2144))] = input0[((((((((int)threadIdx.x) + 2144) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2176))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 17408))];
    input0_shared[((((int)threadIdx.x) + 2208))] = input0[((((((((int)threadIdx.x) + 2208) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2240))] = input0[((((((((int)threadIdx.x) + 2240) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2272))] = input0[((((((((int)threadIdx.x) + 2272) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2304))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 18432))];
    input0_shared[((((int)threadIdx.x) + 2336))] = input0[((((((((int)threadIdx.x) + 2336) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2368))] = input0[((((((((int)threadIdx.x) + 2368) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2400))] = input0[((((((((int)threadIdx.x) + 2400) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2432))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 19456))];
    input0_shared[((((int)threadIdx.x) + 2464))] = input0[((((((((int)threadIdx.x) + 2464) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2496))] = input0[((((((((int)threadIdx.x) + 2496) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2528))] = input0[((((((((int)threadIdx.x) + 2528) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2560))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 20480))];
    input0_shared[((((int)threadIdx.x) + 2592))] = input0[((((((((int)threadIdx.x) + 2592) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2624))] = input0[((((((((int)threadIdx.x) + 2624) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2656))] = input0[((((((((int)threadIdx.x) + 2656) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2688))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 21504))];
    input0_shared[((((int)threadIdx.x) + 2720))] = input0[((((((((int)threadIdx.x) + 2720) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2752))] = input0[((((((((int)threadIdx.x) + 2752) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2784))] = input0[((((((((int)threadIdx.x) + 2784) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2816))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 22528))];
    input0_shared[((((int)threadIdx.x) + 2848))] = input0[((((((((int)threadIdx.x) + 2848) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2880))] = input0[((((((((int)threadIdx.x) + 2880) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2912))] = input0[((((((((int)threadIdx.x) + 2912) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2944))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 23552))];
    input0_shared[((((int)threadIdx.x) + 2976))] = input0[((((((((int)threadIdx.x) + 2976) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3008))] = input0[((((((((int)threadIdx.x) + 3008) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3040))] = input0[((((((((int)threadIdx.x) + 3040) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3072))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 24576))];
    input0_shared[((((int)threadIdx.x) + 3104))] = input0[((((((((int)threadIdx.x) + 3104) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3136))] = input0[((((((((int)threadIdx.x) + 3136) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3168))] = input0[((((((((int)threadIdx.x) + 3168) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3200))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 25600))];
    input0_shared[((((int)threadIdx.x) + 3232))] = input0[((((((((int)threadIdx.x) + 3232) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3264))] = input0[((((((((int)threadIdx.x) + 3264) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3296))] = input0[((((((((int)threadIdx.x) + 3296) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3328))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 26624))];
    input0_shared[((((int)threadIdx.x) + 3360))] = input0[((((((((int)threadIdx.x) + 3360) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3392))] = input0[((((((((int)threadIdx.x) + 3392) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3424))] = input0[((((((((int)threadIdx.x) + 3424) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3456))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 27648))];
    input0_shared[((((int)threadIdx.x) + 3488))] = input0[((((((((int)threadIdx.x) + 3488) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3520))] = input0[((((((((int)threadIdx.x) + 3520) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3552))] = input0[((((((((int)threadIdx.x) + 3552) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3584))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 28672))];
    input0_shared[((((int)threadIdx.x) + 3616))] = input0[((((((((int)threadIdx.x) + 3616) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3648))] = input0[((((((((int)threadIdx.x) + 3648) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3680))] = input0[((((((((int)threadIdx.x) + 3680) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3712))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 29696))];
    input0_shared[((((int)threadIdx.x) + 3744))] = input0[((((((((int)threadIdx.x) + 3744) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3776))] = input0[((((((((int)threadIdx.x) + 3776) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3808))] = input0[((((((((int)threadIdx.x) + 3808) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3840))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 30720))];
    input0_shared[((((int)threadIdx.x) + 3872))] = input0[((((((((int)threadIdx.x) + 3872) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3904))] = input0[((((((((int)threadIdx.x) + 3904) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3936))] = input0[((((((((int)threadIdx.x) + 3936) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3968))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 31744))];
    input0_shared[((((int)threadIdx.x) + 4000))] = input0[((((((((int)threadIdx.x) + 4000) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 4032))] = input0[((((((((int)threadIdx.x) + 4032) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 4064))] = input0[((((((((int)threadIdx.x) + 4064) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    __syncthreads();
    for (int C_inner_outer = 0; C_inner_outer < 128; ++C_inner_outer) {
      float input0_shared_local[2];
      input0_shared_local[(0)] = input0_shared[(((((int)threadIdx.x) * 128) + C_inner_outer))];
      output0_local[(0)] = (output0_local[(0)] + input0_shared_local[(0)]);
    }
  }
  output0[(((int)threadIdx.x))] = output0_local[(0)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 18916612.0, "TPR": 2.47415e-05}

[Antares] Average time cost / run = 2.47415e-05 sec, 2.64883 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 17490, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[input0[N, C]], init=[], axis=[iter_var(C, range(min=0, ext=1024))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=32))], reduce_axis=[iter_var(C, range(min=0, ext=1024))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
failed to find results with padding threshold 0.1
failed to find results with padding threshold 0.2
failed to find results with padding threshold 0.3
failed to find results with padding threshold 0.4
failed to find results with padding threshold 0.5
failed to find results with padding threshold 0.6
failed to find results with padding threshold 0.7
failed to find results with padding threshold 0.8
failed to find results with padding threshold 0.9
found 3 results in first round with threshold 1.0
found 3 results in first round with threshold 1.1
found 3 results in first round with threshold 1.2
found 3 results in first round with threshold 1.3
found 3 results in first round with threshold 1.4
found 3 results in first round with threshold 1.5
found 3 results in first round with threshold 1.6
found 3 results in first round with threshold 1.7
found 3 results in first round with threshold 1.8
found 3 results in first round with threshold 1.9
found 3 results in first round with threshold 2.0
found 3 results in first round with threshold 2.1
found 3 results in first round with threshold 2.2
found 3 results in first round with threshold 2.3
found 3 results in first round with threshold 2.4
found 3 results in first round with threshold 2.5
found 3 results in first round with threshold 2.6
found 3 results in first round with threshold 2.7
found 3 results in first round with threshold 2.8
found 3 results in first round with threshold 2.9
found 7 results in first round with threshold 3.0
found 7 results in first round with threshold 3.1
found 7 results in first round with threshold 3.2
found 7 results in first round with threshold 3.3
found 7 results in first round with threshold 3.4
found 7 results in first round with threshold 3.5
found 7 results in first round with threshold 3.6
found 7 results in first round with threshold 3.7
found 7 results in first round with threshold 3.8
found 7 results in first round with threshold 3.9
[debug] config = {"0": "{\"tile\": [64], \"step\": [128]}", "1": "{\"tile\": [2], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [64], \"step\": [128]}", "1": "{\"tile\": [2], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] code gen tiling: {'N': [32, 2], 'C': [128, 1]}
[debug] adjusted tiling: {'N': [2, 32, 1], 'C': [128, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 1024] -> output0:float32[32]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N] +=! input0[N, C]", input_dict={"input0": {"dtype": "float32", "shape": [32, 1024]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 1024] -> output0:float32[32]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 32
  float output0_local[2];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  for (int C_outer = 0; C_outer < 8; ++C_outer) {
    __shared__ float input0_shared[4096];
  // [thread_extent] threadIdx.x = 32
    __syncthreads();
    input0_shared[(((int)threadIdx.x))] = input0[(((C_outer * 128) + ((int)threadIdx.x)))];
    input0_shared[((((int)threadIdx.x) + 32))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 32))];
    input0_shared[((((int)threadIdx.x) + 64))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 64))];
    input0_shared[((((int)threadIdx.x) + 96))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 96))];
    input0_shared[((((int)threadIdx.x) + 128))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 1024))];
    input0_shared[((((int)threadIdx.x) + 160))] = input0[((((((((int)threadIdx.x) + 160) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 192))] = input0[((((((((int)threadIdx.x) + 192) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 224))] = input0[((((((((int)threadIdx.x) + 224) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 256))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 2048))];
    input0_shared[((((int)threadIdx.x) + 288))] = input0[((((((((int)threadIdx.x) + 288) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 320))] = input0[((((((((int)threadIdx.x) + 320) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 352))] = input0[((((((((int)threadIdx.x) + 352) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 384))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 3072))];
    input0_shared[((((int)threadIdx.x) + 416))] = input0[((((((((int)threadIdx.x) + 416) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 448))] = input0[((((((((int)threadIdx.x) + 448) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 480))] = input0[((((((((int)threadIdx.x) + 480) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 512))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 4096))];
    input0_shared[((((int)threadIdx.x) + 544))] = input0[((((((((int)threadIdx.x) + 544) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 576))] = input0[((((((((int)threadIdx.x) + 576) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 608))] = input0[((((((((int)threadIdx.x) + 608) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 640))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 5120))];
    input0_shared[((((int)threadIdx.x) + 672))] = input0[((((((((int)threadIdx.x) + 672) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 704))] = input0[((((((((int)threadIdx.x) + 704) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 736))] = input0[((((((((int)threadIdx.x) + 736) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 768))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 6144))];
    input0_shared[((((int)threadIdx.x) + 800))] = input0[((((((((int)threadIdx.x) + 800) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 832))] = input0[((((((((int)threadIdx.x) + 832) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 864))] = input0[((((((((int)threadIdx.x) + 864) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 896))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 7168))];
    input0_shared[((((int)threadIdx.x) + 928))] = input0[((((((((int)threadIdx.x) + 928) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 960))] = input0[((((((((int)threadIdx.x) + 960) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 992))] = input0[((((((((int)threadIdx.x) + 992) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1024))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 8192))];
    input0_shared[((((int)threadIdx.x) + 1056))] = input0[((((((((int)threadIdx.x) + 1056) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1088))] = input0[((((((((int)threadIdx.x) + 1088) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1120))] = input0[((((((((int)threadIdx.x) + 1120) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1152))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 9216))];
    input0_shared[((((int)threadIdx.x) + 1184))] = input0[((((((((int)threadIdx.x) + 1184) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1216))] = input0[((((((((int)threadIdx.x) + 1216) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1248))] = input0[((((((((int)threadIdx.x) + 1248) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1280))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 10240))];
    input0_shared[((((int)threadIdx.x) + 1312))] = input0[((((((((int)threadIdx.x) + 1312) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1344))] = input0[((((((((int)threadIdx.x) + 1344) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1376))] = input0[((((((((int)threadIdx.x) + 1376) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1408))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 11264))];
    input0_shared[((((int)threadIdx.x) + 1440))] = input0[((((((((int)threadIdx.x) + 1440) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1472))] = input0[((((((((int)threadIdx.x) + 1472) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1504))] = input0[((((((((int)threadIdx.x) + 1504) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1536))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 12288))];
    input0_shared[((((int)threadIdx.x) + 1568))] = input0[((((((((int)threadIdx.x) + 1568) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1600))] = input0[((((((((int)threadIdx.x) + 1600) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1632))] = input0[((((((((int)threadIdx.x) + 1632) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1664))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 13312))];
    input0_shared[((((int)threadIdx.x) + 1696))] = input0[((((((((int)threadIdx.x) + 1696) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1728))] = input0[((((((((int)threadIdx.x) + 1728) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1760))] = input0[((((((((int)threadIdx.x) + 1760) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1792))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 14336))];
    input0_shared[((((int)threadIdx.x) + 1824))] = input0[((((((((int)threadIdx.x) + 1824) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1856))] = input0[((((((((int)threadIdx.x) + 1856) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 1888))] = input0[((((((((int)threadIdx.x) + 1888) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 1920))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 15360))];
    input0_shared[((((int)threadIdx.x) + 1952))] = input0[((((((((int)threadIdx.x) + 1952) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 1984))] = input0[((((((((int)threadIdx.x) + 1984) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2016))] = input0[((((((((int)threadIdx.x) + 2016) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2048))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 16384))];
    input0_shared[((((int)threadIdx.x) + 2080))] = input0[((((((((int)threadIdx.x) + 2080) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2112))] = input0[((((((((int)threadIdx.x) + 2112) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2144))] = input0[((((((((int)threadIdx.x) + 2144) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2176))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 17408))];
    input0_shared[((((int)threadIdx.x) + 2208))] = input0[((((((((int)threadIdx.x) + 2208) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2240))] = input0[((((((((int)threadIdx.x) + 2240) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2272))] = input0[((((((((int)threadIdx.x) + 2272) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2304))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 18432))];
    input0_shared[((((int)threadIdx.x) + 2336))] = input0[((((((((int)threadIdx.x) + 2336) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2368))] = input0[((((((((int)threadIdx.x) + 2368) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2400))] = input0[((((((((int)threadIdx.x) + 2400) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2432))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 19456))];
    input0_shared[((((int)threadIdx.x) + 2464))] = input0[((((((((int)threadIdx.x) + 2464) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2496))] = input0[((((((((int)threadIdx.x) + 2496) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2528))] = input0[((((((((int)threadIdx.x) + 2528) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2560))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 20480))];
    input0_shared[((((int)threadIdx.x) + 2592))] = input0[((((((((int)threadIdx.x) + 2592) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2624))] = input0[((((((((int)threadIdx.x) + 2624) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2656))] = input0[((((((((int)threadIdx.x) + 2656) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2688))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 21504))];
    input0_shared[((((int)threadIdx.x) + 2720))] = input0[((((((((int)threadIdx.x) + 2720) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2752))] = input0[((((((((int)threadIdx.x) + 2752) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2784))] = input0[((((((((int)threadIdx.x) + 2784) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2816))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 22528))];
    input0_shared[((((int)threadIdx.x) + 2848))] = input0[((((((((int)threadIdx.x) + 2848) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 2880))] = input0[((((((((int)threadIdx.x) + 2880) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 2912))] = input0[((((((((int)threadIdx.x) + 2912) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 2944))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 23552))];
    input0_shared[((((int)threadIdx.x) + 2976))] = input0[((((((((int)threadIdx.x) + 2976) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3008))] = input0[((((((((int)threadIdx.x) + 3008) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3040))] = input0[((((((((int)threadIdx.x) + 3040) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3072))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 24576))];
    input0_shared[((((int)threadIdx.x) + 3104))] = input0[((((((((int)threadIdx.x) + 3104) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3136))] = input0[((((((((int)threadIdx.x) + 3136) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3168))] = input0[((((((((int)threadIdx.x) + 3168) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3200))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 25600))];
    input0_shared[((((int)threadIdx.x) + 3232))] = input0[((((((((int)threadIdx.x) + 3232) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3264))] = input0[((((((((int)threadIdx.x) + 3264) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3296))] = input0[((((((((int)threadIdx.x) + 3296) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3328))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 26624))];
    input0_shared[((((int)threadIdx.x) + 3360))] = input0[((((((((int)threadIdx.x) + 3360) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3392))] = input0[((((((((int)threadIdx.x) + 3392) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3424))] = input0[((((((((int)threadIdx.x) + 3424) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3456))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 27648))];
    input0_shared[((((int)threadIdx.x) + 3488))] = input0[((((((((int)threadIdx.x) + 3488) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3520))] = input0[((((((((int)threadIdx.x) + 3520) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3552))] = input0[((((((((int)threadIdx.x) + 3552) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3584))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 28672))];
    input0_shared[((((int)threadIdx.x) + 3616))] = input0[((((((((int)threadIdx.x) + 3616) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3648))] = input0[((((((((int)threadIdx.x) + 3648) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3680))] = input0[((((((((int)threadIdx.x) + 3680) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3712))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 29696))];
    input0_shared[((((int)threadIdx.x) + 3744))] = input0[((((((((int)threadIdx.x) + 3744) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3776))] = input0[((((((((int)threadIdx.x) + 3776) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3808))] = input0[((((((((int)threadIdx.x) + 3808) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3840))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 30720))];
    input0_shared[((((int)threadIdx.x) + 3872))] = input0[((((((((int)threadIdx.x) + 3872) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 3904))] = input0[((((((((int)threadIdx.x) + 3904) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 3936))] = input0[((((((((int)threadIdx.x) + 3936) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    input0_shared[((((int)threadIdx.x) + 3968))] = input0[((((C_outer * 128) + ((int)threadIdx.x)) + 31744))];
    input0_shared[((((int)threadIdx.x) + 4000))] = input0[((((((((int)threadIdx.x) + 4000) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 32)))];
    input0_shared[((((int)threadIdx.x) + 4032))] = input0[((((((((int)threadIdx.x) + 4032) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 64)))];
    input0_shared[((((int)threadIdx.x) + 4064))] = input0[((((((((int)threadIdx.x) + 4064) >> 7) * 1024) + (C_outer * 128)) + (((int)threadIdx.x) + 96)))];
    __syncthreads();
    for (int C_inner_outer = 0; C_inner_outer < 128; ++C_inner_outer) {
      float input0_shared_local[2];
      input0_shared_local[(0)] = input0_shared[(((((int)threadIdx.x) * 128) + C_inner_outer))];
      output0_local[(0)] = (output0_local[(0)] + input0_shared_local[(0)]);
    }
  }
  output0[(((int)threadIdx.x))] = output0_local[(0)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 18916612.0, "TPR": 2.47065e-05}

[Antares] Average time cost / run = 2.47065e-05 sec, 2.65258 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 18738, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[N]*input1[N])], init=[], axis=[iter_var(N, range(min=0, ext=1024))], where=(bool)1, value_index=0)], axis=[iter_var(I0, range(min=0, ext=1))], reduce_axis=[iter_var(N, range(min=0, ext=1024))], tag=, attrs={})
[debug] is IODependent: False
found 3 results in first round with threshold 0.0
found 3 results in first round with threshold 0.1
found 3 results in first round with threshold 0.2
found 3 results in first round with threshold 0.3
found 3 results in first round with threshold 0.4
found 3 results in first round with threshold 0.5
found 3 results in first round with threshold 0.6
found 3 results in first round with threshold 0.7
found 3 results in first round with threshold 0.8
found 3 results in first round with threshold 0.9
found 6 results in first round with threshold 1.0
found 6 results in first round with threshold 1.1
found 6 results in first round with threshold 1.2
found 6 results in first round with threshold 1.3
found 6 results in first round with threshold 1.4
found 6 results in first round with threshold 1.5
found 6 results in first round with threshold 1.6
found 6 results in first round with threshold 1.7
found 6 results in first round with threshold 1.8
found 6 results in first round with threshold 1.9
found 6 results in first round with threshold 2.0
found 6 results in first round with threshold 2.1
found 6 results in first round with threshold 2.2
found 6 results in first round with threshold 2.3
found 6 results in first round with threshold 2.4
found 6 results in first round with threshold 2.5
found 6 results in first round with threshold 2.6
found 6 results in first round with threshold 2.7
found 6 results in first round with threshold 2.8
found 6 results in first round with threshold 2.9
found 9 results in first round with threshold 3.0
found 9 results in first round with threshold 3.1
found 9 results in first round with threshold 3.2
found 9 results in first round with threshold 3.3
found 9 results in first round with threshold 3.4
found 9 results in first round with threshold 3.5
found 9 results in first round with threshold 3.6
found 9 results in first round with threshold 3.7
found 9 results in first round with threshold 3.8
found 9 results in first round with threshold 3.9
[debug] config = {"0": "{\"tile\": [1], \"step\": [32]}", "1": "{\"tile\": [1], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1], \"step\": [32]}", "1": "{\"tile\": [1], \"step\": [1]}", "2": "{\"tile\": [1], \"step\": [1]}"}
[debug] code gen tiling: {'I0': [1, 1], 'N': [32, 1]}
[debug] adjusted tiling: {'I0': [1, 1, 1], 'N': [32, 1]}
[debug] thread per block 1

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024], input1:float32[1024] -> output0:float32[1]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[] +=! input0[N] * input1[N]", input_dict={"input0": {"dtype": "float32", "shape": [1024]}, "input1": {"dtype": "float32", "shape": [1024]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024], input1:float32[1024] -> output0:float32[1]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(1) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 1
  float output0_local[1];
  output0_local[(0)] = 0.000000e+00f;
  for (int N_outer = 0; N_outer < 32; ++N_outer) {
    __shared__ float input0_shared[32];
  // [thread_extent] threadIdx.x = 1
    __syncthreads();
    input0_shared[(0)] = input0[((N_outer * 32))];
    input0_shared[(1)] = input0[(((N_outer * 32) + 1))];
    input0_shared[(2)] = input0[(((N_outer * 32) + 2))];
    input0_shared[(3)] = input0[(((N_outer * 32) + 3))];
    input0_shared[(4)] = input0[(((N_outer * 32) + 4))];
    input0_shared[(5)] = input0[(((N_outer * 32) + 5))];
    input0_shared[(6)] = input0[(((N_outer * 32) + 6))];
    input0_shared[(7)] = input0[(((N_outer * 32) + 7))];
    input0_shared[(8)] = input0[(((N_outer * 32) + 8))];
    input0_shared[(9)] = input0[(((N_outer * 32) + 9))];
    input0_shared[(10)] = input0[(((N_outer * 32) + 10))];
    input0_shared[(11)] = input0[(((N_outer * 32) + 11))];
    input0_shared[(12)] = input0[(((N_outer * 32) + 12))];
    input0_shared[(13)] = input0[(((N_outer * 32) + 13))];
    input0_shared[(14)] = input0[(((N_outer * 32) + 14))];
    input0_shared[(15)] = input0[(((N_outer * 32) + 15))];
    input0_shared[(16)] = input0[(((N_outer * 32) + 16))];
    input0_shared[(17)] = input0[(((N_outer * 32) + 17))];
    input0_shared[(18)] = input0[(((N_outer * 32) + 18))];
    input0_shared[(19)] = input0[(((N_outer * 32) + 19))];
    input0_shared[(20)] = input0[(((N_outer * 32) + 20))];
    input0_shared[(21)] = input0[(((N_outer * 32) + 21))];
    input0_shared[(22)] = input0[(((N_outer * 32) + 22))];
    input0_shared[(23)] = input0[(((N_outer * 32) + 23))];
    input0_shared[(24)] = input0[(((N_outer * 32) + 24))];
    input0_shared[(25)] = input0[(((N_outer * 32) + 25))];
    input0_shared[(26)] = input0[(((N_outer * 32) + 26))];
    input0_shared[(27)] = input0[(((N_outer * 32) + 27))];
    input0_shared[(28)] = input0[(((N_outer * 32) + 28))];
    input0_shared[(29)] = input0[(((N_outer * 32) + 29))];
    input0_shared[(30)] = input0[(((N_outer * 32) + 30))];
    input0_shared[(31)] = input0[(((N_outer * 32) + 31))];
    __shared__ float input1_shared[32];
  // [thread_extent] threadIdx.x = 1
    input1_shared[(0)] = input1[((N_outer * 32))];
    input1_shared[(1)] = input1[(((N_outer * 32) + 1))];
    input1_shared[(2)] = input1[(((N_outer * 32) + 2))];
    input1_shared[(3)] = input1[(((N_outer * 32) + 3))];
    input1_shared[(4)] = input1[(((N_outer * 32) + 4))];
    input1_shared[(5)] = input1[(((N_outer * 32) + 5))];
    input1_shared[(6)] = input1[(((N_outer * 32) + 6))];
    input1_shared[(7)] = input1[(((N_outer * 32) + 7))];
    input1_shared[(8)] = input1[(((N_outer * 32) + 8))];
    input1_shared[(9)] = input1[(((N_outer * 32) + 9))];
    input1_shared[(10)] = input1[(((N_outer * 32) + 10))];
    input1_shared[(11)] = input1[(((N_outer * 32) + 11))];
    input1_shared[(12)] = input1[(((N_outer * 32) + 12))];
    input1_shared[(13)] = input1[(((N_outer * 32) + 13))];
    input1_shared[(14)] = input1[(((N_outer * 32) + 14))];
    input1_shared[(15)] = input1[(((N_outer * 32) + 15))];
    input1_shared[(16)] = input1[(((N_outer * 32) + 16))];
    input1_shared[(17)] = input1[(((N_outer * 32) + 17))];
    input1_shared[(18)] = input1[(((N_outer * 32) + 18))];
    input1_shared[(19)] = input1[(((N_outer * 32) + 19))];
    input1_shared[(20)] = input1[(((N_outer * 32) + 20))];
    input1_shared[(21)] = input1[(((N_outer * 32) + 21))];
    input1_shared[(22)] = input1[(((N_outer * 32) + 22))];
    input1_shared[(23)] = input1[(((N_outer * 32) + 23))];
    input1_shared[(24)] = input1[(((N_outer * 32) + 24))];
    input1_shared[(25)] = input1[(((N_outer * 32) + 25))];
    input1_shared[(26)] = input1[(((N_outer * 32) + 26))];
    input1_shared[(27)] = input1[(((N_outer * 32) + 27))];
    input1_shared[(28)] = input1[(((N_outer * 32) + 28))];
    input1_shared[(29)] = input1[(((N_outer * 32) + 29))];
    input1_shared[(30)] = input1[(((N_outer * 32) + 30))];
    input1_shared[(31)] = input1[(((N_outer * 32) + 31))];
    __syncthreads();
    for (int N_inner_outer = 0; N_inner_outer < 32; ++N_inner_outer) {
      float input0_shared_local[1];
      input0_shared_local[(0)] = input0_shared[(N_inner_outer)];
      float input1_shared_local[1];
      input1_shared_local[(0)] = input1_shared[(N_inner_outer)];
      output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
    }
  }
  output0[(0)] = output0_local[(0)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1610260.0, "TPR": 1.74198e-05}

[Antares] Average time cost / run = 1.74198e-05 sec, 0.117567 gflops. (Checked: True)

Finish Reduce\n
  >> Backend = c-cuda, Python PID = 19233, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[N, C, (HO + KH), (WO + KW)]*input1[F, C, KH, KW])], init=[], axis=[iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3)), iter_var(C, range(min=0, ext=64))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=16)), iter_var(F, range(min=0, ext=256)), iter_var(HO, range(min=0, ext=30)), iter_var(WO, range(min=0, ext=30))], reduce_axis=[iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3)), iter_var(C, range(min=0, ext=64))], tag=, attrs={})
[debug] is IODependent: True
failed to find results with padding threshold 0.0
found 10 results with threshold 0.2
[debug] config = {"0": "{\"tile\": [4, 12, 8, 8], \"step\": [3, 3, 8]}", "1": "{\"tile\": [1, 2, 2, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [4, 12, 8, 8], \"step\": [3, 3, 8]}", "1": "{\"tile\": [1, 2, 2, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] code gen tiling: {'N': [4, 1], 'F': [6, 2], 'HO': [4, 2], 'WO': [4, 2], 'KH': [3, 1], 'KW': [3, 1], 'C': [8, 1]}
[debug] adjusted tiling: {'N': [1, 4, 1], 'F': [2, 6, 1], 'HO': [2, 4, 1], 'WO': [2, 4, 1], 'KH': [3, 1], 'KW': [3, 1], 'C': [8, 1]}
[debug] thread per block 384

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[16, 64, 32, 32], input1:float32[256, 64, 3, 3] -> output0:float32[16, 256, 30, 30]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F, HO, WO] +=! input0[N, C, HO + KH, WO + KW] * input1[F, C, KH, KW] where HO in 30, WO in 30", { "input0": {"dtype": "float32", "shape": [16, 64, 32, 32]}, "input1": {"dtype": "float32", "shape": [256, 64, 3, 3]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[16, 64, 32, 32], input1:float32[256, 64, 3, 3] -> output0:float32[16, 256, 30, 30]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(384) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1408
  // [thread_extent] threadIdx.x = 384
  float output0_local[8];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  for (int C_outer = 0; C_outer < 8; ++C_outer) {
    __shared__ float input0_shared[3200];
  // [thread_extent] threadIdx.x = 384
    __syncthreads();
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) % 10)) < 32) {
        input0_shared[(((int)threadIdx.x))] = input0[(((((((((((int)blockIdx.x) / 352) * 262144) + (C_outer * 8192)) + ((((int)threadIdx.x) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + (((((int)threadIdx.x) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 84) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 4) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 384))] = input0[(((((((((((int)blockIdx.x) / 352) * 262144) + (C_outer * 8192)) + (((((int)threadIdx.x) + 384) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 84) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 4) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 68) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 8) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 768))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 768) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 768) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 68) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 8) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 52) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 2) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1152))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1152) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 352) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 52) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 2) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 36) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 6) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1536))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1536) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 736) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 36) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 6) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 20) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1920))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1920) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 320) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 20) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 4) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 4) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 2304))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 2304) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 704) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 4) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 4) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 88) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 8) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 2688))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 2688) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 288) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 88) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 8) % 10)))];
      }
    }
    if (((int)threadIdx.x) < 128) {
      if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 72) % 100) / 10)) < 32) {
        if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 2) % 10)) < 32) {
          input0_shared[((((int)threadIdx.x) + 3072))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 3072) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 672) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 72) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 2) % 10)))];
        }
      }
    }
    __shared__ float input1_shared[864];
  // [thread_extent] threadIdx.x = 384
    if (((((((int)blockIdx.x) % 352) >> 4) * 12) + (((int)threadIdx.x) / 72)) < 256) {
      input1_shared[(((int)threadIdx.x))] = input1[(((((((((int)blockIdx.x) % 352) >> 4) * 6912) + ((((int)threadIdx.x) / 72) * 576)) + (C_outer * 72)) + (((int)threadIdx.x) % 72)))];
    }
    if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) + 384) / 72)) < 256) {
      input1_shared[((((int)threadIdx.x) + 384))] = input1[((((((((((int)blockIdx.x) % 352) >> 4) * 6912) + (((((int)threadIdx.x) + 384) / 72) * 576)) + (C_outer * 72)) + ((((((int)threadIdx.x) / 3) + 8) % 24) * 3)) + (((int)threadIdx.x) % 3)))];
    }
    if (((int)threadIdx.x) < 96) {
      if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) + 768) / 72)) < 256) {
        input1_shared[((((int)threadIdx.x) + 768))] = input1[((((((((((int)blockIdx.x) % 352) >> 4) * 6912) + (((((int)threadIdx.x) + 768) / 72) * 576)) + (C_outer * 72)) + ((((((int)threadIdx.x) / 3) + 16) % 24) * 3)) + (((int)threadIdx.x) % 3)))];
      }
    }
    __syncthreads();
    for (int C_inner_outer = 0; C_inner_outer < 8; ++C_inner_outer) {
      for (int KH_inner_outer = 0; KH_inner_outer < 3; ++KH_inner_outer) {
        for (int KW_inner_outer = 0; KW_inner_outer < 3; ++KW_inner_outer) {
          float input0_shared_local[4];
          input0_shared_local[(0)] = input0_shared[((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)))];
          if (((((((int)blockIdx.x) & 3) * 8) + KW_inner_outer) + (((int)threadIdx.x) & 3)) < 28) {
            input0_shared_local[(1)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 4))];
          }
          if ((((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) + KH_inner_outer) < 28) {
            input0_shared_local[(2)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 40))];
            if (((((((int)blockIdx.x) & 3) * 8) + KW_inner_outer) + (((int)threadIdx.x) & 3)) < 28) {
              input0_shared_local[(3)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 44))];
            }
          }
          float input1_shared_local[2];
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
            input1_shared_local[(0)] = input1_shared[(((((((((int)threadIdx.x) % 96) >> 4) * 72) + (C_inner_outer * 9)) + (KH_inner_outer * 3)) + KW_inner_outer))];
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
            input1_shared_local[(1)] = input1_shared[((((((((((int)threadIdx.x) % 96) >> 4) * 72) + (C_inner_outer * 9)) + (KH_inner_outer * 3)) + KW_inner_outer) + 432))];
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
            output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
            if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
              output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
            }
            if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
              output0_local[(2)] = (output0_local[(2)] + (input0_shared_local[(2)] * input1_shared_local[(0)]));
              if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
                output0_local[(3)] = (output0_local[(3)] + (input0_shared_local[(3)] * input1_shared_local[(0)]));
              }
            }
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
            output0_local[(4)] = (output0_local[(4)] + (input0_shared_local[(0)] * input1_shared_local[(1)]));
            if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
              output0_local[(5)] = (output0_local[(5)] + (input0_shared_local[(1)] * input1_shared_local[(1)]));
            }
            if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
              output0_local[(6)] = (output0_local[(6)] + (input0_shared_local[(2)] * input1_shared_local[(1)]));
              if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
                output0_local[(7)] = (output0_local[(7)] + (input0_shared_local[(3)] * input1_shared_local[(1)]));
              }
            }
          }
        }
      }
    }
  }
  if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
    output0[((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)))] = output0_local[(0)];
    if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 4))] = output0_local[(1)];
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 120))] = output0_local[(2)];
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
        output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 124))] = output0_local[(3)];
      }
    }
  }
  if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
    output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5400))] = output0_local[(4)];
    if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5404))] = output0_local[(5)];
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5520))] = output0_local[(6)];
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
        output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5524))] = output0_local[(7)];
      }
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 106640932110000.0, "TPR": 0.00111263}

[Antares] Average time cost / run = 0.00111263 sec, 3816.84 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 19995, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[N, C, ((HO*2) + KH), ((WO*2) + KW)]*input1[F, C, KH, KW])], init=[], axis=[iter_var(C, range(min=0, ext=3)), iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=128)), iter_var(F, range(min=0, ext=96)), iter_var(HO, range(min=0, ext=165)), iter_var(WO, range(min=0, ext=165))], reduce_axis=[iter_var(C, range(min=0, ext=3)), iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
found 10 results in first round with threshold 0.1
[debug] config = {"0": "{\"tile\": [1, 1, 4, 176], \"step\": [3, 3, 3]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 4, 176], \"step\": [3, 3, 3]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] code gen tiling: {'N': [1, 1], 'F': [1, 1], 'HO': [4, 1], 'WO': [88, 2], 'C': [3, 1], 'KH': [3, 1], 'KW': [3, 1]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'F': [1, 1, 1], 'HO': [1, 4, 1], 'WO': [2, 88, 1], 'C': [3, 1], 'KH': [3, 1], 'KW': [3, 1]}
[debug] thread per block 352

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[128, 3, 332, 332], input1:float32[96, 3, 3, 3] -> output0:float32[128, 96, 165, 165]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F, HO, WO] +=! input0[N, C, HO * 2 + KH, WO * 2 + KW] * input1[F, C, KH, KW] where HO in 165, WO in 165", { "input0": {"dtype": "float32", "shape": [128, 3, 332, 332]}, "input1": {"dtype": "float32", "shape": [96, 3, 3, 3]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[128, 3, 332, 332], input1:float32[96, 3, 3, 3] -> output0:float32[128, 96, 165, 165]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(352) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 516096
  // [thread_extent] threadIdx.x = 352
  float output0_local[2];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  __shared__ float input0_shared[8964];
  // [thread_extent] threadIdx.x = 352
  input0_shared[(((int)threadIdx.x))] = input0[(((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)))];
  input0_shared[((((int)threadIdx.x) + 352))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 352))];
  input0_shared[((((int)threadIdx.x) + 704))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 704))];
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1056) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 1056))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 1056))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1408) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 1408))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 1408))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1760) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 1760))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 1760))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2112) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 2112))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 2112))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2464) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 2464))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + ((((int)blockIdx.x) % 42) * 2656)) + ((int)threadIdx.x)) + 2464))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + (((((int)threadIdx.x) + 2816) % 2988) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 2816))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 2816) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + ((((int)threadIdx.x) + 2816) % 2988)))];
  }
  input0_shared[((((int)threadIdx.x) + 3168))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 3168) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 180)))];
  input0_shared[((((int)threadIdx.x) + 3520))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 3520) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 532)))];
  input0_shared[((((int)threadIdx.x) + 3872))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 3872) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 884)))];
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1236) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 4224))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 4224) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1236)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1588) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 4576))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 4576) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1588)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1940) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 4928))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 4928) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1940)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2292) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 5280))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 5280) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 2292)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + (((((int)threadIdx.x) + 2644) % 2988) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 5632))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 5632) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + ((((int)threadIdx.x) + 2644) % 2988)))];
  }
  input0_shared[((((int)threadIdx.x) + 5984))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 5984) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 8)))];
  input0_shared[((((int)threadIdx.x) + 6336))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 6336) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 360)))];
  input0_shared[((((int)threadIdx.x) + 6688))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 6688) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 712)))];
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1064) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 7040))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 7040) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1064)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1416) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 7392))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 7392) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1416)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 1768) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 7744))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 7744) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 1768)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2120) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 8096))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 8096) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 2120)))];
  }
  if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2472) / 332)) < 332) {
    input0_shared[((((int)threadIdx.x) + 8448))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 8448) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 2472)))];
  }
  if (((int)threadIdx.x) < 164) {
    if ((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) + 2824) / 332)) < 332) {
      input0_shared[((((int)threadIdx.x) + 8800))] = input0[((((((((int)blockIdx.x) / 4032) * 330672) + (((((int)threadIdx.x) + 8800) / 2988) * 110224)) + ((((int)blockIdx.x) % 42) * 2656)) + (((int)threadIdx.x) + 2824)))];
    }
  }
  __shared__ float input1_shared[27];
  // [thread_extent] threadIdx.x = 352
  if (((int)threadIdx.x) < 27) {
    input1_shared[(((int)threadIdx.x))] = input1[(((((((int)blockIdx.x) % 4032) / 42) * 27) + ((int)threadIdx.x)))];
  }
  __syncthreads();
  for (int C_inner_outer = 0; C_inner_outer < 3; ++C_inner_outer) {
    for (int KH_inner_outer = 0; KH_inner_outer < 3; ++KH_inner_outer) {
      for (int KW_inner_outer = 0; KW_inner_outer < 3; ++KW_inner_outer) {
        float input0_shared_local[2];
        if (((((((int)blockIdx.x) % 42) * 8) + ((((int)threadIdx.x) / 88) * 2)) + KH_inner_outer) < 332) {
          input0_shared_local[(0)] = input0_shared[((((((C_inner_outer * 2988) + ((((int)threadIdx.x) / 88) * 664)) + (KH_inner_outer * 332)) + ((((int)threadIdx.x) % 88) * 2)) + KW_inner_outer))];
          if ((((((int)threadIdx.x) % 88) * 2) + KW_inner_outer) < 156) {
            input0_shared_local[(1)] = input0_shared[(((((((C_inner_outer * 2988) + ((((int)threadIdx.x) / 88) * 664)) + (KH_inner_outer * 332)) + ((((int)threadIdx.x) % 88) * 2)) + KW_inner_outer) + 176))];
          }
        }
        float input1_shared_local[1];
        input1_shared_local[(0)] = input1_shared[((((C_inner_outer * 9) + (KH_inner_outer * 3)) + KW_inner_outer))];
        if ((((((int)blockIdx.x) % 42) * 4) + (((int)threadIdx.x) / 88)) < 165) {
          output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
          if ((((int)threadIdx.x) % 88) < 77) {
            output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
          }
        }
      }
    }
  }
  if ((((((int)blockIdx.x) % 42) * 4) + (((int)threadIdx.x) / 88)) < 165) {
    output0[((((((((int)blockIdx.x) / 42) * 27225) + ((((int)blockIdx.x) % 42) * 660)) + ((((int)threadIdx.x) / 88) * 165)) + (((int)threadIdx.x) % 88)))] = output0_local[(0)];
    if ((((int)threadIdx.x) % 88) < 77) {
      output0[(((((((((int)blockIdx.x) / 42) * 27225) + ((((int)blockIdx.x) % 42) * 660)) + ((((int)threadIdx.x) / 88) * 165)) + (((int)threadIdx.x) % 88)) + 88))] = output0_local[(1)];
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 450872032470000.0, "TPR": 0.0154934}

[Antares] Average time cost / run = 0.0154934 sec, 1165.99 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 23707, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(tir.if_then_else(((((0 <= (HO + KH)) && ((HO + KH) < 32)) && (0 <= (WO + KW))) && ((WO + KW) < 32)), input0[N, C, (HO + KH), (WO + KW)], 0f)*input1[F, C, KH, KW])], init=[], axis=[iter_var(KW, range(min=0, ext=3)), iter_var(C, range(min=0, ext=64)), iter_var(KH, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=16)), iter_var(F, range(min=0, ext=256)), iter_var(HO, range(min=0, ext=30)), iter_var(WO, range(min=0, ext=30))], reduce_axis=[iter_var(KW, range(min=0, ext=3)), iter_var(C, range(min=0, ext=64)), iter_var(KH, range(min=0, ext=3))], tag=, attrs={})
[debug] is IODependent: True
failed to find results with padding threshold 0.0
found 10 results with threshold 0.2
[debug] config = {"0": "{\"tile\": [4, 12, 8, 8], \"step\": [3, 8, 3]}", "1": "{\"tile\": [1, 2, 2, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [4, 12, 8, 8], \"step\": [3, 8, 3]}", "1": "{\"tile\": [1, 2, 2, 2], \"step\": [1, 1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1, 1]}"}
[debug] code gen tiling: {'N': [4, 1], 'F': [6, 2], 'HO': [4, 2], 'WO': [4, 2], 'KW': [3, 1], 'C': [8, 1], 'KH': [3, 1]}
[debug] adjusted tiling: {'N': [1, 4, 1], 'F': [2, 6, 1], 'HO': [2, 4, 1], 'WO': [2, 4, 1], 'KW': [3, 1], 'C': [8, 1], 'KH': [3, 1]}
[debug] thread per block 384

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[16, 64, 32, 32], input1:float32[256, 64, 3, 3] -> output0:float32[16, 256, 30, 30]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - _N, _CI, _H, _W, _CO, _KH, _KW, _SH, _SW, _PH, _PW = 16, 64, 32, 32, 256, 3, 3, 1, 1, 0, 0; _HO, _WO = (_H - _KH + _PH * 2) // _SH + 1, (_W - _KW + _PW * 2) // _SW + 1; einstein_v2(f"output0[N, F, HO, WO] +=! input0[N, C, HO * {_SH} + KH - {_PH}, WO * {_SW} + KW - {_PW}].when([HO * {_SH} + KH - {_PH} >= 0, HO * {_SH} + KH - {_PH} < {_H}, WO * {_SW} + KW - {_PW} >= 0, WO * {_SW} + KW - {_PW} < {_W}], 0.0) * input1[F, C, KH, KW] where HO in {_HO}, WO in {_WO}", { "input0": {"dtype": "float32", "shape": [_N, _CI, _H, _W]}, "input1": {"dtype": "float32", "shape": [_CO, _CI, _KH, _KW]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[16, 64, 32, 32], input1:float32[256, 64, 3, 3] -> output0:float32[16, 256, 30, 30]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(384) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1408
  // [thread_extent] threadIdx.x = 384
  float output0_local[8];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  for (int C_outer = 0; C_outer < 8; ++C_outer) {
    __shared__ float input0_shared[3200];
  // [thread_extent] threadIdx.x = 384
    __syncthreads();
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) % 10)) < 32) {
        input0_shared[(((int)threadIdx.x))] = input0[(((((((((((int)blockIdx.x) / 352) * 262144) + (C_outer * 8192)) + ((((int)threadIdx.x) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + (((((int)threadIdx.x) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 84) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 4) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 384))] = input0[(((((((((((int)blockIdx.x) / 352) * 262144) + (C_outer * 8192)) + (((((int)threadIdx.x) + 384) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 84) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 4) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 68) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 8) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 768))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 768) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 768) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 68) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 8) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 52) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 2) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1152))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1152) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 352) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 52) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 2) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 36) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 6) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1536))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1536) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 736) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 36) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 6) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 20) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 1920))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 1920) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 320) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 20) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 4) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 4) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 2304))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 2304) / 800) * 65536)) + (C_outer * 8192)) + ((((((int)threadIdx.x) + 704) % 800) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 4) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 4) % 10)))];
      }
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 88) % 100) / 10)) < 32) {
      if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 8) % 10)) < 32) {
        input0_shared[((((int)threadIdx.x) + 2688))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 2688) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 288) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 88) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 8) % 10)))];
      }
    }
    if (((int)threadIdx.x) < 128) {
      if (((((((int)blockIdx.x) & 15) >> 2) * 8) + (((((int)threadIdx.x) + 72) % 100) / 10)) < 32) {
        if ((((((int)blockIdx.x) & 3) * 8) + ((((int)threadIdx.x) + 2) % 10)) < 32) {
          input0_shared[((((int)threadIdx.x) + 3072))] = input0[((((((((((((int)blockIdx.x) / 352) * 262144) + (((((int)threadIdx.x) + 3072) / 800) * 65536)) + (C_outer * 8192)) + (((((int)threadIdx.x) + 672) / 100) * 1024)) + (((((int)blockIdx.x) & 15) >> 2) * 256)) + ((((((int)threadIdx.x) + 72) % 100) / 10) * 32)) + ((((int)blockIdx.x) & 3) * 8)) + ((((int)threadIdx.x) + 2) % 10)))];
        }
      }
    }
    __shared__ float input1_shared[864];
  // [thread_extent] threadIdx.x = 384
    if (((((((int)blockIdx.x) % 352) >> 4) * 12) + (((int)threadIdx.x) / 72)) < 256) {
      input1_shared[(((int)threadIdx.x))] = input1[(((((((((int)blockIdx.x) % 352) >> 4) * 6912) + ((((int)threadIdx.x) / 72) * 576)) + (C_outer * 72)) + (((int)threadIdx.x) % 72)))];
    }
    if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) + 384) / 72)) < 256) {
      input1_shared[((((int)threadIdx.x) + 384))] = input1[((((((((((int)blockIdx.x) % 352) >> 4) * 6912) + (((((int)threadIdx.x) + 384) / 72) * 576)) + (C_outer * 72)) + ((((((int)threadIdx.x) / 3) + 8) % 24) * 3)) + (((int)threadIdx.x) % 3)))];
    }
    if (((int)threadIdx.x) < 96) {
      if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) + 768) / 72)) < 256) {
        input1_shared[((((int)threadIdx.x) + 768))] = input1[((((((((((int)blockIdx.x) % 352) >> 4) * 6912) + (((((int)threadIdx.x) + 768) / 72) * 576)) + (C_outer * 72)) + ((((((int)threadIdx.x) / 3) + 16) % 24) * 3)) + (((int)threadIdx.x) % 3)))];
      }
    }
    __syncthreads();
    for (int C_inner_outer = 0; C_inner_outer < 8; ++C_inner_outer) {
      for (int KW_inner_outer = 0; KW_inner_outer < 3; ++KW_inner_outer) {
        for (int KH_inner_outer = 0; KH_inner_outer < 3; ++KH_inner_outer) {
          float input0_shared_local[4];
          input0_shared_local[(0)] = input0_shared[((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)))];
          if (((((((int)blockIdx.x) & 3) * 8) + KW_inner_outer) + (((int)threadIdx.x) & 3)) < 28) {
            input0_shared_local[(1)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 4))];
          }
          if ((((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) + KH_inner_outer) < 28) {
            input0_shared_local[(2)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 40))];
            if (((((((int)blockIdx.x) & 3) * 8) + KW_inner_outer) + (((int)threadIdx.x) & 3)) < 28) {
              input0_shared_local[(3)] = input0_shared[(((((((((((int)threadIdx.x) / 96) * 800) + (C_inner_outer * 100)) + (((((int)threadIdx.x) & 15) >> 2) * 10)) + (KH_inner_outer * 10)) + KW_inner_outer) + (((int)threadIdx.x) & 3)) + 44))];
            }
          }
          float input1_shared_local[2];
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
            input1_shared_local[(0)] = input1_shared[(((((((((int)threadIdx.x) % 96) >> 4) * 72) + (C_inner_outer * 9)) + (KH_inner_outer * 3)) + KW_inner_outer))];
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
            input1_shared_local[(1)] = input1_shared[((((((((((int)threadIdx.x) % 96) >> 4) * 72) + (C_inner_outer * 9)) + (KH_inner_outer * 3)) + KW_inner_outer) + 432))];
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
            output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
            if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
              output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
            }
            if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
              output0_local[(2)] = (output0_local[(2)] + (input0_shared_local[(2)] * input1_shared_local[(0)]));
              if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
                output0_local[(3)] = (output0_local[(3)] + (input0_shared_local[(3)] * input1_shared_local[(0)]));
              }
            }
          }
          if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
            output0_local[(4)] = (output0_local[(4)] + (input0_shared_local[(0)] * input1_shared_local[(1)]));
            if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
              output0_local[(5)] = (output0_local[(5)] + (input0_shared_local[(1)] * input1_shared_local[(1)]));
            }
            if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
              output0_local[(6)] = (output0_local[(6)] + (input0_shared_local[(2)] * input1_shared_local[(1)]));
              if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
                output0_local[(7)] = (output0_local[(7)] + (input0_shared_local[(3)] * input1_shared_local[(1)]));
              }
            }
          }
        }
      }
    }
  }
  if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 256) {
    output0[((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)))] = output0_local[(0)];
    if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 4))] = output0_local[(1)];
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 120))] = output0_local[(2)];
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
        output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 124))] = output0_local[(3)];
      }
    }
  }
  if (((((((int)blockIdx.x) % 352) >> 4) * 12) + ((((int)threadIdx.x) % 96) >> 4)) < 250) {
    output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5400))] = output0_local[(4)];
    if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5404))] = output0_local[(5)];
    }
    if (((((((int)blockIdx.x) & 15) >> 2) * 8) + ((((int)threadIdx.x) & 15) >> 2)) < 26) {
      output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5520))] = output0_local[(6)];
      if ((((((int)blockIdx.x) & 3) * 8) + (((int)threadIdx.x) & 3)) < 26) {
        output0[(((((((((((((int)blockIdx.x) / 352) * 921600) + ((((int)threadIdx.x) / 96) * 230400)) + (((((int)blockIdx.x) % 352) >> 4) * 10800)) + (((((int)threadIdx.x) % 96) >> 4) * 900)) + (((((int)blockIdx.x) & 15) >> 2) * 240)) + (((((int)threadIdx.x) & 15) >> 2) * 30)) + ((((int)blockIdx.x) & 3) * 8)) + (((int)threadIdx.x) & 3)) + 5524))] = output0_local[(7)];
      }
    }
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 106640932110000.0, "TPR": 0.00110106}

[Antares] Average time cost / run = 0.00110106 sec, 3856.95 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 24479, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(input0[N, C, (HO + KH), (WO + KW)]*input1[KH, KW, C, 0])], init=[], axis=[iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=32)), iter_var(C, range(min=0, ext=16)), iter_var(HO, range(min=0, ext=30)), iter_var(WO, range(min=0, ext=30))], reduce_axis=[iter_var(KH, range(min=0, ext=3)), iter_var(KW, range(min=0, ext=3))], tag=, attrs={})
[debug] is IODependent: False
failed to find results with padding threshold 0.0
found 10 results in first round with threshold 0.1
[debug] config = {"0": "{\"tile\": [1, 1, 2, 32], \"step\": [3, 3]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1]}"}
[debug] input rprog:  {"0": "{\"tile\": [1, 1, 2, 32], \"step\": [3, 3]}", "1": "{\"tile\": [1, 1, 1, 2], \"step\": [1, 1]}", "2": "{\"tile\": [1, 1, 1, 1], \"step\": [1, 1]}"}
[debug] code gen tiling: {'N': [1, 1], 'C': [1, 1], 'HO': [2, 1], 'WO': [16, 2], 'KH': [3, 1], 'KW': [3, 1]}
[debug] adjusted tiling: {'N': [1, 1, 1], 'C': [1, 1, 1], 'HO': [1, 2, 1], 'WO': [2, 16, 1], 'KH': [3, 1], 'KW': [3, 1]}
[debug] thread per block 32

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[32, 16, 32, 32], input1:float32[3, 3, 16, 1] -> output0:float32[32, 16, 30, 30]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, C, HO, WO] +=! input0[N, C, HO + KH, WO + KW] * input1[KH, KW, C, 0] where HO in 30, WO in 30", input_dict={"input0": {"dtype": "float32", "shape": [32, 16, 32, 32]}, "input1": {"dtype": "float32", "shape": [3, 3, 16, 1]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[32, 16, 32, 32], input1:float32[3, 3, 16, 1] -> output0:float32[32, 16, 30, 30]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(32) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 7680
  // [thread_extent] threadIdx.x = 32
  float output0_local[2];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  __shared__ float input0_shared[128];
  // [thread_extent] threadIdx.x = 32
  input0_shared[(((int)threadIdx.x))] = input0[(((((((int)blockIdx.x) / 15) * 1024) + ((((int)blockIdx.x) % 15) * 64)) + ((int)threadIdx.x)))];
  input0_shared[((((int)threadIdx.x) + 32))] = input0[((((((((int)blockIdx.x) / 15) * 1024) + ((((int)blockIdx.x) % 15) * 64)) + ((int)threadIdx.x)) + 32))];
  input0_shared[((((int)threadIdx.x) + 64))] = input0[((((((((int)blockIdx.x) / 15) * 1024) + ((((int)blockIdx.x) % 15) * 64)) + ((int)threadIdx.x)) + 64))];
  input0_shared[((((int)threadIdx.x) + 96))] = input0[((((((((int)blockIdx.x) / 15) * 1024) + ((((int)blockIdx.x) % 15) * 64)) + ((int)threadIdx.x)) + 96))];
  __shared__ float input1_shared[9];
  // [thread_extent] threadIdx.x = 32
  if (((int)threadIdx.x) < 9) {
    input1_shared[(((int)threadIdx.x))] = input1[(((((int)threadIdx.x) * 16) + ((((int)blockIdx.x) % 240) / 15)))];
  }
  __syncthreads();
  for (int KH_inner_outer = 0; KH_inner_outer < 3; ++KH_inner_outer) {
    for (int KW_inner_outer = 0; KW_inner_outer < 3; ++KW_inner_outer) {
      float input0_shared_local[2];
      input0_shared_local[(0)] = input0_shared[((((((((int)threadIdx.x) >> 4) * 32) + (KH_inner_outer * 32)) + KW_inner_outer) + (((int)threadIdx.x) & 15)))];
      if ((KW_inner_outer + (((int)threadIdx.x) & 15)) < 16) {
        input0_shared_local[(1)] = input0_shared[(((((((((int)threadIdx.x) >> 4) * 32) + (KH_inner_outer * 32)) + KW_inner_outer) + (((int)threadIdx.x) & 15)) + 16))];
      }
      float input1_shared_local[1];
      input1_shared_local[(0)] = input1_shared[(((KH_inner_outer * 3) + KW_inner_outer))];
      output0_local[(0)] = (output0_local[(0)] + (input0_shared_local[(0)] * input1_shared_local[(0)]));
      if ((((int)threadIdx.x) & 15) < 14) {
        output0_local[(1)] = (output0_local[(1)] + (input0_shared_local[(1)] * input1_shared_local[(0)]));
      }
    }
  }
  output0[((((((int)blockIdx.x) * 60) + ((((int)threadIdx.x) >> 4) * 30)) + (((int)threadIdx.x) & 15)))] = output0_local[(0)];
  if ((((int)threadIdx.x) & 15) < 14) {
    output0[(((((((int)blockIdx.x) * 60) + ((((int)threadIdx.x) >> 4) * 30)) + (((int)threadIdx.x) & 15)) + 16))] = output0_local[(1)];
  }
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 205578156500.0, "TPR": 1.43831e-05}

[Antares] Average time cost / run = 1.43831e-05 sec, 576.677 gflops. (Checked: True)

Finish Direct Conv\n
  >> Backend = c-cuda, Python PID = 24820, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(temp0[K, N]*input1[K, M])], init=[], axis=[iter_var(K, range(min=0, ext=10))], where=(bool)1, value_index=0)], axis=[iter_var(N, range(min=0, ext=1024)), iter_var(M, range(min=0, ext=512))], reduce_axis=[iter_var(K, range(min=0, ext=10))], tag=, attrs={})
[debug] is IODependent: True
found 10 results with threshold 0.0
[debug] config = {"0": "{\"tile\": [64, 64], \"step\": [10]}", "1": "{\"tile\": [4, 2], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] input rprog:  {"0": "{\"tile\": [64, 64], \"step\": [10]}", "1": "{\"tile\": [4, 2], \"step\": [1]}", "2": "{\"tile\": [1, 1], \"step\": [1]}"}
[debug] code gen tiling: {'N': [16, 4], 'M': [32, 2], 'K': [10, 1]}
[debug] adjusted tiling: {'N': [4, 16, 1], 'M': [2, 32, 1], 'K': [10, 1]}
[debug] thread per block 512

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1024, 512], input1:float32[512, 512] -> output0:float32[1024, 512]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("temp0[K, N] = input0[N, K] + 100; output0[N, M] +=! temp0[K, N] * input1[K, M] where K in 10", { "input0": {"dtype": "float32", "shape": [1024, 512]}, "input1": {"dtype": "float32", "shape": [512, 512]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1024, 512], input1:float32[512, 512] -> output0:float32[1024, 512]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(512) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 128
  // [thread_extent] threadIdx.x = 512
  float output0_local[8];
  output0_local[(0)] = 0.000000e+00f;
  output0_local[(2)] = 0.000000e+00f;
  output0_local[(4)] = 0.000000e+00f;
  output0_local[(6)] = 0.000000e+00f;
  output0_local[(1)] = 0.000000e+00f;
  output0_local[(3)] = 0.000000e+00f;
  output0_local[(5)] = 0.000000e+00f;
  output0_local[(7)] = 0.000000e+00f;
  __shared__ float temp0_shared[640];
  // [thread_extent] threadIdx.x = 512
  temp0_shared[(((int)threadIdx.x))] = (input0[(((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) & 63) * 512)) + (((int)threadIdx.x) >> 6)))] + 1.000000e+02f);
  if (((int)threadIdx.x) < 128) {
    temp0_shared[((((int)threadIdx.x) + 512))] = (input0[((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) & 63) * 512)) + (((int)threadIdx.x) >> 6)) + 8))] + 1.000000e+02f);
  }
  __shared__ float input1_shared[640];
  // [thread_extent] threadIdx.x = 512
  input1_shared[(((int)threadIdx.x))] = input1[(((((((int)threadIdx.x) >> 6) * 512) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 63)))];
  if (((int)threadIdx.x) < 128) {
    input1_shared[((((int)threadIdx.x) + 512))] = input1[((((((((int)threadIdx.x) >> 6) * 512) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 63)) + 4096))];
  }
  __syncthreads();
  for (int K_inner_outer = 0; K_inner_outer < 10; ++K_inner_outer) {
    float temp0_shared_local[4];
    temp0_shared_local[(0)] = temp0_shared[(((K_inner_outer * 64) + (((int)threadIdx.x) >> 5)))];
    temp0_shared_local[(1)] = temp0_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) >> 5)) + 16))];
    temp0_shared_local[(2)] = temp0_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) >> 5)) + 32))];
    temp0_shared_local[(3)] = temp0_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) >> 5)) + 48))];
    float input1_shared_local[2];
    input1_shared_local[(0)] = input1_shared[(((K_inner_outer * 64) + (((int)threadIdx.x) & 31)))];
    input1_shared_local[(1)] = input1_shared[((((K_inner_outer * 64) + (((int)threadIdx.x) & 31)) + 32))];
    output0_local[(0)] = (output0_local[(0)] + (temp0_shared_local[(0)] * input1_shared_local[(0)]));
    output0_local[(2)] = (output0_local[(2)] + (temp0_shared_local[(1)] * input1_shared_local[(0)]));
    output0_local[(4)] = (output0_local[(4)] + (temp0_shared_local[(2)] * input1_shared_local[(0)]));
    output0_local[(6)] = (output0_local[(6)] + (temp0_shared_local[(3)] * input1_shared_local[(0)]));
    output0_local[(1)] = (output0_local[(1)] + (temp0_shared_local[(0)] * input1_shared_local[(1)]));
    output0_local[(3)] = (output0_local[(3)] + (temp0_shared_local[(1)] * input1_shared_local[(1)]));
    output0_local[(5)] = (output0_local[(5)] + (temp0_shared_local[(2)] * input1_shared_local[(1)]));
    output0_local[(7)] = (output0_local[(7)] + (temp0_shared_local[(3)] * input1_shared_local[(1)]));
  }
  output0[((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)))] = output0_local[(0)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 8192))] = output0_local[(2)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 16384))] = output0_local[(4)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 24576))] = output0_local[(6)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 32))] = output0_local[(1)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 8224))] = output0_local[(3)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 16416))] = output0_local[(5)];
  output0[(((((((((int)blockIdx.x) >> 3) * 32768) + ((((int)threadIdx.x) >> 5) * 512)) + ((((int)blockIdx.x) & 7) * 64)) + (((int)threadIdx.x) & 31)) + 24608))] = output0_local[(7)];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1014137961400.0, "TPR": 6.49663e-06}

[Antares] Average time cost / run = 6.49663e-06 sec, 1694.73 gflops. (Checked: True)

Finish Fusion\n
  >> Backend = c-cuda, Python PID = 25610, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[input0[0, F]], axis=[iter_var(F, range(min=0, ext=16))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: False
found 7 results in first round with threshold 0.0
found 7 results in first round with threshold 0.1
found 7 results in first round with threshold 0.2
found 7 results in first round with threshold 0.3
found 7 results in first round with threshold 0.4
found 10 results in first round with threshold 0.5
[debug] config = {"0": "{\"tile\": [8], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [8], \"step\": []}", "1": "{\"tile\": [2], \"step\": []}", "2": "{\"tile\": [1], \"step\": []}"}
[debug] code gen tiling: {'F': [4, 2]}
[debug] adjusted tiling: {'F': [2, 4, 1]}
[debug] thread per block 4

// ---------------------------------------------------------------------------
// GLOBALS: input0:float32[1, 16] -> output0:float32[16]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F] = input0[N, F]", input_dict={"input0": {"dtype": "float32", "shape": [1, 16]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[1, 16] -> output0:float32[1, 16]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(4) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 2
  // [thread_extent] threadIdx.x = 4
  output0[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)))] = input0[(((((int)blockIdx.x) * 8) + ((int)threadIdx.x)))];
  output0[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) + 4))] = input0[((((((int)blockIdx.x) * 8) + ((int)threadIdx.x)) + 4))];
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 1496.0, "TPR": 4.90788e-06}

[Antares] Average time cost / run = 4.90788e-06 sec, 0.00326006 gflops. (Checked: True)

  >> Backend = c-cuda, Python PID = 25951, Task = lang.generic;
  >> Computing CPU result for correctness reference..
[debug] devname = V100
[debug] op info =  compute(output0, body=[tir.if_then_else((input0[N] == F), 1f, 0f)], axis=[iter_var(N, range(min=0, ext=4)), iter_var(F, range(min=0, ext=128))], reduce_axis=[], tag=, attrs={})
[debug] is IODependent: True
found 10 results in first round with threshold 0.0
[debug] config = {"0": "{\"tile\": [4, 128], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] input rprog:  {"0": "{\"tile\": [4, 128], \"step\": []}", "1": "{\"tile\": [1, 2], \"step\": []}", "2": "{\"tile\": [1, 1], \"step\": []}"}
[debug] code gen tiling: {'N': [4, 1], 'F': [64, 2]}
[debug] adjusted tiling: {'N': [1, 4, 1], 'F': [2, 64, 1]}
[debug] thread per block 256

// ---------------------------------------------------------------------------
// GLOBALS: input0:int32[4] -> output0:float32[4, 128]
// BACKEND: c-cuda (default)
// CONFIG: null
// COMPUTE_V1: - einstein_v2("output0[N, F] = const(1.0).when([input0[N] == F], const(0.0)) where F in 128", input_dict={"input0": {"dtype": "int32", "shape": [4]}})


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:int32[4] -> output0:float32[4, 128]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#if (__CUDA_ARCH__ >= 600)

__forceinline__ __device__ __half max(const __half &a, const __half &b) {{ return a > b ? a : b; }}
__forceinline__ __device__ __half min(const __half &a, const __half &b) {{ return a < b ? a : b; }}

#endif

#endif


extern "C" __global__ __launch_bounds__(256) void template_op_kernel0(int* __restrict__ input0, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 256
  output0[((((((int)threadIdx.x) >> 6) * 128) + (((int)threadIdx.x) & 63)))] = ((input0[((((int)threadIdx.x) >> 6))] == (((int)threadIdx.x) & 63)) ? 1.000000e+00f : 0.000000e+00f);
  output0[(((((((int)threadIdx.x) >> 6) * 128) + (((int)threadIdx.x) & 63)) + 64))] = ((input0[((((int)threadIdx.x) >> 6))] == ((((int)threadIdx.x) & 63) + 64)) ? 1.000000e+00f : 0.000000e+00f);
}

// ---------------------------------------------------------------------------

[EvalAgent] Evaluating Modules .. (for backend = c-cuda)

[EvalAgent] Results = {"K/0": 108.0, "TPR": 5.03806e-06}

[Antares] Average time cost / run = 5.03806e-06 sec, 0.101626 gflops. (Checked: True)

Finish Other Utilities\n
